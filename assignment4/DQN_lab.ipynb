{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Deep Q Network\n",
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports %%execwritefile command (executes cell and writes it into file). \n",
    "# All cells that start with %%execwritefile should be in td_autograde.py file after running all cells.\n",
    "\n",
    "from custommagics import CustomMagics\n",
    "get_ipython().register_magics(CustomMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile dqn_autograde.py\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc69f22067705372",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 7, 0), \"Make sure you have Python 3.7 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fef7e20e54e6243b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1. Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-39519f4ab05eb2a1",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/miniconda3/envs/rlcourse/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.envs.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        CartPoleEnv\n",
      "\u001b[0;31mString form:\u001b[0m <CartPoleEnv<CartPole-v1>>\n",
      "\u001b[0;31mFile:\u001b[0m        ~/miniconda3/envs/rlcourse/lib/python3.7/site-packages/gym/envs/classic_control/cartpole.py\n",
      "\u001b[0;31mSource:\u001b[0m     \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mCartPoleEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m    Description:\u001b[0m\n",
      "\u001b[0;34m        A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum starts upright, and the goal is to prevent it from falling over by increasing and reducing the cart's velocity.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Source:\u001b[0m\n",
      "\u001b[0;34m        This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Observation: \u001b[0m\n",
      "\u001b[0;34m        Type: Box(4)\u001b[0m\n",
      "\u001b[0;34m        Num     Observation                 Min         Max\u001b[0m\n",
      "\u001b[0;34m        0       Cart Position             -4.8            4.8\u001b[0m\n",
      "\u001b[0;34m        1       Cart Velocity             -Inf            Inf\u001b[0m\n",
      "\u001b[0;34m        2       Pole Angle                 -24°           24°\u001b[0m\n",
      "\u001b[0;34m        3       Pole Velocity At Tip      -Inf            Inf\u001b[0m\n",
      "\u001b[0;34m        \u001b[0m\n",
      "\u001b[0;34m    Actions:\u001b[0m\n",
      "\u001b[0;34m        Type: Discrete(2)\u001b[0m\n",
      "\u001b[0;34m        Num     Action\u001b[0m\n",
      "\u001b[0;34m        0       Push cart to the left\u001b[0m\n",
      "\u001b[0;34m        1       Push cart to the right\u001b[0m\n",
      "\u001b[0;34m        \u001b[0m\n",
      "\u001b[0;34m        Note: The amount the velocity is reduced or increased is not fixed as it depends on the angle the pole is pointing. This is because the center of gravity of the pole increases the amount of energy needed to move the cart underneath it\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Reward:\u001b[0m\n",
      "\u001b[0;34m        Reward is 1 for every step taken, including the termination step\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Starting State:\u001b[0m\n",
      "\u001b[0;34m        All observations are assigned a uniform random value between ±0.05\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Episode Termination:\u001b[0m\n",
      "\u001b[0;34m        Pole Angle is more than ±12°\u001b[0m\n",
      "\u001b[0;34m        Cart Position is more than ±2.4 (center of the cart reaches the edge of the display)\u001b[0m\n",
      "\u001b[0;34m        Episode length is greater than 200\u001b[0m\n",
      "\u001b[0;34m        Solved Requirements\u001b[0m\n",
      "\u001b[0;34m        Considered solved when the average reward is greater than or equal to 195.0 over 100 consecutive trials.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'render.modes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'video.frames_per_second'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9.8\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasscart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasscart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;31m# actually half the pole's length\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.02\u001b[0m  \u001b[0;31m# seconds between state updates\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'euler'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Angle at which to fail the episode\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.4\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Angle limit set to 2 * theta_threshold_radians so failing observation is still within bounds\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mhigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%r (%s) invalid\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mforce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcostheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msintheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msintheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mthetaacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msintheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcostheta\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mxacc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'euler'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# semi-implicit euler\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta_dot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Pole just fell!\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscreen_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscreen_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mworld_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscreen_width\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mworld_width\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcarty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;31m# TOP OF CART\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpolewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpolelen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0maxleoffset\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolelen\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxleoffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_circle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;31m# MIDDLE OF CART\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcartx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# env is a TimeLimit wrapper around an env, so use env.env to look into the env (but otherwise you can forget about this)\n",
    "??env.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nice thing about the CARTPOLE is that it has very nice rendering functionality (if you are on a local environment). Let's have a look at an episode\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "done = False\n",
    "while not done:\n",
    "    obs, reward, done, _ = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "env.close() # Close the environment or you will have a lot of render screens soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2d83f70e62b99520",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Remember from the previous lab, that in order to optimize a policy we need to estimate the Q-values (e.g. estimate the *action* values). In the CartPole problem, our state is the current position of the cart, the current velocity of the cart, the current (angular) position of the pole and the (angular) speed of the pole. As these are continuous variables, we have an infinite number of states (ignoring the fact that a digital computer can only represent finitely many states in finite memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b3162496f5e6cf5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.1 Implement Q-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96a86bcfa1ebc84a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We will not use the tabular approach but approximate the Q-value function by a general approximator function. We will skip the linear case and directly use a two layer Neural Network. We use [PyTorch](https://pytorch.org/) to implement the network, as this will allow us to train it easily later. We can implement a model using `torch.nn.Sequential`, but with PyTorch it is actually very easy to implement the model (e.g. the forward pass) from scratch. Now implement the `QNetwork.forward` function that uses one hidden layer with ReLU activation (no output activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-216429a5dccf8a0e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_hidden=128):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-00ce108d640a5942",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's instantiate and test if it works\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1)\n",
    "Q_net = QNetwork(num_hidden)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "test_model = nn.Sequential(\n",
    "    nn.Linear(4, num_hidden), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(num_hidden, 2)\n",
    ")\n",
    "\n",
    "x = torch.rand(10, 4)\n",
    "\n",
    "# If you do not need backpropagation, wrap the computation in the torch.no_grad() context\n",
    "# This saves time and memory, and PyTorch complains when converting to numpy\n",
    "with torch.no_grad():\n",
    "    assert np.allclose(Q_net(x).numpy(), test_model(x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ca77eae2e62180cf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.2 Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2c1d117a1a75fd69",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to stabilize learning, we will use an experience replay to save states in and sample states from. Now implement the `push` function that adds a transition to the replay buffer, and the `sample` function that samples a (random!) batch of data, for use during training (hint: you can use the function `random.sample`). It should keep at most the maximum number of transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a3cc876e51eb157f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, transition):\n",
    "        # YOUR CODE HERE\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # YOUR CODE HERE\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3b90135921c4da76",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([ 0.02942155,  0.01920609, -0.03687306, -0.01416851]), 1, 1.0, array([ 0.02980567,  0.21483691, -0.03715643, -0.31825351]), False)]\n"
     ]
    }
   ],
   "source": [
    "capacity = 10\n",
    "memory = ReplayMemory(capacity)\n",
    "\n",
    "# Sample a transition\n",
    "s = env.reset()\n",
    "a = env.action_space.sample()\n",
    "s_next, r, done, _ = env.step(a)\n",
    "\n",
    "# Push a transition\n",
    "memory.push((s, a, r, s_next, done))\n",
    "\n",
    "# Sample a batch size of 1\n",
    "print(memory.sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88f67e3c051da6a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.3 $\\epsilon$psilon Greedy Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aa3c7d1b3000f697",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to learn a good policy, we need to explore quite a bit initially. As we start to learn a good policy, we want to decrease the exploration. As the amount of exploration using an $\\epsilon$-greedy policy is controlled by $\\epsilon$, we can define an 'exploration scheme' by writing $\\epsilon$ as a function of time. There are many possible schemes, but we will use a simple one: we will start with only exploring (so taking random actions) at iteration 0, and then in 1000 iterations linearly anneal $\\epsilon$ such that after 1000 iterations we take random (exploration) actions with 5\\% probability (forever, as you never know if the environment will change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5789e7a792108576",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def get_epsilon(it):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    epsilon = max(1.0 - (it / 1000) * (1.0 - 0.05), 0.05)\n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-40e66db45e742b2e",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x765bcd5ba110>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So what's an easy way to check?\n",
    "plt.plot([get_epsilon(it) for it in range(5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8b604c9998c6c3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now write a function of *EpsilonGreedyPolicy* class. This function takes a state and uses the Q-network to select an ($\\epsilon$-greedy) action. It should return a random action with probability epsilon. Note, you do not need to backpropagate through the model computations, so use `with torch.no_grad():` (see above for example). Note that to convert a PyTorch tensor with only 1 element (0 dimensional) to a simple python scalar (int or float), you can use the '.item()' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-878ad3a637cfb51c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class EpsilonGreedyPolicy(object):\n",
    "    \"\"\"\n",
    "    A simple epsilon greedy policy.\n",
    "    \"\"\"\n",
    "    def __init__(self, Q, epsilon):\n",
    "        self.Q = Q\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def sample_action(self, obs):\n",
    "        \"\"\"\n",
    "        This method takes a state as input and returns an action sampled from this policy.  \n",
    "\n",
    "        Args:\n",
    "            obs: current state\n",
    "\n",
    "        Returns:\n",
    "            An action (int).\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        with torch.no_grad():\n",
    "            # Exploratory action\n",
    "            if np.random.rand() < self.epsilon:\n",
    "                action = np.random.randint(2)\n",
    "            # Greedy action\n",
    "            else:\n",
    "                action = torch.argmax(self.Q(torch.tensor(obs).float())).item()\n",
    "        \n",
    "        return action\n",
    "        \n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e895338d56bee477",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "epg = EpsilonGreedyPolicy(Q_net, 0.05)\n",
    "a = epg.sample_action(s)\n",
    "assert not torch.is_tensor(a)\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 970, 1: 30}\n"
     ]
    }
   ],
   "source": [
    "counts = {0: 0, 1: 0}\n",
    "for i in range(1000):\n",
    "    s = env.reset()\n",
    "    counts[epg.sample_action(s)] += 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec5e94e0b03f8aec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d1a12cc97386fe56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we will implement the function 'train' that samples a batch from the memory and performs a gradient step using some convenient PyTorch functionality. However, you still need to compute the Q-values for the (state, action) pairs in the experience, as well as their target (e.g. the value they should move towards). What is the target for a Q-learning update? What should be the target if `next_state` is terminal (e.g. `done`)?\n",
    "\n",
    "For computing the Q-values for the actions, note that the model returns all action values where you are only interested in a single action value. Because of the batch dimension, you can't use simple indexing, but you may want to have a look at [torch.gather](https://pytorch.org/docs/stable/torch.html?highlight=gather#torch.gather) or use [advanced indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html) (numpy tutorial but works mostly the same in PyTorch). Note, you should NOT modify the function train. You can view the size of a tensor `x` with `x.size()` (similar to `x.shape` in numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c45485324b40081",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def compute_q_vals(Q, states, actions):\n",
    "    \"\"\"\n",
    "    This method returns Q values for given state action pairs.\n",
    "    \n",
    "    Args:\n",
    "        Q: Q-net\n",
    "        states: a tensor of states. Shape: batch_size x obs_dim\n",
    "        actions: a tensor of actions. Shape: Shape: batch_size x 1\n",
    "\n",
    "    Returns:\n",
    "        A torch tensor filled with Q values. Shape: batch_size x 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    Q_values = Q(states).gather(1, actions)\n",
    "    return Q_values\n",
    "\n",
    "    \n",
    "def compute_targets(Q, rewards, next_states, dones, discount_factor):\n",
    "    \"\"\"\n",
    "    This method returns targets (values towards which Q-values should move).\n",
    "    \n",
    "    Args:\n",
    "        Q: Q-net\n",
    "        rewards: a tensor of rewards. Shape: Shape: batch_size x 1\n",
    "        next_states: a tensor of states. Shape: batch_size x obs_dim\n",
    "        dones: a tensor of boolean done flags (indicates if next_state is terminal) Shape: batch_size x 1\n",
    "        discount_factor: discount\n",
    "    Returns:\n",
    "        A torch tensor filled with target values. Shape: batch_size x 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    max_next_Q = Q(next_states).max(1)[0][:, None]\n",
    "    bool_mask = torch.logical_not(dones)\n",
    "    targets = rewards + discount_factor * max_next_Q * bool_mask\n",
    "\n",
    "    return targets\n",
    "\n",
    "def train(Q, memory, optimizer, batch_size, discount_factor):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "    \n",
    "    # don't learn without some decent experience\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "\n",
    "    # random transition batch is taken from experience replay memory\n",
    "    transitions = memory.sample(batch_size)\n",
    "    \n",
    "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
    "    state, action, reward, next_state, done = zip(*transitions)\n",
    "    \n",
    "    # convert to PyTorch and define types\n",
    "    state = torch.tensor(state, dtype=torch.float)\n",
    "    action = torch.tensor(action, dtype=torch.int64)[:, None]  # Need 64 bit to use them as index\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float)\n",
    "    reward = torch.tensor(reward, dtype=torch.float)[:, None]\n",
    "    done = torch.tensor(done, dtype=torch.uint8)[:, None]  # Boolean\n",
    "    \n",
    "    # compute the q value\n",
    "    q_val = compute_q_vals(Q, state, action)\n",
    "    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n",
    "        target = compute_targets(Q, reward, next_state, done, discount_factor)\n",
    "    \n",
    "    # loss is measured from error between current and newly expected Q values\n",
    "    loss = F.smooth_l1_loss(q_val, target)\n",
    "\n",
    "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()  # Returns a Python scalar, and releases history (similar to .detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b060b822eec4282f",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5607788562774658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/miniconda3/envs/rlcourse/lib/python3.7/site-packages/ipykernel_launcher.py:54: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /croot/pytorch_1675190298929/work/torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    }
   ],
   "source": [
    "# You may want to test your functions individually, but after you do so lets see if the method train works.\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "# Simple gradient descent may take long, so we will use Adam\n",
    "optimizer = optim.Adam(Q_net.parameters(), learn_rate)\n",
    "\n",
    "# We need a larger memory, fill with dummy data\n",
    "transition = memory.sample(1)[0]\n",
    "memory = ReplayMemory(10 * batch_size)\n",
    "for i in range(batch_size):\n",
    "    memory.push(transition)\n",
    "\n",
    "# Now let's see if it works\n",
    "loss = train(Q_net, memory, optimizer, batch_size, discount_factor)\n",
    "\n",
    "print (loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3eafd0ab49103f3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-36b8a04b393d8104",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now that you have implemented the training step, you should be able to put everything together. Implement the function `run_episodes` that runs a number of episodes of DQN training. It should return the durations (e.g. number of steps) of each episode. Note: we pass the train function as an argument such that we can swap it for a different training step later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-540a7d50ecc1d046",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def run_episodes(train, Q, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate):\n",
    "    \n",
    "    optimizer = optim.Adam(Q.parameters(), learn_rate)\n",
    "    \n",
    "    global_steps = 0  # Count the steps (do not reset at episode start, to compute epsilon)\n",
    "    episode_durations = []  #\n",
    "    for i in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        \n",
    "        steps = 0\n",
    "        while True:\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            action = policy.sample_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.push((state, action, reward, next_state, done))\n",
    "            train(Q, memory, optimizer, batch_size, discount_factor)\n",
    "            state = next_state\n",
    "            steps += 1\n",
    "            \n",
    "            if done:\n",
    "                if i % 10 == 0:\n",
    "                    print(\"{2} Episode {0} finished after {1} steps\"\n",
    "                          .format(i, steps, '\\033[92m' if steps >= 195 else '\\033[99m'))\n",
    "                episode_durations.append(steps)\n",
    "                break\n",
    "    return episode_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 0 finished after 10 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 10 finished after 8 steps\n",
      "\u001b[99m Episode 20 finished after 9 steps\n",
      "\u001b[99m Episode 30 finished after 9 steps\n",
      "\u001b[99m Episode 40 finished after 11 steps\n",
      "\u001b[99m Episode 50 finished after 10 steps\n",
      "\u001b[99m Episode 60 finished after 10 steps\n",
      "\u001b[99m Episode 70 finished after 12 steps\n",
      "\u001b[99m Episode 80 finished after 15 steps\n",
      "\u001b[99m Episode 90 finished after 11 steps\n"
     ]
    }
   ],
   "source": [
    "# Let's run it!\n",
    "num_episodes = 100\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "memory = ReplayMemory(10000)\n",
    "num_hidden = 128\n",
    "seed = 42  # This is not randomly chosen\n",
    "\n",
    "# We will seed the algorithm (before initializing QNetwork!) for reproducibility\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "\n",
    "Q_net = QNetwork(num_hidden)\n",
    "policy = EpsilonGreedyPolicy(Q_net, 0.05)\n",
    "episode_durations = run_episodes(train, Q_net, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-928ecc11ed5c43d8",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Episode durations per episode')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And see the results\n",
    "def smooth(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "plt.plot(smooth(episode_durations, 10))\n",
    "plt.title('Episode durations per episode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "rlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
