{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Deep Q Network\n",
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports %%execwritefile command (executes cell and writes it into file). \n",
    "# All cells that start with %%execwritefile should be in td_autograde.py file after running all cells.\n",
    "\n",
    "from custommagics import CustomMagics\n",
    "get_ipython().register_magics(CustomMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile dqn_autograde.py\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc69f22067705372",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 7, 0), \"Make sure you have Python 3.7 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fef7e20e54e6243b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1. Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-39519f4ab05eb2a1",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/miniconda3/envs/rlcourse/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.envs.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        CartPoleEnv\n",
      "\u001b[0;31mString form:\u001b[0m <CartPoleEnv<CartPole-v1>>\n",
      "\u001b[0;31mFile:\u001b[0m        ~/miniconda3/envs/rlcourse/lib/python3.7/site-packages/gym/envs/classic_control/cartpole.py\n",
      "\u001b[0;31mSource:\u001b[0m     \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mCartPoleEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m    Description:\u001b[0m\n",
      "\u001b[0;34m        A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum starts upright, and the goal is to prevent it from falling over by increasing and reducing the cart's velocity.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Source:\u001b[0m\n",
      "\u001b[0;34m        This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Observation: \u001b[0m\n",
      "\u001b[0;34m        Type: Box(4)\u001b[0m\n",
      "\u001b[0;34m        Num     Observation                 Min         Max\u001b[0m\n",
      "\u001b[0;34m        0       Cart Position             -4.8            4.8\u001b[0m\n",
      "\u001b[0;34m        1       Cart Velocity             -Inf            Inf\u001b[0m\n",
      "\u001b[0;34m        2       Pole Angle                 -24°           24°\u001b[0m\n",
      "\u001b[0;34m        3       Pole Velocity At Tip      -Inf            Inf\u001b[0m\n",
      "\u001b[0;34m        \u001b[0m\n",
      "\u001b[0;34m    Actions:\u001b[0m\n",
      "\u001b[0;34m        Type: Discrete(2)\u001b[0m\n",
      "\u001b[0;34m        Num     Action\u001b[0m\n",
      "\u001b[0;34m        0       Push cart to the left\u001b[0m\n",
      "\u001b[0;34m        1       Push cart to the right\u001b[0m\n",
      "\u001b[0;34m        \u001b[0m\n",
      "\u001b[0;34m        Note: The amount the velocity is reduced or increased is not fixed as it depends on the angle the pole is pointing. This is because the center of gravity of the pole increases the amount of energy needed to move the cart underneath it\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Reward:\u001b[0m\n",
      "\u001b[0;34m        Reward is 1 for every step taken, including the termination step\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Starting State:\u001b[0m\n",
      "\u001b[0;34m        All observations are assigned a uniform random value between ±0.05\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Episode Termination:\u001b[0m\n",
      "\u001b[0;34m        Pole Angle is more than ±12°\u001b[0m\n",
      "\u001b[0;34m        Cart Position is more than ±2.4 (center of the cart reaches the edge of the display)\u001b[0m\n",
      "\u001b[0;34m        Episode length is greater than 200\u001b[0m\n",
      "\u001b[0;34m        Solved Requirements\u001b[0m\n",
      "\u001b[0;34m        Considered solved when the average reward is greater than or equal to 195.0 over 100 consecutive trials.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'render.modes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'video.frames_per_second'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9.8\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasscart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasscart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;31m# actually half the pole's length\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.02\u001b[0m  \u001b[0;31m# seconds between state updates\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'euler'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Angle at which to fail the episode\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.4\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Angle limit set to 2 * theta_threshold_radians so failing observation is still within bounds\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mhigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%r (%s) invalid\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mforce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcostheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msintheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msintheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mthetaacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msintheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcostheta\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mxacc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'euler'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# semi-implicit euler\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta_dot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Pole just fell!\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscreen_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscreen_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mworld_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscreen_width\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mworld_width\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcarty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;31m# TOP OF CART\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpolewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpolelen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0maxleoffset\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolelen\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxleoffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_circle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;31m# MIDDLE OF CART\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcartx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# env is a TimeLimit wrapper around an env, so use env.env to look into the env (but otherwise you can forget about this)\n",
    "??env.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nice thing about the CARTPOLE is that it has very nice rendering functionality (if you are on a local environment). Let's have a look at an episode\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "done = False\n",
    "while not done:\n",
    "    obs, reward, done, _ = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "env.close() # Close the environment or you will have a lot of render screens soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2d83f70e62b99520",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Remember from the previous lab, that in order to optimize a policy we need to estimate the Q-values (e.g. estimate the *action* values). In the CartPole problem, our state is the current position of the cart, the current velocity of the cart, the current (angular) position of the pole and the (angular) speed of the pole. As these are continuous variables, we have an infinite number of states (ignoring the fact that a digital computer can only represent finitely many states in finite memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b3162496f5e6cf5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.1 Implement Q-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96a86bcfa1ebc84a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We will not use the tabular approach but approximate the Q-value function by a general approximator function. We will skip the linear case and directly use a two layer Neural Network. We use [PyTorch](https://pytorch.org/) to implement the network, as this will allow us to train it easily later. We can implement a model using `torch.nn.Sequential`, but with PyTorch it is actually very easy to implement the model (e.g. the forward pass) from scratch. Now implement the `QNetwork.forward` function that uses one hidden layer with ReLU activation (no output activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-216429a5dccf8a0e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_hidden=128):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-00ce108d640a5942",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's instantiate and test if it works\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1)\n",
    "Q_net = QNetwork(num_hidden)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "test_model = nn.Sequential(\n",
    "    nn.Linear(4, num_hidden), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(num_hidden, 2)\n",
    ")\n",
    "\n",
    "x = torch.rand(10, 4)\n",
    "\n",
    "# If you do not need backpropagation, wrap the computation in the torch.no_grad() context\n",
    "# This saves time and memory, and PyTorch complains when converting to numpy\n",
    "with torch.no_grad():\n",
    "    assert np.allclose(Q_net(x).numpy(), test_model(x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ca77eae2e62180cf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.2 Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2c1d117a1a75fd69",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to stabilize learning, we will use an experience replay to save states in and sample states from. Now implement the `push` function that adds a transition to the replay buffer, and the `sample` function that samples a (random!) batch of data, for use during training (hint: you can use the function `random.sample`). It should keep at most the maximum number of transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a3cc876e51eb157f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, transition):\n",
    "        # YOUR CODE HERE\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # YOUR CODE HERE\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3b90135921c4da76",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([-0.02175903,  0.02946337, -0.03467368, -0.01081389]), 0, 1.0, array([-0.02116976, -0.1651446 , -0.03488996,  0.27073058]), False)]\n"
     ]
    }
   ],
   "source": [
    "capacity = 10\n",
    "memory = ReplayMemory(capacity)\n",
    "\n",
    "# Sample a transition\n",
    "s = env.reset()\n",
    "a = env.action_space.sample()\n",
    "s_next, r, done, _ = env.step(a)\n",
    "\n",
    "# Push a transition\n",
    "memory.push((s, a, r, s_next, done))\n",
    "\n",
    "# Sample a batch size of 1\n",
    "print(memory.sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88f67e3c051da6a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.3 $\\epsilon$psilon Greedy Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aa3c7d1b3000f697",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to learn a good policy, we need to explore quite a bit initially. As we start to learn a good policy, we want to decrease the exploration. As the amount of exploration using an $\\epsilon$-greedy policy is controlled by $\\epsilon$, we can define an 'exploration scheme' by writing $\\epsilon$ as a function of time. There are many possible schemes, but we will use a simple one: we will start with only exploring (so taking random actions) at iteration 0, and then in 1000 iterations linearly anneal $\\epsilon$ such that after 1000 iterations we take random (exploration) actions with 5\\% probability (forever, as you never know if the environment will change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5789e7a792108576",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n",
      "0.050000000000000044\n",
      "0.525\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def get_epsilon(it):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    epsilon = max(1.0 - (it / 1000) * (1.0 - 0.05), 0.05)\n",
    "    return epsilon\n",
    "\n",
    "print(get_epsilon(1000))\n",
    "print(get_epsilon(500))\n",
    "print(get_epsilon(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-40e66db45e742b2e",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x708c416e60d0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So what's an easy way to check?\n",
    "plt.plot([get_epsilon(it) for it in range(5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8b604c9998c6c3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now write a function of *EpsilonGreedyPolicy* class. This function takes a state and uses the Q-network to select an ($\\epsilon$-greedy) action. It should return a random action with probability epsilon. Note, you do not need to backpropagate through the model computations, so use `with torch.no_grad():` (see above for example). Note that to convert a PyTorch tensor with only 1 element (0 dimensional) to a simple python scalar (int or float), you can use the '.item()' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-878ad3a637cfb51c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class EpsilonGreedyPolicy(object):\n",
    "    \"\"\"\n",
    "    A simple epsilon greedy policy.\n",
    "    \"\"\"\n",
    "    def __init__(self, Q, epsilon):\n",
    "        self.Q = Q\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def sample_action(self, obs):\n",
    "        \"\"\"\n",
    "        This method takes a state as input and returns an action sampled from this policy.  \n",
    "\n",
    "        Args:\n",
    "            obs: current state\n",
    "\n",
    "        Returns:\n",
    "            An action (int).\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        with torch.no_grad():\n",
    "            # Exploratory action\n",
    "            if np.random.rand() < self.epsilon:\n",
    "                action = np.random.randint(2)\n",
    "            # Greedy action\n",
    "            else:\n",
    "                action = torch.argmax(self.Q(torch.tensor(obs).float())).item()\n",
    "        \n",
    "        return action\n",
    "        \n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e895338d56bee477",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "epg = EpsilonGreedyPolicy(Q_net, 0.05)\n",
    "a = epg.sample_action(s)\n",
    "assert not torch.is_tensor(a)\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 972, 1: 28}\n"
     ]
    }
   ],
   "source": [
    "counts = {0: 0, 1: 0}\n",
    "for i in range(1000):\n",
    "    s = env.reset()\n",
    "    counts[epg.sample_action(s)] += 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec5e94e0b03f8aec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d1a12cc97386fe56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we will implement the function 'train' that samples a batch from the memory and performs a gradient step using some convenient PyTorch functionality. However, you still need to compute the Q-values for the (state, action) pairs in the experience, as well as their target (e.g. the value they should move towards). What is the target for a Q-learning update? What should be the target if `next_state` is terminal (e.g. `done`)?\n",
    "\n",
    "For computing the Q-values for the actions, note that the model returns all action values where you are only interested in a single action value. Because of the batch dimension, you can't use simple indexing, but you may want to have a look at [torch.gather](https://pytorch.org/docs/stable/torch.html?highlight=gather#torch.gather) or use [advanced indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html) (numpy tutorial but works mostly the same in PyTorch). Note, you should NOT modify the function train. You can view the size of a tensor `x` with `x.size()` (similar to `x.shape` in numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c45485324b40081",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def compute_q_vals(Q, states, actions):\n",
    "    \"\"\"\n",
    "    This method returns Q values for given state action pairs.\n",
    "    \n",
    "    Args:\n",
    "        Q: Q-net\n",
    "        states: a tensor of states. Shape: batch_size x obs_dim\n",
    "        actions: a tensor of actions. Shape: Shape: batch_size x 1\n",
    "\n",
    "    Returns:\n",
    "        A torch tensor filled with Q values. Shape: batch_size x 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    Q_values = Q(states).gather(1, actions)\n",
    "    return Q_values\n",
    "\n",
    "    \n",
    "def compute_targets(Q, rewards, next_states, dones, discount_factor):\n",
    "    \"\"\"\n",
    "    This method returns targets (values towards which Q-values should move).\n",
    "    \n",
    "    Args:\n",
    "        Q: Q-net\n",
    "        rewards: a tensor of rewards. Shape: Shape: batch_size x 1\n",
    "        next_states: a tensor of states. Shape: batch_size x obs_dim\n",
    "        dones: a tensor of boolean done flags (indicates if next_state is terminal) Shape: batch_size x 1\n",
    "        discount_factor: discount\n",
    "    Returns:\n",
    "        A torch tensor filled with target values. Shape: batch_size x 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    max_next_Q = Q(next_states).max(1)[0][:, None]\n",
    "    bool_mask = torch.logical_not(dones)\n",
    "    targets = rewards + discount_factor * max_next_Q * bool_mask\n",
    "\n",
    "    return targets\n",
    "\n",
    "def train(Q, memory, optimizer, batch_size, discount_factor):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "    \n",
    "    # don't learn without some decent experience\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "\n",
    "    # random transition batch is taken from experience replay memory\n",
    "    transitions = memory.sample(batch_size)\n",
    "    \n",
    "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
    "    state, action, reward, next_state, done = zip(*transitions)\n",
    "    \n",
    "    # convert to PyTorch and define types\n",
    "    state = torch.tensor(state, dtype=torch.float)\n",
    "    action = torch.tensor(action, dtype=torch.int64)[:, None]  # Need 64 bit to use them as index\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float)\n",
    "    reward = torch.tensor(reward, dtype=torch.float)[:, None]\n",
    "    done = torch.tensor(done, dtype=torch.uint8)[:, None]  # Boolean\n",
    "    \n",
    "    # compute the q value\n",
    "    q_val = compute_q_vals(Q, state, action)\n",
    "    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n",
    "        target = compute_targets(Q, reward, next_state, done, discount_factor)\n",
    "    \n",
    "    # loss is measured from error between current and newly expected Q values\n",
    "    loss = F.smooth_l1_loss(q_val, target)\n",
    "\n",
    "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()  # Returns a Python scalar, and releases history (similar to .detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b060b822eec4282f",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4567742645740509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/miniconda3/envs/rlcourse/lib/python3.7/site-packages/ipykernel_launcher.py:54: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /croot/pytorch_1675190298929/work/torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    }
   ],
   "source": [
    "# You may want to test your functions individually, but after you do so lets see if the method train works.\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "# Simple gradient descent may take long, so we will use Adam\n",
    "optimizer = optim.Adam(Q_net.parameters(), learn_rate)\n",
    "\n",
    "# We need a larger memory, fill with dummy data\n",
    "transition = memory.sample(1)[0]\n",
    "memory = ReplayMemory(10 * batch_size)\n",
    "for i in range(batch_size):\n",
    "    memory.push(transition)\n",
    "\n",
    "# Now let's see if it works\n",
    "loss = train(Q_net, memory, optimizer, batch_size, discount_factor)\n",
    "\n",
    "print (loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3eafd0ab49103f3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-36b8a04b393d8104",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now that you have implemented the training step, you should be able to put everything together. Implement the function `run_episodes` that runs a number of episodes of DQN training. It should return the durations (e.g. number of steps) of each episode. Note: we pass the train function as an argument such that we can swap it for a different training step later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-540a7d50ecc1d046",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def run_episodes(train, Q, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate):\n",
    "    \n",
    "    optimizer = optim.Adam(Q.parameters(), learn_rate)\n",
    "    \n",
    "    global_steps = 0  # Count the steps (do not reset at episode start, to compute epsilon)\n",
    "    episode_durations = []  #\n",
    "    for i in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        \n",
    "        steps = 0\n",
    "        while True:\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            action = policy.sample_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.push((state, action, reward, next_state, done))\n",
    "            train(Q, memory, optimizer, batch_size, discount_factor)\n",
    "            state = next_state\n",
    "            steps += 1\n",
    "            \n",
    "            if done:\n",
    "                if i % 10 == 0:\n",
    "                    print(\"{2} Episode {0} finished after {1} steps\"\n",
    "                          .format(i, steps, '\\033[92m' if steps >= 195 else '\\033[99m'))\n",
    "                episode_durations.append(steps)\n",
    "                break\n",
    "    return episode_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 0 finished after 12 steps\n",
      "\u001b[99m Episode 10 finished after 12 steps\n",
      "\u001b[99m Episode 20 finished after 9 steps\n",
      "\u001b[99m Episode 30 finished after 8 steps\n",
      "\u001b[99m Episode 40 finished after 8 steps\n",
      "\u001b[99m Episode 50 finished after 10 steps\n",
      "\u001b[99m Episode 60 finished after 11 steps\n",
      "\u001b[99m Episode 70 finished after 11 steps\n",
      "\u001b[99m Episode 80 finished after 12 steps\n",
      "\u001b[99m Episode 90 finished after 13 steps\n"
     ]
    }
   ],
   "source": [
    "# Let's run it!\n",
    "num_episodes = 100\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "memory = ReplayMemory(10000)\n",
    "num_hidden = 128\n",
    "seed = 42  # This is not randomly chosen\n",
    "\n",
    "# We will seed the algorithm (before initializing QNetwork!) for reproducibility\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "\n",
    "Q_net = QNetwork(num_hidden)\n",
    "policy = EpsilonGreedyPolicy(Q_net, 0.05)\n",
    "episode_durations = run_episodes(train, Q_net, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-928ecc11ed5c43d8",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Episode durations per episode')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And see the results\n",
    "def smooth(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "plt.plot(smooth(episode_durations, 10))\n",
    "plt.title('Episode durations per episode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "rlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
