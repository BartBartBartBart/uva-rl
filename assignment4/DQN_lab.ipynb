{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Deep Q Network\n",
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports %%execwritefile command (executes cell and writes it into file). \n",
    "# All cells that start with %%execwritefile should be in td_autograde.py file after running all cells.\n",
    "\n",
    "from custommagics import CustomMagics\n",
    "get_ipython().register_magics(CustomMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile dqn_autograde.py\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc69f22067705372",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 7, 0), \"Make sure you have Python 3.7 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fef7e20e54e6243b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1. Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-39519f4ab05eb2a1",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/miniconda3/envs/rlcourse/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.envs.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        CartPoleEnv\n",
      "\u001b[0;31mString form:\u001b[0m <CartPoleEnv<CartPole-v1>>\n",
      "\u001b[0;31mFile:\u001b[0m        ~/miniconda3/envs/rlcourse/lib/python3.7/site-packages/gym/envs/classic_control/cartpole.py\n",
      "\u001b[0;31mSource:\u001b[0m     \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mCartPoleEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m    Description:\u001b[0m\n",
      "\u001b[0;34m        A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum starts upright, and the goal is to prevent it from falling over by increasing and reducing the cart's velocity.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Source:\u001b[0m\n",
      "\u001b[0;34m        This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Observation: \u001b[0m\n",
      "\u001b[0;34m        Type: Box(4)\u001b[0m\n",
      "\u001b[0;34m        Num     Observation                 Min         Max\u001b[0m\n",
      "\u001b[0;34m        0       Cart Position             -4.8            4.8\u001b[0m\n",
      "\u001b[0;34m        1       Cart Velocity             -Inf            Inf\u001b[0m\n",
      "\u001b[0;34m        2       Pole Angle                 -24°           24°\u001b[0m\n",
      "\u001b[0;34m        3       Pole Velocity At Tip      -Inf            Inf\u001b[0m\n",
      "\u001b[0;34m        \u001b[0m\n",
      "\u001b[0;34m    Actions:\u001b[0m\n",
      "\u001b[0;34m        Type: Discrete(2)\u001b[0m\n",
      "\u001b[0;34m        Num     Action\u001b[0m\n",
      "\u001b[0;34m        0       Push cart to the left\u001b[0m\n",
      "\u001b[0;34m        1       Push cart to the right\u001b[0m\n",
      "\u001b[0;34m        \u001b[0m\n",
      "\u001b[0;34m        Note: The amount the velocity is reduced or increased is not fixed as it depends on the angle the pole is pointing. This is because the center of gravity of the pole increases the amount of energy needed to move the cart underneath it\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Reward:\u001b[0m\n",
      "\u001b[0;34m        Reward is 1 for every step taken, including the termination step\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Starting State:\u001b[0m\n",
      "\u001b[0;34m        All observations are assigned a uniform random value between ±0.05\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Episode Termination:\u001b[0m\n",
      "\u001b[0;34m        Pole Angle is more than ±12°\u001b[0m\n",
      "\u001b[0;34m        Cart Position is more than ±2.4 (center of the cart reaches the edge of the display)\u001b[0m\n",
      "\u001b[0;34m        Episode length is greater than 200\u001b[0m\n",
      "\u001b[0;34m        Solved Requirements\u001b[0m\n",
      "\u001b[0;34m        Considered solved when the average reward is greater than or equal to 195.0 over 100 consecutive trials.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'render.modes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'video.frames_per_second'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9.8\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasscart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasscart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;31m# actually half the pole's length\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.02\u001b[0m  \u001b[0;31m# seconds between state updates\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'euler'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Angle at which to fail the episode\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.4\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Angle limit set to 2 * theta_threshold_radians so failing observation is still within bounds\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mhigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%r (%s) invalid\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mforce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcostheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msintheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msintheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mthetaacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msintheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcostheta\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mxacc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'euler'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# semi-implicit euler\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta_dot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Pole just fell!\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscreen_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscreen_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mworld_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscreen_width\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mworld_width\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcarty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;31m# TOP OF CART\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpolewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpolelen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0maxleoffset\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolelen\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxleoffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_circle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;31m# MIDDLE OF CART\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcartx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# env is a TimeLimit wrapper around an env, so use env.env to look into the env (but otherwise you can forget about this)\n",
    "??env.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nice thing about the CARTPOLE is that it has very nice rendering functionality (if you are on a local environment). Let's have a look at an episode\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "done = False\n",
    "while not done:\n",
    "    obs, reward, done, _ = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "env.close() # Close the environment or you will have a lot of render screens soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2d83f70e62b99520",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Remember from the previous lab, that in order to optimize a policy we need to estimate the Q-values (e.g. estimate the *action* values). In the CartPole problem, our state is the current position of the cart, the current velocity of the cart, the current (angular) position of the pole and the (angular) speed of the pole. As these are continuous variables, we have an infinite number of states (ignoring the fact that a digital computer can only represent finitely many states in finite memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b3162496f5e6cf5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.1 Implement Q-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96a86bcfa1ebc84a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We will not use the tabular approach but approximate the Q-value function by a general approximator function. We will skip the linear case and directly use a two layer Neural Network. We use [PyTorch](https://pytorch.org/) to implement the network, as this will allow us to train it easily later. We can implement a model using `torch.nn.Sequential`, but with PyTorch it is actually very easy to implement the model (e.g. the forward pass) from scratch. Now implement the `QNetwork.forward` function that uses one hidden layer with ReLU activation (no output activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-216429a5dccf8a0e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_hidden=128):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-00ce108d640a5942",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's instantiate and test if it works\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1)\n",
    "Q_net = QNetwork(num_hidden)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "test_model = nn.Sequential(\n",
    "    nn.Linear(4, num_hidden), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(num_hidden, 2)\n",
    ")\n",
    "\n",
    "x = torch.rand(10, 4)\n",
    "\n",
    "# If you do not need backpropagation, wrap the computation in the torch.no_grad() context\n",
    "# This saves time and memory, and PyTorch complains when converting to numpy\n",
    "with torch.no_grad():\n",
    "    assert np.allclose(Q_net(x).numpy(), test_model(x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ca77eae2e62180cf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.2 Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2c1d117a1a75fd69",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to stabilize learning, we will use an experience replay to save states in and sample states from. Now implement the `push` function that adds a transition to the replay buffer, and the `sample` function that samples a (random!) batch of data, for use during training (hint: you can use the function `random.sample`). It should keep at most the maximum number of transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a3cc876e51eb157f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, transition):\n",
    "        # YOUR CODE HERE\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # YOUR CODE HERE\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3b90135921c4da76",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([ 0.01585099,  0.03579416, -0.01259527,  0.02976086]), 1, 1.0, array([ 0.01656688,  0.23109445, -0.01200005, -0.26686925]), False)]\n"
     ]
    }
   ],
   "source": [
    "capacity = 10\n",
    "memory = ReplayMemory(capacity)\n",
    "\n",
    "# Sample a transition\n",
    "s = env.reset()\n",
    "a = env.action_space.sample()\n",
    "s_next, r, done, _ = env.step(a)\n",
    "\n",
    "# Push a transition\n",
    "memory.push((s, a, r, s_next, done))\n",
    "\n",
    "# Sample a batch size of 1\n",
    "print(memory.sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88f67e3c051da6a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.3 $\\epsilon$psilon Greedy Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aa3c7d1b3000f697",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to learn a good policy, we need to explore quite a bit initially. As we start to learn a good policy, we want to decrease the exploration. As the amount of exploration using an $\\epsilon$-greedy policy is controlled by $\\epsilon$, we can define an 'exploration scheme' by writing $\\epsilon$ as a function of time. There are many possible schemes, but we will use a simple one: we will start with only exploring (so taking random actions) at iteration 0, and then in 1000 iterations linearly anneal $\\epsilon$ such that after 1000 iterations we take random (exploration) actions with 5\\% probability (forever, as you never know if the environment will change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5789e7a792108576",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def get_epsilon(it):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    epsilon = max(1.0 - (it / 1000) * (1.0 - 0.05), 0.05)\n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-40e66db45e742b2e",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x78fa440122d0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsCUlEQVR4nO3de1DV953/8dc5BzgowkFAURQVL0lNTIxiVRC2bdLS2iQ7+W1nYjeZ2Esyv7qTm7HNTI0zMc1mfmQ724zb7Wq6m8tuZ7KJ0ybpZKY2GzrbKIrGSKAxalIVI6gggnBAkOv5/P7AcxICKAfO4XMuz8fMmanf8/2e8+ajKa/5ft6fz9dhjDECAACwxGm7AAAAEN8IIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsSrBdwGj4fD6dO3dOqampcjgctssBAACjYIxRe3u7cnJy5HSOfP8jKsLIuXPnlJuba7sMAAAwBnV1dZo9e/aI70dFGElNTZU08MOkpaVZrgYAAIxGW1ubcnNzA7/HRxIVYcQ/NZOWlkYYAQAgylyrxYIGVgAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGBV0GFkz549uvPOO5WTkyOHw6Hf//7317xm9+7dys/PV3JysubPn6/nn39+LLUCAIAYFHQY6ejo0NKlS/WrX/1qVOefOnVK3/72t1VcXKyqqio98cQTeuSRR/T6668HXSwAAIg9QT+bZu3atVq7du2oz3/++ec1Z84cbdu2TZK0ePFiHTp0SP/8z/+s73znO8F+PQAAiDFh7xnZv3+/SkpKBh375je/qUOHDqm3t3fYa7q7u9XW1jboFQ5/PFyvTTurdeScNyyfDwAAri3sYaShoUHZ2dmDjmVnZ6uvr09NTU3DXlNaWiqPxxN45ebmhqW2N6vO6o2qs3r3kwth+XwAAHBtE7Ka5ouPDjbGDHvcb/PmzfJ6vYFXXV1dWOoqXpQlSSo/ThgBAMCWoHtGgjVjxgw1NDQMOtbY2KiEhARlZmYOe43b7Zbb7Q53aSpaNE2SVHm6RZ09fZqcFPbhAAAAXxD2OyMFBQUqKysbdOydd97RihUrlJiYGO6vv6p5mZM1K32SevuNDp66aLUWAADiVdBh5NKlS6qurlZ1dbWkgaW71dXVqq2tlTQwxbJ+/frA+Rs2bNDp06e1adMmHTt2TC+99JJefPFF/eQnPwnNTzAODodDRQsHpmr2Hh++fwUAAIRX0GHk0KFDWrZsmZYtWyZJ2rRpk5YtW6Ynn3xSklRfXx8IJpKUl5enXbt26d1339Utt9yif/zHf9Qvf/nLiFnWW3Slb2TvCcIIAAA2OIy/mzSCtbW1yePxyOv1Ki0tLaSffbGjR/nPlMkY6eCW2zQ9NTmknw8AQLwa7e/vuH82TUZKkm7MGRigfdwdAQBgwsV9GJGkooUDq2r2Hm+2XAkAAPGHMCJ91sR64oKiYNYKAICYQhiRtGLeVLkTnDrf1q0TjZdslwMAQFwhjEhKTnRpZV6GJKmcJb4AAEwowsgVn03VEEYAAJhIhJEr/PuNHKhpVm+/z3I1AADED8LIFYtnpCkzJUmdPf2qqm21XQ4AAHGDMHKF0+lQYWBreJ7iCwDARCGMfE7xlTBSTt8IAAAThjDyOWuu9I38pa5V3su9lqsBACA+EEY+Z1b6JM3PSpHPDDSyAgCA8COMfEHgKb7sNwIAwIQgjHwB+40AADCxCCNfsHpBplxOh041dehMS6ftcgAAiHmEkS9IS07ULbnpkpiqAQBgIhBGhrGGqRoAACYMYWQYxVeaWCtONsvnM5arAQAgthFGhnFLbrqmuBN0saNHR+vbbJcDAEBMI4wMI9Hl1Or5GZKkcvpGAAAIK8LICPxLfPfRNwIAQFgRRkbg3/zs4KcX1dXbb7kaAABiF2FkBAumTdGMtGT19Pn0/qcXbZcDAEDMIoyMwOFwsDU8AAATgDByFf4lvjSxAgAQPoSRqyhcMBBGjta3qflSt+VqAACITYSRq5iW6taXZqRKkvadbLZcDQAAsYkwcg3Fgb6RC5YrAQAgNhFGrqFo0TRJA02sxrA1PAAAoUYYuYaV8zKU5HLqnLdLNU0dtssBACDmEEauYVKSS/lzp0piN1YAAMKBMDIKRSzxBQAgbAgjo+BvYj1wsll9/T7L1QAAEFsII6NwY45H6ZMT1d7dp7+cabVdDgAAMYUwMgoup0NrFjBVAwBAOBBGRmnNwoEwQhMrAAChRRgZJX/fSFVtqy5191muBgCA2EEYGaXcjMmamzlZfT6jA2wNDwBAyBBGglB0ZapmL1M1AACEDGEkCMWB/UZ4Tg0AAKFCGAlCwfwsOR3SyQsdqvdetl0OAAAxgTASBM/kRN00O13SwIPzAADA+BFGglRM3wgAACFFGAmS/zk1+040yeczlqsBACD6EUaCtHzOVE1KdKnpUo8+Od9uuxwAAKIeYSRISQlOrZqfIYm+EQAAQoEwMgb+/UbK6RsBAGDcCCNjULxomiTp4KlmdfX2W64GAIDoRhgZg+uyp2h6qltdvT59cLrFdjkAAEQ1wsgYOBwOtoYHACBECCNjtIYwAgBASBBGxsi/38jhs161dPRYrgYAgOhFGBmj7LRkXZc9RcZIFSebbZcDAEDUIoyMQ9HCgVU1e0/wFF8AAMaKMDIORYsyJdE3AgDAeBBGxmFVXqYSXQ7VXbys080dtssBACAqEUbGIcWdoGVzpkqSytkaHgCAMSGMjFOxf4kvYQQAgDEhjIyTf4lvxckm9fuM5WoAAIg+hJFxummWR6nJCWrr6tPhs17b5QAAEHXGFEa2b9+uvLw8JScnKz8/X+Xl5Vc9/5VXXtHSpUs1efJkzZw5Uz/4wQ/U3Bwbe3MkuJwqXHBlVc1xlvgCABCsoMPIzp07tXHjRm3ZskVVVVUqLi7W2rVrVVtbO+z5e/fu1fr163X//ffryJEj+u1vf6v3339fDzzwwLiLjxRFV57iSxMrAADBCzqMPPfcc7r//vv1wAMPaPHixdq2bZtyc3O1Y8eOYc8/cOCA5s2bp0ceeUR5eXkqKirSj370Ix06dGjcxUcKfxPrB7Ut6ujus1wNAADRJagw0tPTo8rKSpWUlAw6XlJSooqKimGvKSws1JkzZ7Rr1y4ZY3T+/Hn97ne/0+233z7i93R3d6utrW3QK5LNzZys2VMnqbff6OCpi7bLAQAgqgQVRpqamtTf36/s7OxBx7Ozs9XQ0DDsNYWFhXrllVe0bt06JSUlacaMGUpPT9e//uu/jvg9paWl8ng8gVdubm4wZU44h8OhIp7iCwDAmIypgdXhcAz6szFmyDG/o0eP6pFHHtGTTz6pyspKvf322zp16pQ2bNgw4udv3rxZXq838KqrqxtLmRPKv8SX/UYAAAhOQjAnZ2VlyeVyDbkL0tjYOORuiV9paanWrFmjxx9/XJJ08803KyUlRcXFxXrmmWc0c+bMIde43W653e5gSrNuzYIsORzSJ+fb1djWpelpybZLAgAgKgR1ZyQpKUn5+fkqKysbdLysrEyFhYXDXtPZ2Smnc/DXuFwuSQN3VGLF1JQkLcnxSGKqBgCAYAQ9TbNp0ya98MILeumll3Ts2DE99thjqq2tDUy7bN68WevXrw+cf+edd+qNN97Qjh07VFNTo3379umRRx7RypUrlZOTE7qfJAIEpmoIIwAAjFpQ0zSStG7dOjU3N+vpp59WfX29lixZol27dmnu3LmSpPr6+kF7jnz/+99Xe3u7fvWrX+nHP/6x0tPTdeutt+qf/umfQvdTRIiihVna8e5J7T3edNU+GgAA8BmHiYK5kra2Nnk8Hnm9XqWlpdkuZ0Rdvf1a+rN31N3n0zuP/Y2uy061XRIAANaM9vc3z6YJoeREl1bmZUhiN1YAAEaLMBJixYElvjynBgCA0SCMhNiaK5ufvXfqonr6fJarAQAg8hFGQmzxjDRlpiSps6dfVbUttssBACDiEUZCzOl0BO6OsMQXAIBrI4yEgX+/EZpYAQC4NsJIGPgfmvfhmVZ5O3stVwMAQGQjjIRBTvokzZ+WIp+R9tc02y4HAICIRhgJk+JA3whLfAEAuBrCSJgULZomSdpL3wgAAFdFGAmT1fMz5HI69Glzp+oudtouBwCAiEUYCZPU5EQty02XxBJfAACuhjASRuw3AgDAtRFGwsj/nJqKE03y+SL+4cgAAFhBGAmjpbnpmuJOUEtnr46ca7NdDgAAEYkwEkaJLqdWz8+UJJWzxBcAgGERRsLMP1Wzj74RAACGRRgJM38T6/uftqirt99yNQAARB7CSJgtmJaimZ5k9fT5dPDURdvlAAAQcQgjYeZwOAIPzmOJLwAAQxFGJkDRlb6RcraGBwBgCMLIBPD3jRyrb1PTpW7L1QAAEFkIIxMga4pbi2emSWJVDQAAX0QYmSD+Jb48xRcAgMEIIxPk802sxrA1PAAAfoSRCbIyL0NJCU7Ve7t08kKH7XIAAIgYhJEJkpzo0oq5UyXRNwIAwOcRRiYQS3wBABiKMDKBihdOkyQdqGlWb7/PcjUAAEQGwsgEujEnTVMnJ+pSd5/+UtdquxwAACICYWQCOZ0OFS5kqgYAgM8jjEww/xJfmlgBABhAGJlg/jBSVdeq9q5ey9UAAGAfYWSC5WZM1rzMyer3GR2ouWi7HAAArCOMWFAU2Br+guVKAACwjzBiQdGVJb7l9I0AAEAYsaFgQaacDqnmQofOtV62XQ4AAFYRRizwTErUzbPTJQ08OA8AgHhGGLGkONA3QhgBAMQ3wogln99vxOczlqsBAMAewogly+ZM1eQkl5o7evRxQ7vtcgAAsIYwYklSglOr8jIkSXtPsMQXABC/CCMWFS26ssSXvhEAQBwjjFjkb2I9eOqiunr7LVcDAIAdhBGLFk2foumpbnX3+VR5usV2OQAAWEEYscjhcARW1bDfCAAgXhFGLCtivxEAQJwjjFjmvzPy0TmvWjp6LFcDAMDEI4xYNj0tWddnp8oYad9J7o4AAOIPYSQCMFUDAIhnhJEI4J+qKT/eJGPYGh4AEF8IIxFg1fwMJbocOtt6WaebO22XAwDAhCKMRIDJSQlaPmeqJKmcJb4AgDhDGIkQxYG+EZ5TAwCIL4SRCOF/Tk3FyWb19fssVwMAwMQhjESIm2Z5lJacoPauPh0+67VdDgAAE4YwEiFcTocKF7DEFwAQfwgjEcS/3whNrACAeEIYiSD+Jtaq2hZ1dPdZrgYAgIlBGIkgczNTlJsxSb39Ru+darZdDgAAE2JMYWT79u3Ky8tTcnKy8vPzVV5eftXzu7u7tWXLFs2dO1dut1sLFizQSy+9NKaCY51/N9a9xwkjAID4kBDsBTt37tTGjRu1fft2rVmzRr/+9a+1du1aHT16VHPmzBn2mrvvvlvnz5/Xiy++qIULF6qxsVF9fUxDDKdo4TS9erBOe0+w3wgAID44TJAPQ1m1apWWL1+uHTt2BI4tXrxYd911l0pLS4ec//bbb+u73/2uampqlJGRMaYi29ra5PF45PV6lZaWNqbPiBYtHT1a/kyZjJHee+I2Zacl2y4JAIAxGe3v76CmaXp6elRZWamSkpJBx0tKSlRRUTHsNW+99ZZWrFihn//855o1a5auu+46/eQnP9Hly5dH/J7u7m61tbUNesWLqSlJummWRxJLfAEA8SGoMNLU1KT+/n5lZ2cPOp6dna2GhoZhr6mpqdHevXv10Ucf6c0339S2bdv0u9/9Tg8++OCI31NaWiqPxxN45ebmBlNm1PP3jexjiS8AIA6MqYHV4XAM+rMxZsgxP5/PJ4fDoVdeeUUrV67Ut7/9bT333HP6z//8zxHvjmzevFlerzfwqqurG0uZUSvQxHqiSUHOogEAEHWCCiNZWVlyuVxD7oI0NjYOuVviN3PmTM2aNUsejydwbPHixTLG6MyZM8Ne43a7lZaWNugVT/LnTVVyolON7d366/lLtssBACCsggojSUlJys/PV1lZ2aDjZWVlKiwsHPaaNWvW6Ny5c7p06bNfqn/961/ldDo1e/bsMZQc+9wJLq3My5QklfMUXwBAjAt6mmbTpk164YUX9NJLL+nYsWN67LHHVFtbqw0bNkgamGJZv3594Px77rlHmZmZ+sEPfqCjR49qz549evzxx/XDH/5QkyZNCt1PEmOKPzdVAwBALAt6n5F169apublZTz/9tOrr67VkyRLt2rVLc+fOlSTV19ertrY2cP6UKVNUVlamhx9+WCtWrFBmZqbuvvtuPfPMM6H7KWLQmith5L2ai+rp8ykpgc1yAQCxKeh9RmyIp31G/Hw+o5X/709qutSj1/7vaq2en2m7JAAAghKWfUYwcZxOR+DuCPuNAABiGWEkgvmX+JbTNwIAiGGEkQhWtGggjBw+0ypvZ6/lagAACA/CSASb6ZmkBdNS5DPS/hrujgAAYhNhJMIVL5omSSqnbwQAEKMIIxGuiP1GAAAxjjAS4VYvyFSC06HTzZ2qu9hpuxwAAEKOMBLhprgTtGxOuiSmagAAsYkwEgX8+43sY6oGABCDCCNRoPjKEt99J5vU74v4DXMBAAgKYSQKLJ2drlR3glo7e3XknNd2OQAAhBRhJAokuJxavWDg2TT0jQAAYg1hJEr4p2p4Tg0AINYQRqKEv4m18nSLLvf0W64GAIDQIYxEiflZKcrxJKun36eDn160XQ4AACFDGIkSDocj8OC8vccvWK4GAIDQIYxEkSKeUwMAiEGEkShSeGVFzccN7brQ3m25GgAAQoMwEkWyprh1w8w0SVLFSe6OAABiA2EkyviX+DJVAwCIFYSRKFP0uf1GjGFreABA9COMRJkvz8tQUoJTDW1dOnnhku1yAAAYN8JIlElOdOnL86ZKYjdWAEBsIIxEoaKFA0t8954gjAAAoh9hJAr5m1gP1FxUb7/PcjUAAIwPYSQK3TAzTRkpSbrU3afqulbb5QAAMC6EkSjkdDoCG6CxxBcAEO0II1Gq6MpTfPfRNwIAiHKEkSjl32+kuq5VbV29lqsBAGDsCCNRavbUycrLSlG/z+jAyWbb5QAAMGaEkSjmn6phiS8AIJoRRqLY57eGBwAgWhFGotjq+ZlyOqSapg6dbb1suxwAAMaEMBLFPJMStTQ3XZK0j7sjAIAoRRiJcsVX+kbK6RsBAEQpwkiUK1o08JyafSea5PMZy9UAABA8wkiUWzYnXSlJLl3s6NHR+jbb5QAAEDTCSJRLdDm1av7A1vDsxgoAiEaEkRjAfiMAgGhGGIkBxVf2Gzl46qK6evstVwMAQHAIIzFg4fQpyk5zq7vPp0OfttguBwCAoBBGYoDD4dAapmoAAFGKMBIj/FM1e09csFwJAADBIYzECP+dkSPn2nSxo8dyNQAAjB5hJEZMT03Wl2akyhiW+AIAogthJIYElvjynBoAQBQhjMSQNYs+a2I1hq3hAQDRgTASQ1blZSjJ5dTZ1sv6tLnTdjkAAIwKYSSGTE5K0PK56ZKkvcdZVQMAiA6EkRhTfOUpvuX0jQAAogRhJMb4m1j3n2xWX7/PcjUAAFwbYSTGLJnlkWdSotq7+/ThWa/tcgAAuCbCSIxxOR0qXJApiSW+AIDoQBiJQUWL2G8EABA9CCMxqHjhQBPrB7UtutTdZ7kaAACujjASg+ZkTtacjMnq8xm9V9NsuxwAAK6KMBKj/A/O28tzagAAEY4wEqOK6RsBAEQJwkiMKlyQKYdDOt54SQ3eLtvlAAAwIsJIjEqfnKSbZ3kkMVUDAIhsYwoj27dvV15enpKTk5Wfn6/y8vJRXbdv3z4lJCTolltuGcvXIkj+vpF9hBEAQAQLOozs3LlTGzdu1JYtW1RVVaXi4mKtXbtWtbW1V73O6/Vq/fr1uu2228ZcLIIT2G/kRJOMMZarAQBgeEGHkeeee07333+/HnjgAS1evFjbtm1Tbm6uduzYcdXrfvSjH+mee+5RQUHBmItFcPLnTtWkRJcutHfrk/PttssBAGBYQYWRnp4eVVZWqqSkZNDxkpISVVRUjHjdyy+/rJMnT2rr1q2j+p7u7m61tbUNeiF47gSXVuZlSGJVDQAgcgUVRpqamtTf36/s7OxBx7Ozs9XQ0DDsNcePH9dPf/pTvfLKK0pISBjV95SWlsrj8QReubm5wZSJz/Ev8S0njAAAItSYGlgdDsegPxtjhhyTpP7+ft1zzz362c9+puuuu27Un79582Z5vd7Aq66ubixlQp81sR48dVHdff2WqwEAYKjR3aq4IisrSy6Xa8hdkMbGxiF3SySpvb1dhw4dUlVVlR566CFJks/nkzFGCQkJeuedd3TrrbcOuc7tdsvtdgdTGkbwpRmpypriVtOlbn1wulUFV57oCwBApAjqzkhSUpLy8/NVVlY26HhZWZkKCwuHnJ+WlqbDhw+ruro68NqwYYOuv/56VVdXa9WqVeOrHtfkcDhUtHAggOw9ccFyNQAADBXUnRFJ2rRpk+677z6tWLFCBQUF+vd//3fV1tZqw4YNkgamWM6ePavf/OY3cjqdWrJkyaDrp0+fruTk5CHHET5Fi6bp99XntPd4kx7/pu1qAAAYLOgwsm7dOjU3N+vpp59WfX29lixZol27dmnu3LmSpPr6+mvuOYKJVXSlb+TDs161dvYofXKS5YoAAPiMw0TBblhtbW3yeDzyer1KS0uzXU5U+vpzu3Wi8ZJ23Ltca2+aabscAEAcGO3vb55NEyf8d0fK2RoeABBhCCNxwr/fCJufAQAiDWEkTqyan6kEp0O1FztV29xpuxwAAAIII3FiijtBy+dMlSSVs8QXABBBCCNxxL8b6z76RgAAEYQwEkeKFvnDSLP6fRG/iAoAECcII3Fk6WyPUpMT5L3cq4/Oem2XAwCAJMJIXElwOVUw3781PFM1AIDIQBiJM/4lvuXHaWIFAEQGwkic8TexfnC6VZ09fZarAQCAMBJ38rJSNCt9knr6fTp46qLtcgAAIIzEG4fDEdgant1YAQCRgDASh/xLfGliBQBEAsJIHCpcMLCi5uOGdjW2d1muBgAQ7wgjcShzils35gw8yrniRLPlagAA8Y4wEqeKAkt8maoBANhFGIlTxQunSZL2nrggY9gaHgBgD2EkTq2YN1XuBKfOt3XrROMl2+UAAOIYYSROJSe69OV5GZJYVQMAsIswEscCS3zpGwEAWEQYiWP+zc8O1DSrt99nuRoAQLwijMSxG2amKTMlSR09/aqqbbVdDgAgThFG4pjT6VBhYGt4nuILALCDMBLnihYO7MZKEysAwBbCSJwrWjSw38hfznjV1tVruRoAQDwijMS5WemTND8rRf0+o/0n2RoeADDxCCNgiS8AwCrCCAJLfOkbAQDYQBiBVi/IlMvp0KmmDp1p6bRdDgAgzhBGoLTkRC2d7ZEk7ePuCABgghFGIOmzVTXl9I0AACYYYQSSpOIrTawVJ5vl8xnL1QAA4glhBJKkW3LTlZLk0sWOHh2tb7NdDgAgjhBGIElKdDm1ej67sQIAJh5hBAHsNwIAsIEwggB/38jBTy+qq7ffcjUAgHhBGEHAgmlTNCMtWT19Pr3/6UXb5QAA4gRhBAEOh0Nr2I0VADDBCCMYpJi+EQDABCOMYBD/nZEj59rUfKnbcjUAgHhAGMEg01Ld+tKMVEnSvpPNlqsBAMQDwgiG+Gyq5oLlSgAA8YAwgiECTazHm2QMW8MDAMKLMIIhVuVlKsnl1Dlvl041ddguBwAQ4wgjGGJSkkv5c6dKYokvACD8CCMYln9r+HKW+AIAwowwgmH5m1gPnGxWX7/PcjUAgFhGGMGwbszxyDMpUe3dffrLGa/tcgAAMYwwgmG5nA6tWZgpid1YAQDhRRjBiIoWTpMk7T3BfiMAgPAhjGBE/r6RqtpWXerus1wNACBWEUYwotyMyZqbOVl9PqMDbA0PAAgTwgiuKrAbK/uNAADChDCCqyomjAAAwowwgqsqXJAlp0M60XhJ9d7LtssBAMQgwgiuyjM5UTfNTpfEEl8AQHgQRnBNRf79RpiqAQCEAWEE1+Tfb2TfiSYZYyxXAwCINYQRXNPyuemalOhS06UefdzQbrscAECMGVMY2b59u/Ly8pScnKz8/HyVl5ePeO4bb7yhb3zjG5o2bZrS0tJUUFCg//mf/xlzwZh47gSXVs3PkETfCAAg9IIOIzt37tTGjRu1ZcsWVVVVqbi4WGvXrlVtbe2w5+/Zs0ff+MY3tGvXLlVWVuprX/ua7rzzTlVVVY27eEycoitLfMvpGwEAhJjDBNkEsGrVKi1fvlw7duwIHFu8eLHuuusulZaWjuozbrzxRq1bt05PPvnkqM5va2uTx+OR1+tVWlpaMOUiRD5uaNO3tpUrOdGpv2wtkTvBZbskAECEG+3v76DujPT09KiyslIlJSWDjpeUlKiiomJUn+Hz+dTe3q6MjIwRz+nu7lZbW9ugF+y6PjtV01Ld6ur1qfJ0i+1yAAAxJKgw0tTUpP7+fmVnZw86np2drYaGhlF9xi9+8Qt1dHTo7rvvHvGc0tJSeTyewCs3NzeYMhEGDocjMFVD3wgAIJTG1MDqcDgG/dkYM+TYcF599VU99dRT2rlzp6ZPnz7ieZs3b5bX6w286urqxlImQqyIreEBAGGQEMzJWVlZcrlcQ+6CNDY2Drlb8kU7d+7U/fffr9/+9rf6+te/ftVz3W633G53MKVhAhQtGggjh8961dLRo6kpSZYrAgDEgqDujCQlJSk/P19lZWWDjpeVlamwsHDE61599VV9//vf13//93/r9ttvH1ulsC47LVmLpk+RMdL+mmbb5QAAYkTQ0zSbNm3SCy+8oJdeeknHjh3TY489ptraWm3YsEHSwBTL+vXrA+e/+uqrWr9+vX7xi19o9erVamhoUENDg7xeb+h+CkwY/92RcvpGAAAhEnQYWbdunbZt26ann35at9xyi/bs2aNdu3Zp7ty5kqT6+vpBe478+te/Vl9fnx588EHNnDkz8Hr00UdD91NgwhQv8veNXLBcCQAgVgS9z4gN7DMSOTq6+3TL0++ot99o9+Nf1dzMFNslAQAiVFj2GQFS3AlaNmeqJKZqAAChQRhB0PxLfPexxBcAEAKEEQTN38RacbJZ/b6In+UDAEQ4wgiCdvMsj1KTE+S93KvDZ1kVBQAYH8IIgpbgcqpwQaYkae9xVtUAAMaHMIIx8feN0MQKABgvwgjGpGjRNEnSB7Ut6uzps1wNACCaEUYwJvMyJ2tW+iT19hu9d+qi7XIAAFGMMIIxcTgcn+3GylQNAGAcCCMYsyLCCAAgBAgjGLPCBVlyOKRPzrersb3LdjkAgChFGMGYZaQk6cacgWcNsBsrAGCsCCMYl6KFA6tqWOILABgrwgjG5fNNrFHwAGgAQAQijGBc8udOlTvBqcb2bh1vvGS7HABAFCKMYFySE11amZchiVU1AICxIYxg3Pxbw++liRUAMAaEEYybf7+RAzXN6unzWa4GABBtCCMYt8Uz0pSZkqTOnn5V1bbYLgcAEGUIIxg3p9OhNUzVAADGiDCCkKBvBAAwVoQRhIS/b+Qvda3yXu61XA0AIJoQRhASOemTNH9ainxG2n+y2XY5AIAoQhhByBQHpmouWK4EABBNCCMImaJFA8+pYfMzAEAwCCMImVXzM+RyOvRpc6fqLnbaLgcAECUIIwiZtORE3ZKbLknax6oaAMAoEUYQUv4lvuWEEQDAKBFGEFLFV5b4Vpxoks9nLFcDAIgGhBGE1NLcdE1xJ6ils1dHzrXZLgcAEAUIIwipRJdTq+dnSGI3VgDA6BBGEHJF7DcCAAgCYQQh599v5P1PW9TV22+5GgBApCOMIOQWTEvRTE+yevp8Onjqou1yAAARjjCCkHM4HFpzZaqG/UYAANdCGEFY+Jf4lrM1PADgGggjCAv/nZGj9W1qutRtuRoAQCQjjCAssqa4tXhmmiSmagAAV0cYQdj4p2p4ii8A4GoIIwibzzexGsPW8ACA4RFGEDYr52UoyeXUOW+Xapo6bJcDAIhQhBGEzaQkl1bMmyqJqRoAwMgIIwirIpb4AgCugTCCsCpeOLA1/IGaZvX2+yxXAwCIRIQRhNUNOWlKn5yoS919+vBMq+1yAAARKMF2AYhtLqdDaxZk6Q+H6/Xztz/RDTlptksCAAzjO8tna8ksj5XvJowg7L5y3TT94XC93jt1Ue/x4DwAiEjL5kwljCB2/Z/ls9TW1auWzh7bpQAARrBo+hRr300YQdglupx6oHi+7TIAABGKBlYAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGBVVDy11xgjSWpra7NcCQAAGC3/723/7/GRREUYaW9vlyTl5uZargQAAASrvb1dHo9nxPcd5lpxJQL4fD6dO3dOqampcjgcIfvctrY25ebmqq6uTmlpaSH7XAzFWE8MxnliMM4Tg3GeGOEcZ2OM2tvblZOTI6dz5M6QqLgz4nQ6NXv27LB9flpaGv/QJwhjPTEY54nBOE8MxnlihGucr3ZHxI8GVgAAYBVhBAAAWBXXYcTtdmvr1q1yu922S4l5jPXEYJwnBuM8MRjniREJ4xwVDawAACB2xfWdEQAAYB9hBAAAWEUYAQAAVhFGAACAVXEdRrZv3668vDwlJycrPz9f5eXltkuKWHv27NGdd96pnJwcORwO/f73vx/0vjFGTz31lHJycjRp0iR99atf1ZEjRwad093drYcfflhZWVlKSUnR3/7t3+rMmTODzmlpadF9990nj8cjj8ej++67T62trWH+6SJHaWmpvvzlLys1NVXTp0/XXXfdpU8++WTQOYz1+O3YsUM333xzYJOngoIC/fGPfwy8zxiHR2lpqRwOhzZu3Bg4xliHxlNPPSWHwzHoNWPGjMD7ET/OJk699tprJjEx0fzHf/yHOXr0qHn00UdNSkqKOX36tO3SItKuXbvMli1bzOuvv24kmTfffHPQ+88++6xJTU01r7/+ujl8+LBZt26dmTlzpmlrawucs2HDBjNr1ixTVlZmPvjgA/O1r33NLF261PT19QXO+da3vmWWLFliKioqTEVFhVmyZIm54447JurHtO6b3/ymefnll81HH31kqqurze23327mzJljLl26FDiHsR6/t956y/zhD38wn3zyifnkk0/ME088YRITE81HH31kjGGMw+HgwYNm3rx55uabbzaPPvpo4DhjHRpbt241N954o6mvrw+8GhsbA+9H+jjHbRhZuXKl2bBhw6BjX/rSl8xPf/pTSxVFjy+GEZ/PZ2bMmGGeffbZwLGuri7j8XjM888/b4wxprW11SQmJprXXnstcM7Zs2eN0+k0b7/9tjHGmKNHjxpJ5sCBA4Fz9u/fbySZjz/+OMw/VWRqbGw0kszu3buNMYx1OE2dOtW88MILjHEYtLe3m0WLFpmysjLzla98JRBGGOvQ2bp1q1m6dOmw70XDOMflNE1PT48qKytVUlIy6HhJSYkqKiosVRW9Tp06pYaGhkHj6Xa79ZWvfCUwnpWVlert7R10Tk5OjpYsWRI4Z//+/fJ4PFq1alXgnNWrV8vj8cTt34vX65UkZWRkSGKsw6G/v1+vvfaaOjo6VFBQwBiHwYMPPqjbb79dX//61wcdZ6xD6/jx48rJyVFeXp6++93vqqamRlJ0jHNUPCgv1JqamtTf36/s7OxBx7Ozs9XQ0GCpqujlH7PhxvP06dOBc5KSkjR16tQh5/ivb2ho0PTp04d8/vTp0+Py78UYo02bNqmoqEhLliyRxFiH0uHDh1VQUKCuri5NmTJFb775pm644YbA/6kyxqHx2muv6YMPPtD7778/5D3+PYfOqlWr9Jvf/EbXXXedzp8/r2eeeUaFhYU6cuRIVIxzXIYRP4fDMejPxpghxzB6YxnPL54z3Pnx+vfy0EMP6cMPP9TevXuHvMdYj9/111+v6upqtba26vXXX9f3vvc97d69O/A+Yzx+dXV1evTRR/XOO+8oOTl5xPMY6/Fbu3Zt4H/fdNNNKigo0IIFC/Rf//VfWr16taTIHue4nKbJysqSy+UakuQaGxuHJEdcm79j+2rjOWPGDPX09KilpeWq55w/f37I51+4cCHu/l4efvhhvfXWW/rzn/+s2bNnB44z1qGTlJSkhQsXasWKFSotLdXSpUv1L//yL4xxCFVWVqqxsVH5+flKSEhQQkKCdu/erV/+8pdKSEgIjANjHXopKSm66aabdPz48aj4Nx2XYSQpKUn5+fkqKysbdLysrEyFhYWWqopeeXl5mjFjxqDx7Onp0e7duwPjmZ+fr8TExEHn1NfX66OPPgqcU1BQIK/Xq4MHDwbOee+99+T1euPm78UYo4ceekhvvPGG/vd//1d5eXmD3mesw8cYo+7ubsY4hG677TYdPnxY1dXVgdeKFSt07733qrq6WvPnz2esw6S7u1vHjh3TzJkzo+Pf9LjaX6OYf2nviy++aI4ePWo2btxoUlJSzKeffmq7tIjU3t5uqqqqTFVVlZFknnvuOVNVVRVYCv3ss88aj8dj3njjDXP48GHz93//98MuG5s9e7b505/+ZD744ANz6623Drts7Oabbzb79+83+/fvNzfddFNcLc/7h3/4B+PxeMy77747aIleZ2dn4BzGevw2b95s9uzZY06dOmU+/PBD88QTTxin02neeecdYwxjHE6fX01jDGMdKj/+8Y/Nu+++a2pqasyBAwfMHXfcYVJTUwO/0yJ9nOM2jBhjzL/927+ZuXPnmqSkJLN8+fLA8kkM9ec//9lIGvL63ve+Z4wZWDq2detWM2PGDON2u83f/M3fmMOHDw/6jMuXL5uHHnrIZGRkmEmTJpk77rjD1NbWDjqnubnZ3HvvvSY1NdWkpqaae++917S0tEzQT2nfcGMsybz88suBcxjr8fvhD38Y+G9/2rRp5rbbbgsEEWMY43D6YhhhrEPDv29IYmKiycnJMX/3d39njhw5Eng/0sfZYYwx47u3AgAAMHZx2TMCAAAiB2EEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVf8fX2XPkGJo7j8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So what's an easy way to check?\n",
    "plt.plot([get_epsilon(it) for it in range(5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8b604c9998c6c3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now write a function of *EpsilonGreedyPolicy* class. This function takes a state and uses the Q-network to select an ($\\epsilon$-greedy) action. It should return a random action with probability epsilon. Note, you do not need to backpropagate through the model computations, so use `with torch.no_grad():` (see above for example). Note that to convert a PyTorch tensor with only 1 element (0 dimensional) to a simple python scalar (int or float), you can use the '.item()' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-878ad3a637cfb51c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class EpsilonGreedyPolicy(object):\n",
    "    \"\"\"\n",
    "    A simple epsilon greedy policy.\n",
    "    \"\"\"\n",
    "    def __init__(self, Q, epsilon):\n",
    "        self.Q = Q\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def sample_action(self, obs):\n",
    "        \"\"\"\n",
    "        This method takes a state as input and returns an action sampled from this policy.  \n",
    "\n",
    "        Args:\n",
    "            obs: current state\n",
    "\n",
    "        Returns:\n",
    "            An action (int).\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        with torch.no_grad():\n",
    "            # Exploratory action\n",
    "            if np.random.rand() < self.epsilon:\n",
    "                action = np.random.randint(2)\n",
    "            # Greedy action\n",
    "            else:\n",
    "                action = torch.argmax(self.Q(torch.tensor(obs).float())).item()\n",
    "        \n",
    "        return action\n",
    "        \n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e895338d56bee477",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "epg = EpsilonGreedyPolicy(Q_net, 0.05)\n",
    "a = epg.sample_action(s)\n",
    "assert not torch.is_tensor(a)\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 978, 1: 22}\n"
     ]
    }
   ],
   "source": [
    "counts = {0: 0, 1: 0}\n",
    "for i in range(1000):\n",
    "    s = env.reset()\n",
    "    counts[epg.sample_action(s)] += 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec5e94e0b03f8aec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d1a12cc97386fe56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we will implement the function 'train' that samples a batch from the memory and performs a gradient step using some convenient PyTorch functionality. However, you still need to compute the Q-values for the (state, action) pairs in the experience, as well as their target (e.g. the value they should move towards). What is the target for a Q-learning update? What should be the target if `next_state` is terminal (e.g. `done`)?\n",
    "\n",
    "For computing the Q-values for the actions, note that the model returns all action values where you are only interested in a single action value. Because of the batch dimension, you can't use simple indexing, but you may want to have a look at [torch.gather](https://pytorch.org/docs/stable/torch.html?highlight=gather#torch.gather) or use [advanced indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html) (numpy tutorial but works mostly the same in PyTorch). Note, you should NOT modify the function train. You can view the size of a tensor `x` with `x.size()` (similar to `x.shape` in numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c45485324b40081",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def compute_q_vals(Q, states, actions):\n",
    "    \"\"\"\n",
    "    This method returns Q values for given state action pairs.\n",
    "    \n",
    "    Args:\n",
    "        Q: Q-net\n",
    "        states: a tensor of states. Shape: batch_size x obs_dim\n",
    "        actions: a tensor of actions. Shape: Shape: batch_size x 1\n",
    "\n",
    "    Returns:\n",
    "        A torch tensor filled with Q values. Shape: batch_size x 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    Q_values = Q(states).gather(1, actions)\n",
    "    return Q_values\n",
    "\n",
    "    \n",
    "def compute_targets(Q, rewards, next_states, dones, discount_factor):\n",
    "    \"\"\"\n",
    "    This method returns targets (values towards which Q-values should move).\n",
    "    \n",
    "    Args:\n",
    "        Q: Q-net\n",
    "        rewards: a tensor of rewards. Shape: Shape: batch_size x 1\n",
    "        next_states: a tensor of states. Shape: batch_size x obs_dim\n",
    "        dones: a tensor of boolean done flags (indicates if next_state is terminal) Shape: batch_size x 1\n",
    "        discount_factor: discount\n",
    "    Returns:\n",
    "        A torch tensor filled with target values. Shape: batch_size x 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    max_next_Q = Q(next_states).max(1)[0][:, None]\n",
    "    bool_mask = torch.logical_not(dones)\n",
    "    targets = rewards + discount_factor * max_next_Q * bool_mask\n",
    "\n",
    "    return targets\n",
    "\n",
    "def train(Q, memory, optimizer, batch_size, discount_factor):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "    \n",
    "    # don't learn without some decent experience\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "\n",
    "    # random transition batch is taken from experience replay memory\n",
    "    transitions = memory.sample(batch_size)\n",
    "    \n",
    "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
    "    state, action, reward, next_state, done = zip(*transitions)\n",
    "    \n",
    "    # convert to PyTorch and define types\n",
    "    state = torch.tensor(state, dtype=torch.float)\n",
    "    action = torch.tensor(action, dtype=torch.int64)[:, None]  # Need 64 bit to use them as index\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float)\n",
    "    reward = torch.tensor(reward, dtype=torch.float)[:, None]\n",
    "    done = torch.tensor(done, dtype=torch.uint8)[:, None]  # Boolean\n",
    "    \n",
    "    # compute the q value\n",
    "    q_val = compute_q_vals(Q, state, action)\n",
    "    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n",
    "        target = compute_targets(Q, reward, next_state, done, discount_factor)\n",
    "    \n",
    "    # loss is measured from error between current and newly expected Q values\n",
    "    loss = F.smooth_l1_loss(q_val, target)\n",
    "\n",
    "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()  # Returns a Python scalar, and releases history (similar to .detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b060b822eec4282f",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5544154644012451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/miniconda3/envs/rlcourse/lib/python3.7/site-packages/ipykernel_launcher.py:54: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /croot/pytorch_1675190298929/work/torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    }
   ],
   "source": [
    "# You may want to test your functions individually, but after you do so lets see if the method train works.\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "# Simple gradient descent may take long, so we will use Adam\n",
    "optimizer = optim.Adam(Q_net.parameters(), learn_rate)\n",
    "\n",
    "# We need a larger memory, fill with dummy data\n",
    "transition = memory.sample(1)[0]\n",
    "memory = ReplayMemory(10 * batch_size)\n",
    "for i in range(batch_size):\n",
    "    memory.push(transition)\n",
    "\n",
    "# Now let's see if it works\n",
    "loss = train(Q_net, memory, optimizer, batch_size, discount_factor)\n",
    "\n",
    "print (loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3eafd0ab49103f3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-36b8a04b393d8104",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now that you have implemented the training step, you should be able to put everything together. Implement the function `run_episodes` that runs a number of episodes of DQN training. It should return the durations (e.g. number of steps) of each episode. Note: we pass the train function as an argument such that we can swap it for a different training step later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-540a7d50ecc1d046",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def run_episodes(train, Q, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate):\n",
    "    \n",
    "    optimizer = optim.Adam(Q.parameters(), learn_rate)\n",
    "    \n",
    "    global_steps = 0  # Count the steps (do not reset at episode start, to compute epsilon)\n",
    "    episode_durations = []  #\n",
    "    for i in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        \n",
    "        steps = 0\n",
    "        while True:\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            epsilon = get_epsilon(global_steps)\n",
    "            policy.set_epsilon(epsilon)\n",
    "            action = policy.sample_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.push((state, action, reward, next_state, done))\n",
    "            train(Q, memory, optimizer, batch_size, discount_factor)\n",
    "            state = next_state\n",
    "            steps += 1\n",
    "            global_steps += 1\n",
    "            \n",
    "            if done:\n",
    "                if i % 10 == 0:\n",
    "                    print(\"{2} Episode {0} finished after {1} steps\"\n",
    "                          .format(i, steps, '\\033[92m' if steps >= 195 else '\\033[99m'))\n",
    "                episode_durations.append(steps)\n",
    "                break\n",
    "    return episode_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 0 finished after 14 steps\n",
      "\u001b[99m Episode 10 finished after 20 steps\n",
      "\u001b[99m Episode 20 finished after 14 steps\n",
      "\u001b[99m Episode 30 finished after 32 steps\n",
      "\u001b[99m Episode 40 finished after 81 steps\n",
      "\u001b[99m Episode 50 finished after 130 steps\n",
      "\u001b[99m Episode 60 finished after 171 steps\n",
      "\u001b[99m Episode 70 finished after 137 steps\n",
      "\u001b[99m Episode 80 finished after 147 steps\n",
      "\u001b[99m Episode 90 finished after 158 steps\n"
     ]
    }
   ],
   "source": [
    "# Let's run it!\n",
    "num_episodes = 100\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "memory = ReplayMemory(10000)\n",
    "num_hidden = 128\n",
    "seed = 42  # This is not randomly chosen\n",
    "\n",
    "# We will seed the algorithm (before initializing QNetwork!) for reproducibility\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "\n",
    "Q_net = QNetwork(num_hidden)\n",
    "policy = EpsilonGreedyPolicy(Q_net, 0.05)\n",
    "episode_durations = run_episodes(train, Q_net, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-928ecc11ed5c43d8",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Episode durations per episode')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGxCAYAAABIjE2TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABZw0lEQVR4nO3dd3hT9f4H8HdGm+5071JaKBRomWUrlG1ZKsgQvYCD60CvqFyv84r+VNzjXsV1FRwguC8IXpllyGpBoNACpQNaulfSmbbJ9/dHSSS0hZYmzej79Tx5NCcnJ5/k0Obd7zoSIYQAERERkRWRWroAIiIioisxoBAREZHVYUAhIiIiq8OAQkRERFaHAYWIiIisDgMKERERWR0GFCIiIrI6DChERERkdRhQiIiIyOowoJDVW7NmDSQSSau3xMTEdh8zMTHxup/bEfHx8YiPj7eb12nNli1bsGLFihYf6969OxYvXtyp9XR1ixcvRvfu3Tv1NbOzsyGRSLBmzZpOfV2yH3JLF0DUVqtXr0Z0dHSz7X379m33sQYPHowDBw5c13Pp2rZs2YIPPvigxZDy008/wcPDo/OL6sKee+45PPLII5Yug6hdGFDIZsTExCAuLs4kx/Lw8MCIESNMcqyuoKamBi4uLiY51qBBg0xyHFtmys+zLXr06NFpr0VkKuziIbsikUjw0EMP4eOPP0avXr2gUCjQt29frF+/3mi/lrp4MjMzMX/+fAQHB0OhUCAgIAATJkzAsWPHDPvodDq8/vrriI6OhkKhgL+/PxYuXIjc3Fyj4wsh8PrrryM8PBxOTk4YPHgwfv311xZrVqvVWL58OSIiIuDo6IiQkBAsW7YM1dXV13y/bX0dfTdZdnb2NT+H+Ph4xMTEYM+ePRg1ahRcXFxw9913AwA2bNiAyZMnIygoCM7OzujTpw+efPJJo1oXL16MDz74AACMuuL0r91SF8+FCxdw5513wt/fHwqFAn369MFbb70FnU5n2EffZfDmm2/i7bffRkREBNzc3DBy5EgcPHjQ6HhtOZctWbx4Mdzc3HDq1ClMmDABrq6u8PPzw0MPPYSamppmn/2qVaswcOBAODs7w8vLC7fddhsyMzON9rva59ma5ORkzJw5E97e3nBycsKgQYPw7bffGu2jP6fbtm3DXXfdBW9vb7i6umLGjBnNamipi+e7777D8OHDoVQq4eLigsjIyGZ1teW8AEBeXh7mzp0Ld3d3KJVKzJs3DwUFBdf93ogAtqCQDdFqtWhsbDTaJpFIIJPJjLZt3LgRu3btwosvvghXV1esWrUKt99+O+RyOW677bZWjz916lRotVq8/vrr6NatG0pKSrB//35UVFQY9nnggQfwySef4KGHHsL06dORnZ2N5557DomJiTh69Ch8fX0BAC+88AJeeOEF3HPPPbjtttuQk5ODJUuWQKvVonfv3obj1dTUYOzYscjNzcXTTz+N/v3749SpU/jnP/+JlJQUbN++HRKJpNWa2/o67ZWfn48777wTTzzxBF555RVIpU1/y6Snp2Pq1KlYtmwZXF1dcfr0abz22ms4fPgwdu7cCaCpO6G6uhrff/89Dhw4YDhmUFBQi69VXFyMUaNGob6+Hv/3f/+H7t2745dffsHy5cuRkZGBVatWGe3/wQcfIDo6Gu+++67h9aZOnYqsrCwolUoAbTuXrWloaMDUqVNx33334cknn8T+/fvx0ksv4fz589i0aZNhv/vuuw9r1qzB3/72N7z22msoKyvDiy++iFGjRuH48eMICAi45ufZkl27duGmm27C8OHD8dFHH0GpVGL9+vWYN28eampqmoW7e+65B5MmTcK6deuQk5ODZ599FvHx8Thx4gQ8PT1bfI0DBw5g3rx5mDdvHlasWAEnJyecP3/ecA7bc15qa2sxceJE5OXlYeXKlejVqxc2b96MefPmdfi9URcniKzc6tWrBYAWbzKZzGhfAMLZ2VkUFBQYtjU2Noro6GjRs2dPw7Zdu3YJAGLXrl1CCCFKSkoEAPHuu++2WkdaWpoAIB588EGj7YcOHRIAxNNPPy2EEKK8vFw4OTmJW2+91Wi/33//XQAQY8eONWxbuXKlkEqlIikpyWjf77//XgAQW7ZsabWe9ryO/jPMysoy2vfKz0EIIcaOHSsAiB07drT62kIIodPpRENDg9i9e7cAII4fP254bOnSpaK1Xy/h4eFi0aJFhvtPPvmkACAOHTpktN8DDzwgJBKJOHPmjBBCiKysLAFAxMbGisbGRsN+hw8fFgDEN998I4Ro27lszaJFiwQA8d577xltf/nllwUAsW/fPiGEEAcOHBAAxFtvvWW0X05OjnB2dhZPPPGEYVtbP0+96OhoMWjQINHQ0GC0ffr06SIoKEhotVohxJ/ntLXz/9JLLxm9r/DwcMP9N998UwAQFRUVrdbR1vPy4YcfCgDiv//9r9F+S5YsEQDE6tWr2/3eiIQQgl08ZDO+/PJLJCUlGd0OHTrUbL8JEyYY/fUqk8kwb948nDt3rllXjJ63tzd69OiBN954A2+//Tb++OOPZs3Yu3btAoBmf+UNGzYMffr0wY4dOwA0/XVaV1eHO+64w2i/UaNGITw83GjbL7/8gpiYGAwcOBCNjY2G25QpU645y6g9r9NeXl5eGD9+fLPtmZmZWLBgAQIDAyGTyeDg4ICxY8cCANLS0q7rtXbu3Im+ffti2LBhRtsXL14MIYTRX/UAMG3aNKNWs/79+wMAzp8/D6Bt5/JarvxMFyxYAODPfwO//PILJBIJ7rzzTqPzFhgYiAEDBjQ7b619nlc6d+4cTp8+bXj9y489depU5Ofn48yZM1etVX/+9bW2ZOjQoQCAuXPn4ttvv8XFixeb7dPW87Jr1y64u7tj5syZRvvpP7OOvDfq2hhQyGb06dMHcXFxRrchQ4Y02y8wMLDVbaWlpS0eWyKRYMeOHZgyZQpef/11DB48GH5+fvjb3/6GyspKo+e21FURHBxseFz/36vVoVdYWIgTJ07AwcHB6Obu7g4hBEpKSlr9PNrzOu3V0nusqqrCjTfeiEOHDuGll15CYmIikpKS8OOPPwJoauq/HqWlpa1+pvrHL+fj42N0X6FQGL1+W87l1cjl8mavceW/n8LCQgghEBAQ0OzcHTx4sNl5a61760qFhYUAgOXLlzc77oMPPggAzY7d2vlv7d86AIwZMwY///wzGhsbsXDhQoSGhiImJgbffPONYZ+2npfS0lKjPwhaq+t63ht1bRyDQnanpcF5+m1XfvFcLjw8HJ999hkA4OzZs/j222+xYsUK1NfX46OPPjI8Nz8/H6GhoUbPzcvLM4w/0e/XWh2XD1b09fWFs7MzPv/88xZr0h+zJe15HScnJwCARqMx2q+1L4SWxr3s3LkTeXl5SExMNLSaAGjTuI6r8fHxQX5+frPteXl5AK7+GbTmWufyahobG1FaWmr0b+XKfz++vr6QSCTYu3evISBd7sptVxtHdDn9e33qqacwa9asFve5cmxRa+e/Z8+eV32tm2++GTfffDM0Gg0OHjyIlStXYsGCBejevTtGjhzZ5vPi4+ODw4cPt1hDR98bdW1sQSG7s2PHDsNfa0DT4NoNGzagR48ezYJFa3r16oVnn30WsbGxOHr0KAAYmui//vpro32TkpKQlpaGCRMmAABGjBgBJycnrF271mi//fv3G7oh9KZPn46MjAz4+Pg0ax2Ki4u76uJa7Xkd/XFOnDhhtH3jxo1X+RSM6b9kr/zy/fjjj5vte2WrxtVMmDABqamphs9Z78svv4REIsG4cePaXGNLWjqX13LlZ7pu3ToAMCx+N336dAghcPHixRbPW2xs7HXV2rt3b0RFReH48eMtHjcuLg7u7u5XrVV//tu6UJ9CocDYsWPx2muvAQD++OMPAG0/L+PGjUNlZWWzf0v6z6wj7426NragkM04efJks1k8QNMaD35+fob7vr6+GD9+PJ577jnDLJ7Tp083m2p8uRMnTuChhx7CnDlzEBUVBUdHR+zcuRMnTpzAk08+CaDpF+xf//pX/Pvf/4ZUKkVCQoJhFk9YWBgeffRRAE3jDZYvX46XXnoJ9957L+bMmYOcnBysWLGiWbP3smXL8MMPP2DMmDF49NFH0b9/f+h0Oly4cAFbt27F448/juHDh7dYc3teZ+jQoejduzeWL1+OxsZGeHl54aeffsK+ffva9uGjaWyDl5cX7r//fjz//PNwcHDA2rVrcfz48Wb76r+gX3vtNSQkJEAmk6F///5wdHRstu+jjz6KL7/8EtOmTcOLL76I8PBwbN68GatWrcIDDzyAXr16tblGoG3n8mocHR3x1ltvoaqqCkOHDjXM4klISMANN9wAABg9ejT++te/4q677kJycjLGjBkDV1dX5OfnY9++fYiNjcUDDzzQrrr1Pv74YyQkJGDKlClYvHgxQkJCUFZWhrS0NBw9ehTfffed0f7JyclG5/+ZZ55BSEiIodukJf/85z+Rm5uLCRMmIDQ0FBUVFXjvvfeMxhS19bwsXLgQ77zzDhYuXIiXX34ZUVFR2LJlC3777bcOvzfq4iw6RJeoDa42iweA+PTTTw37AhBLly4Vq1atEj169BAODg4iOjparF271uiYV85eKSwsFIsXLxbR0dHC1dVVuLm5if79+4t33nnHaMaIVqsVr732mujVq5dwcHAQvr6+4s477xQ5OTlGx9fpdGLlypUiLCxMODo6iv79+4tNmzaJsWPHGs2uEUKIqqoq8eyzz4revXsLR0dHoVQqRWxsrHj00UeNZiO1pD2vc/bsWTF58mTh4eEh/Pz8xMMPPyw2b97c4iyefv36tfh6+/fvFyNHjhQuLi7Cz89P3HvvveLo0aPNZmtoNBpx7733Cj8/PyGRSIxmEF05i0cIIc6fPy8WLFggfHx8hIODg+jdu7d44403jGZ16GfxvPHGG83qAiCef/55IUTbz2VLFi1aJFxdXcWJEydEfHy8cHZ2Ft7e3uKBBx4QVVVVzfb//PPPxfDhw4Wrq6twdnYWPXr0EAsXLhTJyclt+jxbc/z4cTF37lzh7+8vHBwcRGBgoBg/frz46KOPDPvofy62bt0q/vKXvwhPT0/h7Owspk6dKtLT05u9r8tn8fzyyy8iISFBhISECEdHR+Hv7y+mTp0q9u7da/S8tpwXIYTIzc0Vs2fPFm5ubsLd3V3Mnj1b7N+/v9m/i7a+NyIhhJAIIUTnxyIi85BIJFi6dCnef/99S5dCNmjx4sX4/vvvUVVVZelSrmnNmjW46667kJSUZLIVlomsCcegEBERkdVhQCEiIiKrwy4eIiIisjpsQSEiIiKrw4BCREREVocBhYiIiKyOTS7UptPpkJeXB3d39zYvIU1ERESWJYRAZWUlgoODIZVevY3EJgNKXl4ewsLCLF0GERERXYecnJxrXnrEJgOK/noNOTk58PDwsHA1RERE1BZqtRphYWFtuu6STQYUfbeOh4cHAwoREZGNacvwDA6SJSIiIqvDgEJERERWhwGFiIiIrA4DChEREVkdBhQiIiKyOgwoREREZHUYUIiIiMjqMKAQERGR1WFAISIiIqvDgEJERERWhwGFiIiIrA4DChEREVkdm7xYIBHZtmpNI9Ly1TiVp0Z9ow5zh4ZB6exg6bKIyIowoBBRpziVp8LHuzNxMk+FrJJqCPHnY+uTLmD14mHo5uNiuQKJyKqwi4eIOsXLm9Ow8XgeMoubwkmghxMmRPsjSOmEjOJq3LLqdyRnl1m6TCKyEmxBISKz0+kETuSqAABvzhmA+N5+8HVTAACK1HW454tkpFxUYcGnh/DGnP64eWCIJcslIivAFhQiMrus0mpUaRrh5CDFLQODDeEEAPw9nLDhvhGY3DcA9VodHll/DO9sOwtxeR8QEXU5DChEZHYnLza1nvQJ8oBc1vzXjoujHB/dOQT3jY0EALy3Ix3/O1nQqTUSkXVhQCEis0u51L0TG6JsdR+pVIKnEvpg8ajuAIBfGVCIujQGFCIyu5SL1w4oetP7BwEAdp8tRqNWZ9a6iMh6MaAQkVnpdAKn8tQAgNjQaweUgWGeUDo7QFXbgGM5FWaujoisFQMKEZnV5QNke/q5XXN/uUyKsb38AAC7zhSZu7yr0uoE0gsrOWCXyAIYUIjIrK41QLYl46KbAsrO08Vmq+taGrU63PdVMia9swcbj+dZrA6irooBhYjMSj9Atn8bxp/ojYnyg0QCpOWrUaCqM1dprRJC4MVfUrE9rakFZ/+50k6vgairY0AhIrM6cakFJaYdAcXHTYGBYZ4AgEQLdPN8/ns2vjxw3nA/rUDd6TUQdXUMKERkNjqdQGo7BsheblxvfwDAztOdG1B+O1WAlzanAgDuGN4NAHCmoJIziog6GQMKEZlNewfIXk4fUH4/VwJNo9Yc5TVzIrcCj6z/A0IAC4Z3w//dHAMXRxk0jTpkl1Z3Sg1E1IQBhYjMRj/+pG87Bsjq9Qv2gJ+7AtX1WiRnl5ujPCO55TW454tk1DXoMLaXH16c2Q9SqQTRge4AYJgqbSlancDZwkpodZxRRF0DAwoRmU17Fmi7klQqQbx+urGZu3l0OoHHNhxHcaUG0YHueH/BIEOg6hPkAQBIy680aw3X8smeTEx+Zw/mf3IAOWU1Fq2FqDMwoBCR2aRcxwDZy42LvjQOxcwDZb9NzsHh7DK4OMrw6cI4uDs5GB77M6BYtgVl06WpzknZ5bjp3T34NjnH6tZn6ayuOOoa5JYugIjsk04ncErfgtLOAbJ6N0T5Qi6VILO4GudLqxHu42rKEgEARZV1eGVLGgDgsUm9EObtYvR432DLB5QCVR1S89WQSIBBYZ44eqECT3x/AjvSCvHKrbHwuezq0KZU16DFpuN52HWmCGHeLogL98aQcC94uzoCaDrHx3IrsC21ENtSC3GuqAr/d3M//GVkd7PUQ10LAwoRmUVmSTWq67XXNUBWz8PJAXHdvXAwswyJZ4qxaJTpA8r//ZIGdV0jYkOUhgsVXi460B0SCVBUqUFJlQa+ZgoDV6NfUXdAqCe+u38UPtmTibe3ncFvpwpx5HwF/rMozjAt2xTyKmrx9cHzWJ+Ug7LqesP2j5EJAOjh54peAe5IPl+O4kqN0XM3p+QzoJBJtLuLZ8+ePZgxYwaCg4MhkUjw888/Gz0ukUhavL3xxhuGfeLj45s9Pn/+/A6/GSKyHvoVZK9ngOzlzDndeNeZImw6ngepBFg5K7bFOl0c5eh+qeXGUq0oOy4tGDc+2h8yqQQPxPfATw+ORpS/G0qqNLj/qyMordJc4yjXlldRiwfXHsGNr+/CqsQMlFXXI1jphIfH98T8oWHo6d8UNDOKq/HryQIUV2rgppBjWv8g/H1KbwDAqYtq6DiQl0yg3S0o1dXVGDBgAO666y7Mnj272eP5+flG93/99Vfcc889zfZdsmQJXnzxRcN9Z2fn9pZCRFasIwNkLzcu2h8rfz2NA5mlqK3XwtlRZoryUFPfiGd/OgkAuHt0xFXHyfQJckdWSTXS8tW4McrPJK/fVnUNWvx+rgRAU0DRiwlR4qelo3Hz+/uQUVyNZRuOYc1dwyCTSq7rdQrVdbj904M4X9o0AHdEpDcWj+qOiX0CjIJbeXU9jpwvx5nCSsSEKDEi0hsKuQwNWh3e25GOSk0jLpTVoLuv6Vu7qGtpd0BJSEhAQkJCq48HBgYa3f/vf/+LcePGITIy0mi7i4tLs32JyH50dICsXpS/G0I8nXGxohb/PXYR84d1M0V5eHd7Oi5W1CLE0xmPTup11X37BHpgS0qBRWbyHMoqQ22DFgEeCvS7NB5Gz00hx6o7huDmD/Zhb3oJ3t95Do9MjGr3a5RWaXDHfw7hfGkNwryd8fGdcYaxN1fycnXExL4BmNg3wGi7g0yKPkEeOJ5TgZSLKgYU6jCzzuIpLCzE5s2bcc899zR7bO3atfD19UW/fv2wfPlyVFa2/oOv0WigVquNbkRkvS4fINs/1LNDx5JIJJgTFwoAePbnk9ieWtjR8nDyogqf7csCALx0SwxcFVf/W03/ZZ1qgbVQ9FOsx/X2h0TSvHWkd6A7XrolFgDw7o6zhtaWtlLVNOAvnx3GuaIqBHo4Yd29I1oNJ9cSG9L0PH33HlFHmDWgfPHFF3B3d8esWbOMtt9xxx345ptvkJiYiOeeew4//PBDs30ut3LlSiiVSsMtLCzMnGUTUQddPkC2h1/H/5J+eHwUbh4YjEadwINrj2Jfevu+hC9XUVOPh7/5A1qdwLT+QYapzFejn2qcUVzVqVNphRCGsTdXq/O2IaGYFxcGIYBH1v+BQnXbLrBYpWnEotWHkZqvhq+bI9YuGd5sFlN76LvzUhhQyATMGlA+//xz3HHHHXBycjLavmTJEkycOBExMTGYP38+vv/+e2zfvh1Hjx5t8ThPPfUUVCqV4ZaTk2POsomog0w1QFZPJpXgrTkDMKVfAOq1Oiz5MhlJ2WXtPk6DVoel644iq6QaIZ7OeGFmvzY9L0jpBKWzAxp1AumFVe1+3euVUVyNC2U1cJRJcUNP36vu+8LN/RAd6I6Sqno8vO6Pa147qLZei3vWJOFYTgWUzg746p7h6HGds630+gU3BZSTF1VWt0YL2R6zBZS9e/fizJkzuPfee6+57+DBg+Hg4ID09PQWH1coFPDw8DC6EZH1OpZTAaDjA2QvJ5dJ8a/bB2FsLz/UNmhx1+okHL/0Om31wqZT+P1cKVwcZfjPorg2TxmWSCToE9S05H1nzuTZebqpO2t4pPc1u6GcHGT48M4hcFPIcTi7DP/4IaXVkFKtacTda5JwKKsMbgo5vrx7mKGVqCN6BbjDUSaFuq5poCxRR5htHZTPPvsMQ4YMwYABA66576lTp9DQ0ICgoCBzlUNEnaBRq8O/d57DlweyAQCDw71MenyFXIaP/zIEi1cfxsHMMiz49GCzxdtcHGWYNTgUswaHwMnhzxk/Xx7IxtcHL0AiAd6bP6jdX8h9g5Q4mFmG1E4NKH9OL26LCF9XvDlnAJauO4ofjuaisq4B/7p9kNHnUFnXgLtWJyH5fDlcHWVYfddQDDDRGiqOcimig9xxIleFlIsqsyysR11Hu1tQqqqqcOzYMRw7dgwAkJWVhWPHjuHChQuGfdRqNb777rsWW08yMjLw4osvIjk5GdnZ2diyZQvmzJmDQYMGYfTo0df/TojIovJVtVjwn0N4b0c6dAKYGxeK6f2DTf46Tg4y/GfRUAzu5onqei1S89VGt+Tz5Xj6p5RLa3mcg7quAXvTi/HCplQAwD9uisakK2agtEVnt6Co6xoMF0lsa0ABgJtiAvHhHYPhKJdia2oh7l6ThCpNI4CmAbF3fnYYyefL4e4kx9f3DsfQ7t4mrTuG41DIRNrdgpKcnIxx48YZ7j/22GMAgEWLFmHNmjUAgPXr10MIgdtvv73Z8x0dHbFjxw689957qKqqQlhYGKZNm4bnn38eMplp1jcgos61PbUQy78/joqaBrg6yvDKrFjcPDDEbK/nppBjw30jceR8OeobjbsxzhZW4vN9WchT1eH1/53Bql0ZAJquBjx7cCjuGxPZ0iGv6fKLBgohWpxRY0p7z5agUScQ6efa7paIyf0CseauoVjyRTL2Z5Tijk8P4q25A/G3b/5Aar4aXi5NY046OgW8JfpuvVMXOduSOkYibHAkk1qthlKphEql4ngUIgv7z95MvLS56Vo2MSEeeP/2wRZfA6NBq8PGY3n4eE8Gzl4a1BoX7oW1S4ZDIb++P4Q0jVr0++dvaNQJ7H9yPII9zbu45OPfHscPR3Ox5MYIPDOt73Ud40RuBRZ9fhjlNQ2QSAAh0DRb594R6B3obuKKm5y8qML0f++D0tkBx/45yexBjmxLe76/eS0eIrpuheo6vPHbGQDA4lHd8dTU6OsOAKbkIJNi9pBQ3DooBLvOFOFYTgXuGh3RodoUchl6+rvhdEElUvPUZg0oOp1A4plrTy++lv6hnvju/pG48z+HUaCuQ4CHAmvvHWFYst4c9ANlVbUNyC2v7dC0ZerazDrNmIjs2792pEPTqMOQcC88P6OvVYSTy0mlEkzoE4DHJ/c2XIG3I/7s5jFv98Xx3AqUVtfDXSHv8BiRnv7u+GnpKPx9Sm/88MAos4YToGmgrL51huNQqCMYUIjoupwvrcaGpKY1iZ6Y0rtLNOUbBsoWmDegbE9rml58Yy9fOJhgHZkgpTOWjuuJUK/Oac3gQFkyBQYUIroub287i0adwNhefhge6WPpcjrF5QNl9eoatPgwMQN/+ewQ0gs7fq2eRq0O3x/JBQAkxNjm0gsxXPKeTIBjUIio3dLy1dh4PA8A8PcpvS1cTefRB5Ts0mqo6xrwa0o+3tmWjoJLS8u/tDkNX9w9rEOvseN0EQrVGvi4OmJyv/ZPh7YGly953xkznsg+MaAQUbu9+dsZCAFM6x9klqmq1srXTQF/dwWKKjWY/PYeQzAJVjqhQF2H3WeLkZav7tCqrOsONa0pdVtcqNWN6Wmr3oHucJBJUFHDgbJ0/djFQ0Ttkpxdhh2niyCTSvD4pF6WLqfT6cNHgboOSmcHPDO1D3Yuj8fU2KbumE/2ZF73sXPKarAnvRgAsGBYt44XayEKuQy9AprG67Cbh64XAwoRtZkQAq9fmlY8Ny4UkR28uJwtmj0kFAEeCtw/tgf2PDEOS8ZEwslBhvvG9AAAbDyeh9zy67sOzTeHL0AI4MYoX5tfJl7fzXMyjwGFrg8DChG12e6zxTicVQZHuRR/mxBl6XIsYuaAYBx6eiKeTIiG0tnBsD02VInRPX2g1Ql8vi+73cetb9Th2+SmWVG23Hqi9+dMHq4oS9eHAYWI2kQIgXe2nQUALBoZjiCleVdStUX6VpT1SRdQUVPfruduSy1ESVU9/NwVmHgd1wqyNoYWlEsDZYnaiwGFiNpk37kSHM9VwclBivvH9rB0OVbpxihf9A3yQE29Fl8dON+u56473LT/vLgwk6x9Ymm9A90hl0pQVl2PPFWdpcshG2T7PwVE1Cne33kOALBgWDh83BQWrsY6SSQS3De26WKEa/Zno65Ba/R4ZnEVPt+XhXxVrdH2rJJq/H6uFBIJMH9YWKfVa05ODn8OlE3J5TgUaj8GFCK6puTsMhzKKoODTIIlYyIsXY5VmxYbhBBPZ5RW1xsWXMsqqcZjG45h4tu78eIvqYh/IxGv/noaqtoGAE2DYwEgvpdfp6322hku7+Yhai8GFCK6pg92NbWezB4cyrEn1yCXSbHkxqYQ98meTDz27TFMeCsRP/5xEToBhPu4QNOow0e7MzD2jV34ZE8GvtMPjh0ebsnSTW5QN08ATd2DRO3FhdqI6KpO5amw60wxpBJw7EkbzR0ahnd3pONCWQ0ulDVNOZ4Q7Y9HJkYhNkSJHWlFeO1/p5FeVIVXtpwGAAQpnTCut58lyza58X38IZEAx3IqUKiuQ4CHk6VLIhvCFhQiuqpVuzIAANP7B6O7r22vzdFZXBzlWHZpGva43n7479LR+GzxUPQP9YREIsHEvgH437IxeH12fwRe+tJeNKo75HYwOPZy/u5OGBjmCaBplhJRe7AFhYhalVFchS0n8wEAD45j60l7LB4dgduHd2t1uXqZVIK5Q8Mwc2AwzhZWGsZr2JvJfQPxx4UKbE0txJ0j7KsLi8zLvuI6EZnUh4kZEAKY2CcA0YHXf32Zrqot19JxcpAZWlbskf6ChwcySlBZ12DhasiWMKAQUYtyy2vw8x8XAQBL2XpC16mHnxsi/VzRoBVIPFNs6XLIhjCgEFGL/rM3C406gdE9fTCom5elyyEbNrlvIABgK8ehUDswoBBRM0II/Hpp7Mm9N0ZauBqydfpunsTTRahv1Fm4GrIVDChE1My5oioUqjVQyKUYGelj6XLIxg0M9YSfuwKVmkYczCy1dDlkIxhQiKgZ/cJawyK84eRw7YGeRFcjlUowsU9TK8rW1AILV0O2ggGFiJr5/VJAGd3T18KVkL3Qd/NsSy2ETserG9O1cR0UIjLSoNXhYGYZAOAGBhQykVE9fODqKEOhWoMTF1WGBdzIsorUdXho3R9wc5JjxoAgTOobCDeFdUQD66iCiKzG8ZwKVGka4eXigL5BXPuETEMhlyG+tz82p+RjW2oBA4oVEELgHz+cwOHspj9Idp4ugpNDCib0CcDMAcGI7+3XprV8zIVdPERkRD/+ZFRPX0il9rl4GFmGvptn6ylON7YG3ybnYNeZYjjKpfjrmEhE+LqirkGHzSfycd9XRzD61Z3QNGotVh9bUIjIiH78Cbt3yNTie/tDLpUgvagKWSXViOC1nSwmp6wGL25KBQAsn9wLfx3TA08lROPkRTU2Hr+ITcfzEROitGgLCgMKERlUaRrxx4UKAAwoZHpKZweMiPTBvnMlWLklDQ/E98DAMONl/nU6gX3nSrAhOQeJp4twy6AQPDe9L2eTmZBOJ/DE9ydQXa9FXLgX7rmhaa0jiUSC2FAlYkOVeCqhD1S1lr00AQMKERkcyixFo06gm7cLwrxdLF0O2aE5caHYd64EW1MLsTW1EN28XTBjQBDie/tjX3oJvj+Si4sVtYb91x66gBO5Kqy6YzD/TZrIlweycSCzFM4OMrw5ZwBkLXTlSqUSeLk6WqC6PzGgEJHBPk4vJjO7eWAIPF0c8ePRXGxLLcSFshp8sCsDH+zKMOzj4STHLYNCEBuixCtb0pByUYXp/96Hd+cPxLje/has3vZlFlfh1f+dBgA8PTUa3a24m40BhYgM9ONPboxiQCHzGdvLD2N7+aGmvhE70oqw8XgeDmaWIjZEiXlDwzClX6ChS2dkDx8sXXsUx3NVuHtNEh4eH4VHJkS1+Fc/XZ1WJ/D4d8dR16DDDT19ccfwcEuXdFUSIYTNrZijVquhVCqhUqng4cFpkESmUKSuw7BXdkAiAY4+O8nizbtEeppGLf7vl1R8ffACAMDTxQGje/jihihf3Bjli1Avdv20xbpDF/D0TylwV8jxv0fHIMTTudNraM/3N1tQiAgA8HtGU+tJTLCS4YSsikIuw0u3xGJwNy+8sCkVFTUN2JySj80pTRe0jPR1xRM3ReOmmEALV2q9qjWNeHvbWQDAo5N6WSSctBfXQSEiAMDedI4/Ies2a3Aojjw7ET88MBLLJkYhLtwLMqkEmSXVWLruKP53ktf5ac0nezJRUqVBuI8L7hxh3V07egwoRAQhBMefkE2Qy6QYEu6NZRN74fsHRuGPf07CrMEh0OoEHv7mKBLPFFm6RLMqqdJg8erD+OpAdpufU6Suw6d7MwEAT0yJhqPcNr76baNKIjKrjOIqFKo1UMilGBLuZelyiNrMw8kBr8/uj2mxQWjQCtz31REcyCht03Mraurx1cHzOF2gNnOVpvPW1jNIPFOMFzalIr2wsk3PeWd7OmrqtRgY5ompsbbTDdbugLJnzx7MmDEDwcHBkEgk+Pnnn40eX7x4MSQSidFtxIgRRvtoNBo8/PDD8PX1haurK2bOnInc3NwOvREiun77LnXvDO3uzQWxyObIZVK8M28gJkT7Q9Oowz1fJOHohfJW969r0OKj3RkY8/ouPPfzSSS8txePfXvMaP0VUyit0uCDXedw07t78NHujGs/4RrOFlZiQ1IOAKBRJ/DP/57Ctea5pBdWYkNS0+DiZ6b1MVoUz9q1O6BUV1djwIABeP/991vd56abbkJ+fr7htmXLFqPHly1bhp9++gnr16/Hvn37UFVVhenTp0Ortdya/0Rd2b5zTX9xcvwJ2SpHuRQf3DEYN/T0RU29Fos+P4zP92Vhb3ox8ipqodMJaHUC3yXnYPybiXj119NQ1zUiSOkEIYAfj17EuDcT8fLmVFTU1HeolhO5FXjs22MYuXIn3vjtDE4XVOLVX09j0/G8Dh331V9PQyeAYRHeUMilOJBZik0n8q/6nNf+1/ScyX0DMLS7d4dev7O1exZPQkICEhISrrqPQqFAYGDLzUgqlQqfffYZvvrqK0ycOBEA8PXXXyMsLAzbt2/HlClT2lsSEXWAVidwKKspoIzq4WPhaoiun5ODDJ8sHIJFnx9GUnY5Xvwl1fCYs4MM7k5yFFVqAADBSic8Nrk3bh0UgpMXVXj119M4kFmKT/dmYX1SDsJ9XFBbr0Vdgw61DVo0anWY2DcATyX0gZ+7osXXP5xVhtf+dxpHzv/ZejMgVIlQLxdsTsnH378/jkg/V/QLVrb7ve3PKMHO00WQSyV4dVYsNp/Ix1vbzuKlX1IxPtofbormX+cHM0uxPa0IMqkE/0iIbvdrWppZphknJibC398fnp6eGDt2LF5++WX4+zet/nfkyBE0NDRg8uTJhv2Dg4MRExOD/fv3txhQNBoNNBqN4b5abTv9hUTWLi1fjcq6Rrgp5OgXzHWFyLa5OMrx+eKh+HxfNk7mqZBRXIULpTWobdCitkELDyc5lo7riUWjuhu6MweEeWLdkuFIPFuM1349jdMFlTh5sfn3zI9HL2J7aiGeTOiD+UPDDFf7vlhRa9RC4iCTYFpsEBaN6o5B3byg1QlUahqx52wx/vrlEWx8aDR83FoOOS3R6QRWbmla/XXB8G6I9HPDkjGR+OFoLrJLa/De9rN4Zlpfo+c0anVYuSWt6TnDuqGHn1v7P0wLM3lASUhIwJw5cxAeHo6srCw899xzGD9+PI4cOQKFQoGCggI4OjrCy8t4IF5AQAAKClqeIrZy5Uq88MILpi6ViAAcyioDAAwJ94JcxnHzZPvcnRzwyMQow/0GrQ4XymqQX1GH2BAllC4OzZ4jkUgwrrc/xkT54VBWKTSNOjg7yJpujjKUVtXjpc2pOJWnxtM/peD7Izl4bnpf7D5bjI92Z6CuQQeJBJg/tBsenRgFfw8nw7FlUgn+PX8Qbv5gH7JLa7B03VF8dc9wOLTx523TiTykXFTBTSHHIxOa3peTgwzPz+yHu1Yn4fPfszEnLgy9AtwBAPvPleCFTak4U1gJV0cZ/jYh6mqHt1omDyjz5s0z/H9MTAzi4uIQHh6OzZs3Y9asWa0+TwjR6uCdp556Co899pjhvlqtRlhYmOmKJurCDmU2de8Mj7St/mmitnKQSdHDz61NrQgyqQSjerQwFisA+O/S0fjiwHm8vfUMjl6owK2r9hseHtbdG8/P7Ntq943SxQGfLIzDrR/8joOZZXh5cxpWzOx3zXrqGrR4/X9nAAAPxPcwankZ19sfk/sGYGtqIf7535N4ffYAvLIlDf871fTHvqeLA16dFdtql5S1M/ufS0FBQQgPD0d6ejoAIDAwEPX19SgvNx5hXVRUhICAgBaPoVAo4OHhYXQjoo7T6QQOZze1oAyP4PgToquRy6S454YIbH98LG7q1zTOMljphPcXDMKG+0Zcc2xJrwB3vDNvIABgzf5svLPtLKo0jVd9zpcHsnGxohaBHk64e3REs8efm94XTg5SHMwsw7i3EvG/UwWQSSVYNDIcicvjcVNM0PW9WStg9oBSWlqKnJwcBAU1fUhDhgyBg4MDtm3bZtgnPz8fJ0+exKhRo8xdDhFd5mxRJSpqGuDsIEP/0PYP3CPqioKUzvjoL0Owa3k8di6Px/T+wW2evju5XyCWXep+em9HOka/uhNvbT2Dkqo/x1kKIXCuqBKrf8/C+zvPAQAem9wLzo7NlwAI83bB0vieAJoGvI/u6YMtf7sRL9wcA08X275kRbu7eKqqqnDu3DnD/aysLBw7dgze3t7w9vbGihUrMHv2bAQFBSE7OxtPP/00fH19ceuttwIAlEol7rnnHjz++OPw8fGBt7c3li9fjtjYWMOsHiLqHIcy/xx/0tb+cCJqEuHrel3Pe2RCFIKVzvhwdwaySqrx753n8MmeTMweEoqGRh32nStBvqrOsH/fIA/MHhza6vHuj+8BZ0cZuvu4YkIff5ta6+Rq2h1QkpOTMW7cOMN9/diQRYsW4cMPP0RKSgq+/PJLVFRUICgoCOPGjcOGDRvg7u5ueM4777wDuVyOuXPnora2FhMmTMCaNWsgk3GBKKLOpJ9ePDyC40+IOotEIsHcoWGYPSQU21IL8OHuTBzPqcC6QxcM+zjKpRjW3Rs3Rvli3tAwyKSthw4HmRT33hjZGaV3Kom41jJ0Vqg9l2smopYJITD05e0oqarHt/eNxDCGFCKLEELgYGYZfjiaCy8XB9wY5YdhEfa5qnN7vr/Nsg4KEVm/jOIqlFTVQyGXYkAYx58QWYpEIsHIHj4YyYUSjbDTmaiLOnhp/Mmgbp5QyO3vLzUism0MKERdlH6BNk4vJiJrxIBC1AUJIXA4iwu0EZH1YkAh6oLOl9agUK2Bo0yKwd28rv0EIqJOxoBC1AXppxcPCFPa5UwBIrJ9DChEXZB+gTaOPyEia8WAQtQFGQbIcvwJEVkpBhSiLianrAYXK2ohl0owJJzjT4jIOjGgEHUx+taT2FAlXBy5ViMRWScGFKIu5lCm/vo7HH9CRNaLAYWoCxFCYN+5EgDACI4/ISIrxoBC1IWk5VciX1UHZwcZRkSyBYWIrBcDClEXsvN0IQBgdE9frn9CRFaNAYWoC9lxuggAMKGPv4UrISK6OgYUoi6ipEqDYzkVAIBxvRlQiMi6MaAQdRG7ThdBCCAmxAOBSidLl0NEdFUMKERdxM5L3TvjowMsXAkR0bUxoBB1AfWNOuw5WwwAmBDN7h0isn4MKERdwOGsMlTXa+HrpkBsiNLS5RARXRMDClEXsOPS9OLx0X6QSiUWroaI6NoYUIjsnBACO9I4/oSIbAsDCpGdyyiuxoWyGjjKpLghytfS5RARtQkDCpGd068eOzzSG24KXr2YiGwDAwqRndN370zsw+4dIrIdDChEdkxV04Dk8+UAgPGcXkxENoQBhciO7U4vhlYn0CvADWHeLpYuh4iozRhQiOzYzjT99GJ27xCRbWFAIbJj+u6dMZy9Q0Q2hgGFyE6pahuQW14LAOjH1WOJyMYwoBDZqbR8NQAg1MsZSmcHC1dDRNQ+DChEdio1rymg9AnysHAlRETtx4BCZKdSL7Wg9GVAISIbxIBCZKf0LSh9gxlQiMj2MKAQ2aH6Rh3SiyoBsAWFiGwTAwqRHcoorkKDVsDdSY5QL2dLl0NE1G4MKER2yNC9E+QBiURi4WqIiNqPAYXIDhkGyHL8CRHZqHYHlD179mDGjBkIDg6GRCLBzz//bHisoaEB//jHPxAbGwtXV1cEBwdj4cKFyMvLMzpGfHw8JBKJ0W3+/PkdfjNE1OTyFhQiIlvU7oBSXV2NAQMG4P3332/2WE1NDY4ePYrnnnsOR48exY8//oizZ89i5syZzfZdsmQJ8vPzDbePP/74+t4BERkRQrAFhYhsnry9T0hISEBCQkKLjymVSmzbts1o27///W8MGzYMFy5cQLdu3QzbXVxcEBgY2N6XJ6JryFPVQVXbAAeZBFH+7pYuh4jouph9DIpKpYJEIoGnp6fR9rVr18LX1xf9+vXD8uXLUVlZ2eoxNBoN1Gq10Y2IWqbv3unp7w5HOYeZEZFtancLSnvU1dXhySefxIIFC+Dh8WdT8x133IGIiAgEBgbi5MmTeOqpp3D8+PFmrS96K1euxAsvvGDOUonsBsefEJE9MFtAaWhowPz586HT6bBq1Sqjx5YsWWL4/5iYGERFRSEuLg5Hjx7F4MGDmx3rqaeewmOPPWa4r1arERYWZq7SiWxaar4KAMefEJFtM0tAaWhowNy5c5GVlYWdO3catZ60ZPDgwXBwcEB6enqLAUWhUEChUJijVCK7w2vwEJE9MHlA0YeT9PR07Nq1Cz4+Ptd8zqlTp9DQ0ICgoCBTl0PUpahqG5BTVguAAYWIbFu7A0pVVRXOnTtnuJ+VlYVjx47B29sbwcHBuO2223D06FH88ssv0Gq1KCgoAAB4e3vD0dERGRkZWLt2LaZOnQpfX1+kpqbi8ccfx6BBgzB69GjTvTOiLuj0pdaTEE9nKF0cLFwNEdH1a3dASU5Oxrhx4wz39WNDFi1ahBUrVmDjxo0AgIEDBxo9b9euXYiPj4ejoyN27NiB9957D1VVVQgLC8O0adPw/PPPQyaTdeCtEJG+e6cPW0+IyMa1O6DEx8dDCNHq41d7DADCwsKwe/fu9r4sEbWBYQYPB8gSkY3jIglEdoQDZInIXjCgENmJ+kYd0gurAAD92IJCRDaOAYXITmQUV6Feq4O7Qo5QL2dLl0NE1CEMKER2Qj/+pE+wByQSiYWrISLqGAYUIjvB8SdEZE8YUIjsBGfwEJE9YUAhsgNCCJzMu3QNHragEJEdYEAhsgMXympQWdcIR5kUvQLcLV0OEVGHMaAQ2YGUi02tJ9FB7nCU88eaiGwff5MR2QF9QIkJUVq4EiIi02BAIbIDJy8FlFgGFCKyEwwoRDZOCIGTF5tm8DCgEJG9YEAhsnE5ZbVQ1TZwgCwR2RUGFCIbpx9/0juQA2SJyH7wtxmRjeMAWSKyRwwoRDbupCGgcIE2IrIfDChENuzyFWQ5QJaI7AkDCpENyy2vRUVNAxxkEvQO5ABZIrIfDChENkzfvdMrwB0KuczC1RARmQ4DCpENS+ECbURkpxhQiGwYZ/AQkb1iQCGyUU0ryLIFhYjsEwMKkY26WFGL8poGyKUcIEtE9ocBhchGXT5A1smBA2SJyL4woBDZqBQu0EZEdowBhchG8QrGRGTPGFCIbNDlA2Q5g4eI7BEDCpENylfVobS6HjKpBH2C2MVDRPaHAYXIBunHn0T5u3GALBHZJQYUIhvE9U+IyN4xoBDZIMMS96EMKERknxhQiGyMVidw9Hw5AKB/qKdliyEiMhMGFCIbk5avhrquEW4KOWKCOUCWiOwTAwqRjTmYWQoAGNrdC3IZf4SJyD7xtxuRjTmYWQYAGBHpY+FKiIjMhwGFyIZodQKHsppaUBhQiMieMaAQ2ZC0fDUqL40/6cfxJ0Rkx9odUPbs2YMZM2YgODgYEokEP//8s9HjQgisWLECwcHBcHZ2Rnx8PE6dOmW0j0ajwcMPPwxfX1+4urpi5syZyM3N7dAbIeoK9ONPhkV4c/wJEdm1dv+Gq66uxoABA/D++++3+Pjrr7+Ot99+G++//z6SkpIQGBiISZMmobKy0rDPsmXL8NNPP2H9+vXYt28fqqqqMH36dGi12ut/J0RdgD6gjIj0tnAlRETmJW/vExISEpCQkNDiY0IIvPvuu3jmmWcwa9YsAMAXX3yBgIAArFu3Dvfddx9UKhU+++wzfPXVV5g4cSIA4Ouvv0ZYWBi2b9+OKVOmdODtENmvpvEnHCBLRF2DSduIs7KyUFBQgMmTJxu2KRQKjB07Fvv37wcAHDlyBA0NDUb7BAcHIyYmxrDPlTQaDdRqtdGNqKtJzWsaf+KukKMvLxBIRHbOpAGloKAAABAQEGC0PSAgwPBYQUEBHB0d4eXl1eo+V1q5ciWUSqXhFhYWZsqyiWwCx58QUVdilt9yEonE6L4Qotm2K11tn6eeegoqlcpwy8nJMVmtRLbiz/En7N4hIvtn0oASGBgIAM1aQoqKigytKoGBgaivr0d5eXmr+1xJoVDAw8PD6EbUlWh1Aoc5/oSIuhCTBpSIiAgEBgZi27Zthm319fXYvXs3Ro0aBQAYMmQIHBwcjPbJz8/HyZMnDfsQkbHUPDUqNZfGn3D9EyLqAto9i6eqqgrnzp0z3M/KysKxY8fg7e2Nbt26YdmyZXjllVcQFRWFqKgovPLKK3BxccGCBQsAAEqlEvfccw8ef/xx+Pj4wNvbG8uXL0dsbKxhVg8RGTuQWQKgafyJTHr17lIiInvQ7oCSnJyMcePGGe4/9thjAIBFixZhzZo1eOKJJ1BbW4sHH3wQ5eXlGD58OLZu3Qp3d3fDc9555x3I5XLMnTsXtbW1mDBhAtasWQOZTGaCt0Rkf/TX3xnZg907RNQ1SIQQwtJFtJdarYZSqYRKpeJ4FLJ7jVodBr24DZWaRvzy8A2ICVFauiQiouvSnu9vzlUksnKp+ZfGnzjJ0YfrnxBRF8GAQmTl9NOLh3P8CRF1IQwoRFZOP/6E04uJqCthQCGyYlqdQFJ2U0AZHsGAQkRdBwMKkRU7W1iJyrpGuDrK0CfI/dpPICKyEwwoRFYs+VLryeBwL15/h4i6FP7GI7JiSdlNl4QY2t3bwpUQEXUuBhQiKyXEn+NP4rp7XWNvIiL7woBCZKUuVtQiX1UHuVSCgWGeli6HiKhTMaAQWankS907/UKUcHFs91UpiIhsGgMKkZXSd+8MDWf3DhF1PQwoRFZK34ISxwGyRNQFMaAQWSFVTQPOFFYC4ABZIuqaGFCIrNCRC03dO5G+rvB1U1i4GiKizseAQmSFDmdx/RMi6toYUIisUDLXPyGiLo4BhcjK1DVocSJXBYAtKETUdTGgEFmZlIsq1Gt18HVTINzHxdLlEBFZBAMKkZUxrH/S3QsSicTC1RARWQYDCpGV4fonREQMKERWRacThgGyQzlAloi6MAYUIitytqgS6rpGuDjK0DfIw9LlEBFZDAMKkRVJutS9M6ibJ+Qy/ngSUdfF34BEVuTP7h2OPyGiro0BhciKHDl/aYBsOAMKEXVtDChEVqK0SoPc8loAQP8wpYWrISKyLAYUIiuhXz020s8VHk4OFq6GiMiyGFCIrMTx3AoAwIBQT4vWQURkDRhQiKzE8ZwKAMCAUHbvEBExoBBZASGEoYunf5inZYshIrICDChEVuBiRS1Kq+shl0q4QBsRERhQiKzC8Zym1pPoIHc4OcgsXA0RkeUxoBBZgROXBsj25wBZIiIADChEVkE/g2cgAwoREQAGFCKL0+oEUgwDZDmDh4gIYEAhsrjM4ipU12vh7CBDTz83S5dDRGQVGFCILOzYpfVPYkOUvIIxEdEl/G1IZGGG9U+4QBsRkYHJA0r37t0hkUia3ZYuXQoAWLx4cbPHRowYYeoyiGyGYQYPF2gjIjKQm/qASUlJ0Gq1hvsnT57EpEmTMGfOHMO2m266CatXrzbcd3R0NHUZRDZB06hFar4aAGfwEBFdzuQBxc/Pz+j+q6++ih49emDs2LGGbQqFAoGBgaZ+aSKbczq/Eg1aAS8XB4R5O1u6HCIiq2HWMSj19fX4+uuvcffdd0MikRi2JyYmwt/fH7169cKSJUtQVFR01eNoNBqo1WqjG5E90HfvxIZ6Gv2MEBF1dWYNKD///DMqKiqwePFiw7aEhASsXbsWO3fuxFtvvYWkpCSMHz8eGo2m1eOsXLkSSqXScAsLCzNn2USd5tilJe4HcoAsEZERiRBCmOvgU6ZMgaOjIzZt2tTqPvn5+QgPD8f69esxa9asFvfRaDRGAUatViMsLAwqlQoeHrywGtmuSW/vRnpRFf6zMA4T+wZYuhwiIrNSq9VQKpVt+v42+RgUvfPnz2P79u348ccfr7pfUFAQwsPDkZ6e3uo+CoUCCoXC1CUSWVSVphHniqsAcAVZIqIrma2LZ/Xq1fD398e0adOuul9paSlycnIQFBRkrlKIrFJKrgpCAMFKJ/i7O1m6HCIiq2KWgKLT6bB69WosWrQIcvmfjTRVVVVYvnw5Dhw4gOzsbCQmJmLGjBnw9fXFrbfeao5SiKwWr2BMRNQ6s3TxbN++HRcuXMDdd99ttF0mkyElJQVffvklKioqEBQUhHHjxmHDhg1wd3c3RylEVuu4YYE2du8QEV3JLAFl8uTJaGnsrbOzM3777TdzvCSRTamoqcfesyUAgEFhXhauhojI+vBaPEQW8OHuDFRqGhEd6I7hEd6WLoeIyOowoBB1skJ1Hdb8ng0AWD65N6RSLtBGRHQlBhSiTvavHenQNOowuJsnJvTxt3Q5RERWiQGFqBOdL63GhqQcAMATN0VzeXsiolYwoBB1ore3nUWjTmBMLz+MiPSxdDlERFaLAYWok6Tlq7HxeB4A4IkpvS1cDRGRdWNAIeokb/52BkIA02KDEBPCtU+IiK6GAYWoEyRnl2HH6SLIpBI8NrmXpcshIrJ6DChEneCd7WcBALcNDkUPPzcLV0NEZP0YUIjMLKO4Cr+fK4VUAjw8oaelyyEisgkMKERmtv7wBQDA+Gh/hHq5WLgaIiLbwIBCZEaaRi2+P5ILAJg/tJuFqyEish0MKERm9NupQpTXNCDQwwnxvf0sXQ4Rkc1gQCEyI333ztyhYZDL+ONGRNRW/I1JZCZZJdXYn1EKiQSYNzTM0uUQEdkUBhQiM1mf1NR6MraXH0I8nS1cDRGRbWFAITKD+kYdvk9uGhx7+zAOjiUiai8GFCIz2J5WiNLqevi7KzA+2t/S5RAR2RwGFCIz+EY/ODYuDA4cHEtE1G78zUlkYhdKa7A3vYSDY4mIOoABhcjENiQ3tZ7c0NMXYd5cOZaI6HowoBCZUF2DFhuScgBwcCwRUUcwoBCZ0M9/XERJVT1CPJ0xqW+ApcshIrJZDChEJqLTCXy6NxMAcNfo7hwcS0TUAfwNSmQiu84UIaO4Gu5Ocsxn9w4RUYcwoBCZyMd7mlpPFgzvBjeF3MLVEBHZNgYUIhM4llOBw1llkEsluGtUhKXLISKyeQwoRCagH3syc2AwApVOFq6GiMj2MaAQdVBOWQ1+TckHACy5MdLC1RAR2QcGFKIO+mxfFnQCGNPLD32CPCxdDhGRXWBAIeqAipp6fJvctDDbX9l6QkRkMgwoRB2w9tAF1NRr0SfIA6N7+li6HCIiu8GAQnSdhBCGqxYvuTECEonEwhUREdkPBhSi63S+tAa55bVwkElwU0ygpcshIrIrDChE1+n3jBIAwKBuXnBx5MJsRESmxIBCdJ32Z5QCAEb38LVwJURE9ocBheg66HQCB/QBhYNjiYhMzuQBZcWKFZBIJEa3wMA/++eFEFixYgWCg4Ph7OyM+Ph4nDp1ytRlEJnV6YJKlFXXw8VRhv6hnpYuh4jI7pilBaVfv37Iz8833FJSUgyPvf7663j77bfx/vvvIykpCYGBgZg0aRIqKyvNUQqRWey/NP5kWIQ3HOVsiCQiMjWz/GaVy+UIDAw03Pz8/AA0tZ68++67eOaZZzBr1izExMTgiy++QE1NDdatW2eOUojM4vdzTQGF40+IiMzDLAElPT0dwcHBiIiIwPz585GZ2XQhtaysLBQUFGDy5MmGfRUKBcaOHYv9+/e3ejyNRgO1Wm10I7KUBq0Oh7PKAACjOP6EiMgsTB5Qhg8fji+//BK//fYbPv30UxQUFGDUqFEoLS1FQUEBACAgIMDoOQEBAYbHWrJy5UoolUrDLSwszNRlE7XZidwKVNdr4eXigD6BvPYOEZE5mDygJCQkYPbs2YiNjcXEiROxefNmAMAXX3xh2OfKFTeFEFddhfOpp56CSqUy3HJyckxdNlGb/X6uafbOyB4+kEq5eiwRkTmYfXSfq6srYmNjkZ6ebpjNc2VrSVFRUbNWlcspFAp4eHgY3YgsRT/+ZBTHnxARmY3ZA4pGo0FaWhqCgoIQERGBwMBAbNu2zfB4fX09du/ejVGjRpm7FKIOq63X4o8LFQCA0T0ZUIiIzMXk63MvX74cM2bMQLdu3VBUVISXXnoJarUaixYtgkQiwbJly/DKK68gKioKUVFReOWVV+Di4oIFCxaYuhQik0vKLkO9VodgpRO6+7hYuhwiIrtl8oCSm5uL22+/HSUlJfDz88OIESNw8OBBhIeHAwCeeOIJ1NbW4sEHH0R5eTmGDx+OrVu3wt3d3dSlEJmcfnn7kT18efViIiIzkgghhKWLaC+1Wg2lUgmVSsXxKNSpZr6/DydyVXh77gDMGhxq6XKIiGxKe76/uQQmURupahqQclEFgONPiIjMjQGFqI0OZJZCCKCHnysCPJwsXQ4RkV1jQCFqI/31dzi9mIjI/BhQiNrIcP0dLm9PRGR2DChEbZBbXoOM4mpIJcDISLagEBGZGwMKURvsOdvUejK4mxeULg4WroaIyP4xoBC1we6zRQCAsb38LFwJEVHXwIBCdA0NWp3hAoFjezOgEBF1BgYUoms4er4cVZpGeLs6IiZYaelyiIi6BAYUomvYfbYYAHBjlC+kUi5vT0TUGRhQiK5BH1A4/oSIqPMwoBBdRXGlBqfy1ACAG6MYUIiIOgsDCtFV7E1vaj2JCfGAn7vCwtUQEXUdDChEV8HuHSIiy2BAIWqFViewxxBQ/C1cDRFR18KAQtSKkxdVKK9pgLtCjkHdPC1dDhFRl8KAQtQKfffO6J6+cJDxR4WIqDPxty5RKwzjT7h6LBFRp2NAIWqBqqYBf1woBwCM4QBZIqJOx4BC1IJ950qgE0CUvxtCPJ0tXQ4RUZfDgELUAl69mIjIshhQiK6g0wkknmkaf8LuHSIiy2BAIbrC8dwKFFVq4KaQY3ikt6XLISLqkhhQiK7w26lCAEB8bz8o5DILV0NE1DUxoBBdYWtqAQBgSr9AC1dCRNR1MaAQXeZcUSUyi6vhKJMinuufEBFZDAMK0WX03TujevrA3cnBwtUQEXVdDChEl9l6it07RETWgAGF6JJ8VS2O56ogkQAT+wRYuhwioi6NAYXokq2XuneGdPOCn7vCwtUQEXVtDChEl3D2DhGR9WBAIQJQUVOPg5llAIDJ/di9Q0RkaQwoRAB2pBVBqxOIDnRHuI+rpcshIuryGFCI8Gf3zmR27xARWQUGFOryauu12H226eKAk/uye4eIyBowoFCXtye9GHUNOoR4OqNfsIelyyEiIjCgWC1VbQMOZZYis7jK0qXYPf304sn9AiCRSCxcDRERAYDc0gUQIITAkfPlOJhZilN5apzMUyGnrNbweEJMIB6ZGIXoQP51b2oNWh22pzUFFE4vJiKyHiZvQVm5ciWGDh0Kd3d3+Pv745ZbbsGZM2eM9lm8eDEkEonRbcSIEaYuxeJ0OoGvDp7Hf/ZmIrukutnjWp3Aryn5uOWD33HbRwfw5taz+PVkgSGcBCmdIJEAv54swE3v7sXStUdxpqCys9+GXTuQUQpVbQN8XB0xtLu3pcshIqJLTN6Csnv3bixduhRDhw5FY2MjnnnmGUyePBmpqalwdf1z+uZNN92E1atXG+47OjqauhSL0jRqsfy7E9h0PA8A8NLmNET5u2FS3wBM7BuAMwWV+GRPJrIuBReFXIqJfQMwIFSJmGAl+gZ7wNPFEWcLK/HejnRsPpGPzSn52HIyH1Njg7BsQhSiAtwt+Rbtwq8nLy3OFhMImZTdO0RE1kIihBDmfIHi4mL4+/tj9+7dGDNmDICmFpSKigr8/PPP13VMtVoNpVIJlUoFDw/r6/ZQ1zXgvi+P4EBmKeRSCQaHe+Ho+XI06pp/1B5Ociwc2R2LR3eHr1vry6ufKajEezvOYktK0xeqRAJM7x+MRyb0RE9/46DSqNUho7gaMqkEkb6ukPKLt0WNWh2Gv7IDpdX1+OqeYbgxys/SJRER2bX2fH+bfQyKSqUCAHh7GzefJyYmwt/fH56enhg7dixefvll+Pv7t3gMjUYDjUZjuK9Wq81XcBvodAIf7DqH6notJvX1x8AwL8Nf3wWqOixefRinCyrh6ijDR38Zghuj/KCqaUDi2SJsTS3E7jPFUDo74K7R3TF/WDe4Ka59GnoHumPVHUOQlq/Gv3ak49eTBdh0PA+/nMjDjP7BGBbhjdR8NU5dVCGtoBL1jToAgKeLA4Z080Jcd2/EdffCgFBPOMo5NhoADmeXobS6Hp4uDhgR6WPpcoiI6DJmbUERQuDmm29GeXk59u7da9i+YcMGuLm5ITw8HFlZWXjuuefQ2NiII0eOQKFo3oqwYsUKvPDCC822W6oF5Yv92Xh+4ynDfV83R0zsE4BhEd5487czyFPVwc9dgdWLhyImRNns+UKIDs8WSc1T470dZ/HbpRkoV3JTyNGo06GuQWe0vU+QB358YBScHWUden178NzPJ/HVwfOYGxeK128bYOlyiIjsXntaUMwaUJYuXYrNmzdj3759CA0NbXW//Px8hIeHY/369Zg1a1azx1tqQQkLC7NIQLlQWoMp7+5BbYMWwyK8kZavRmVdo9E+kX6u+OKuYQjzdjF7PScvqvDp3kyU1zSgX7AH+gV7ICZYiW7eLmjUCZzKU+HI+XIkZ5dj37kSVGka8dz0vrjnhgiz12bNdDqB4St3oLhSg9V3DcW43i233hERkelYRRfPww8/jI0bN2LPnj1XDScAEBQUhPDwcKSnp7f4uEKhaLFlpbPpdAJP/HActQ1aDI/wxjdLRqBRJ3A4qwxbUwuw60wRwr1d8e/bB8HLtXMG/caEKPHe/EEtPuYolWBQNy8M6uaFe28Evjl8AU/9mIKPdmfgjuHd4OTQdVtRjlwoR3GlBu5Ocozu4WvpcoiI6AomDyhCCDz88MP46aefkJiYiIiIa/+lXlpaipycHAQFBZm6HJNae/gCDmaWwdlBhtdv6w+pVAJHqQQ3RPnihijr/5KbPTgU7+88h4sVtVh36ALu7sKtKFtS8gEAk/oEcEwOEZEVMvlv5qVLl+Lrr7/GunXr4O7ujoKCAhQUFKC2tmltj6qqKixfvhwHDhxAdnY2EhMTMWPGDPj6+uLWW281dTkmk1NWg5Vb0gAAT9zU2yaveOsol+LBcT0AAB/tzkBdg9bCFVmGTifwv0vTixNirTsUExF1VSYPKB9++CFUKhXi4+MRFBRkuG3YsAEAIJPJkJKSgptvvhm9evXCokWL0KtXLxw4cADu7ta5rocQAk/+eAI19VoM6+6NRSO7W7qk6zZnSBiClU4oqtRg/eELli7HIo7nViBfVQdXRxlutIGWLyKirsgsXTxX4+zsjN9++83UL2tW3xzOwe/nSuHkIMVrl7p2bFVTK0pPPPvzSXy4OwPzh3W9sSj6xdnG9wnocu+diMhW8Fo8LcirqEVSdhmOnC9HUnY5zhQ0rbvy9ynRiPC1va6dK82JC8UHu84hX1WHb5NzsNCGW4TaSwhhGH8yNYbX3iEislYMKJc5nlOBB74+gjxVXbPHbuoXiMWjund+UWagkMvwYHwPPPffU1i1KwPzhoZBIe8aLQmn8tTILa+Fs4MM8ZxaTERktRhQLhPs6Yw8VR1kUgn6BnkgrrsX4sKbVmAN8HCydHkmNXdoGD7YlYECdR2+2J+N0T19kV9RhzxVLS5W1MLXVYFZg0Pgc5Xl922RvvVkXLQfF6sjIrJiZr8WjzmY81o8Sdll6BvkAdc2LD9v665cEfdKjnIpZvQPxuJR3REb2nxFXFtRU9+I7WlF2HgsD7vPFqFBK/Cv2wdh5oBgS5dGRNSlWM1KsuZi7RcLtBV1DVrM+Pc+pBdVwcfVEcGezgj2dEKQ0hlHL5TjRK7KsO/gbp6YP6wb4nv5wd9GWpOOnC/DF/vPY1tqIWovm1J9Q09f/GdRHAfIEhF1MgYUajOdTqBeq2v2ZS2EwB85Ffhifza2pOSjQfvnP5PeAe64IcoXN0b5YkSkj9V90TdqdXh3ezo+SDwH/b/uMG9n3DwgBDMHBqNXgHVOZycisncMKGRSRZV1WH84B9vTCpFyUYXL/8UEK53w/QOjEOzpbLkCL3OxohaPfPMHks+XAwBuHRSChSPDMTDMs8MXaCQioo5hQCGzKa+ux+8ZJdiXXoLtaUUoqdIgNkSJ7+4fafGWlN9OFeCJ709AVdsAN4Ucr8yK5TgTIiIrwoBCnSKnrAYz39+H8poG3DooBG/PHWCRVoriSg3e3nYG3xzOAQAMCFXiX7cPssnLERAR2bP2fH/zKml03cK8XfDBHYMhk0rw0x8X8dm+rE59/SpNI97ZdhZj39hlCCd/HROJ7+4fxXBCRGTj7H8uLZnVqB6+eHZaH7ywKRWvbElD70B33BjlZ9bXbNDq8M3hC/jXjnSUVNUDAAaEeeLphGgMj/Qx62sTEVHnYEChDls8qjtO5anx/ZFcPLTuD2x8aLTZWjBOXlTh0Q3HkF5UBQDo7uOCv0+JxtTYQA6CJSKyIwwo1GESiQQv3RKD9KIqHM+pwOwPD2BwN0/08HdDpK8revi7wUEqRUZxFTKLq5BRXI2M4io06gQifV0R6eeGHn5N+/UKcIdbC4vkaXUCH+3OwLvbz6JBK+Dj6ohlE6Mwf1g3OMjYU0lEZG84SJZMpkBVh1tX/Y78Fq5l1FZyqQQjIn0wqW8AJvUNQLCnMy6U1uCxb48Zpg5P6ReAlbP6w9vV0VSlExFRJ+AsHrKYKk0jjp4vN2opySiuglYnEOnrhkg/V/Twc0MPf1fIpVLDfpklVThXVIVCtcboeP2CPZBdUo3qei3cFHKsmNkPsweHsDuHiMgGMaCQzcosrsK21EJsSy3EkQvlhkXhhnX3xltzByDM28WyBRIR0XVjQCG7UFKlwa7TRXB2lCEhJggyKVtNiIhsWXu+vzlIlqyWr5sCc+LCLF0GERFZAKc/EBERkdVhQCEiIiKrw4BCREREVocBhYiIiKwOAwoRERFZHQYUIiIisjoMKERERGR1GFCIiIjI6jCgEBERkdVhQCEiIiKrw4BCREREVocBhYiIiKwOAwoRERFZHZu8mrEQAkDTZZuJiIjINui/t/Xf41djkwGlsrISABAWFmbhSoiIiKi9KisroVQqr7qPRLQlxlgZnU6HvLw8uLu7QyKRmPTYarUaYWFhyMnJgYeHh0mPTe3H82FdeD6sC8+H9eE5uTohBCorKxEcHAyp9OqjTGyyBUUqlSI0NNSsr+Hh4cF/XFaE58O68HxYF54P68Nz0rprtZzocZAsERERWR0GFCIiIrI6DChXUCgUeP7556FQKCxdCoHnw9rwfFgXng/rw3NiOjY5SJaIiIjsG1tQiIiIyOowoBAREZHVYUAhIiIiq8OAQkRERFaHAYWIiIisDgPKZVatWoWIiAg4OTlhyJAh2Lt3r6VL6hJWrlyJoUOHwt3dHf7+/rjllltw5swZo32EEFixYgWCg4Ph7OyM+Ph4nDp1ykIVdy0rV66ERCLBsmXLDNt4PjrfxYsXceedd8LHxwcuLi4YOHAgjhw5Ynic56TzNDY24tlnn0VERAScnZ0RGRmJF198ETqdzrAPz4cJCBJCCLF+/Xrh4OAgPv30U5GamioeeeQR4erqKs6fP2/p0uzelClTxOrVq8XJkyfFsWPHxLRp00S3bt1EVVWVYZ9XX31VuLu7ix9++EGkpKSIefPmiaCgIKFWqy1Yuf07fPiw6N69u+jfv7945JFHDNt5PjpXWVmZCA8PF4sXLxaHDh0SWVlZYvv27eLcuXOGfXhOOs9LL70kfHx8xC+//CKysrLEd999J9zc3MS7775r2Ifno+MYUC4ZNmyYuP/++422RUdHiyeffNJCFXVdRUVFAoDYvXu3EEIInU4nAgMDxauvvmrYp66uTiiVSvHRRx9Zqky7V1lZKaKiosS2bdvE2LFjDQGF56Pz/eMf/xA33HBDq4/znHSuadOmibvvvtto26xZs8Sdd94phOD5MBV28QCor6/HkSNHMHnyZKPtkydPxv79+y1UVdelUqkAAN7e3gCArKwsFBQUGJ0fhUKBsWPH8vyY0dKlSzFt2jRMnDjRaDvPR+fbuHEj4uLiMGfOHPj7+2PQoEH49NNPDY/znHSuG264ATt27MDZs2cBAMePH8e+ffswdepUADwfpmKTVzM2tZKSEmi1WgQEBBhtDwgIQEFBgYWq6pqEEHjsscdwww03ICYmBgAM56Cl83P+/PlOr7ErWL9+PY4ePYqkpKRmj/F8dL7MzEx8+OGHeOyxx/D000/j8OHD+Nvf/gaFQoGFCxfynHSyf/zjH1CpVIiOjoZMJoNWq8XLL7+M22+/HQB/RkyFAeUyEonE6L4Qotk2Mq+HHnoIJ06cwL59+5o9xvPTOXJycvDII49g69atcHJyanU/no/Oo9PpEBcXh1deeQUAMGjQIJw6dQoffvghFi5caNiP56RzbNiwAV9//TXWrVuHfv364dixY1i2bBmCg4OxaNEiw348Hx3DLh4Avr6+kMlkzVpLioqKmiVgMp+HH34YGzduxK5duxAaGmrYHhgYCAA8P53kyJEjKCoqwpAhQyCXyyGXy7F7927861//glwuN3zmPB+dJygoCH379jXa1qdPH1y4cAEAf0Y629///nc8+eSTmD9/PmJjY/GXv/wFjz76KFauXAmA58NUGFAAODo6YsiQIdi2bZvR9m3btmHUqFEWqqrrEELgoYcewo8//oidO3ciIiLC6PGIiAgEBgYanZ/6+nrs3r2b58cMJkyYgJSUFBw7dsxwi4uLwx133IFjx44hMjKS56OTjR49utnU+7NnzyI8PBwAf0Y6W01NDaRS469PmUxmmGbM82EiFhyga1X004w/++wzkZqaKpYtWyZcXV1Fdna2pUuzew888IBQKpUiMTFR5OfnG241NTWGfV599VWhVCrFjz/+KFJSUsTtt9/OKXud6PJZPELwfHS2w4cPC7lcLl5++WWRnp4u1q5dK1xcXMTXX39t2IfnpPMsWrRIhISEGKYZ//jjj8LX11c88cQThn14PjqOAeUyH3zwgQgPDxeOjo5i8ODBhmmuZF4AWrytXr3asI9OpxPPP/+8CAwMFAqFQowZM0akpKRYrugu5sqAwvPR+TZt2iRiYmKEQqEQ0dHR4pNPPjF6nOek86jVavHII4+Ibt26CScnJxEZGSmeeeYZodFoDPvwfHScRAghLNmCQ0RERHQljkEhIiIiq8OAQkRERFaHAYWIiIisDgMKERERWR0GFCIiIrI6DChERERkdRhQiIiIyOowoBAREZHVYUAhIiIiq8OAQkRERFaHAYWIiIiszv8Dv8MzUrDh/uEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And see the results\n",
    "def smooth(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "plt.plot(smooth(episode_durations, 10))\n",
    "plt.title('Episode durations per episode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "rlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
