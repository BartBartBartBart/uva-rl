{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Deep Q Network\n",
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports %%execwritefile command (executes cell and writes it into file). \n",
    "# All cells that start with %%execwritefile should be in td_autograde.py file after running all cells.\n",
    "\n",
    "from custommagics import CustomMagics\n",
    "get_ipython().register_magics(CustomMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile dqn_autograde.py\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc69f22067705372",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 7, 0), \"Make sure you have Python 3.7 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fef7e20e54e6243b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1. Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-39519f4ab05eb2a1",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/miniconda3/envs/rlcourse/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.envs.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        CartPoleEnv\n",
      "\u001b[0;31mString form:\u001b[0m <CartPoleEnv<CartPole-v1>>\n",
      "\u001b[0;31mFile:\u001b[0m        ~/miniconda3/envs/rlcourse/lib/python3.7/site-packages/gym/envs/classic_control/cartpole.py\n",
      "\u001b[0;31mSource:\u001b[0m     \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mCartPoleEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m    Description:\u001b[0m\n",
      "\u001b[0;34m        A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum starts upright, and the goal is to prevent it from falling over by increasing and reducing the cart's velocity.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Source:\u001b[0m\n",
      "\u001b[0;34m        This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Observation: \u001b[0m\n",
      "\u001b[0;34m        Type: Box(4)\u001b[0m\n",
      "\u001b[0;34m        Num     Observation                 Min         Max\u001b[0m\n",
      "\u001b[0;34m        0       Cart Position             -4.8            4.8\u001b[0m\n",
      "\u001b[0;34m        1       Cart Velocity             -Inf            Inf\u001b[0m\n",
      "\u001b[0;34m        2       Pole Angle                 -24°           24°\u001b[0m\n",
      "\u001b[0;34m        3       Pole Velocity At Tip      -Inf            Inf\u001b[0m\n",
      "\u001b[0;34m        \u001b[0m\n",
      "\u001b[0;34m    Actions:\u001b[0m\n",
      "\u001b[0;34m        Type: Discrete(2)\u001b[0m\n",
      "\u001b[0;34m        Num     Action\u001b[0m\n",
      "\u001b[0;34m        0       Push cart to the left\u001b[0m\n",
      "\u001b[0;34m        1       Push cart to the right\u001b[0m\n",
      "\u001b[0;34m        \u001b[0m\n",
      "\u001b[0;34m        Note: The amount the velocity is reduced or increased is not fixed as it depends on the angle the pole is pointing. This is because the center of gravity of the pole increases the amount of energy needed to move the cart underneath it\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Reward:\u001b[0m\n",
      "\u001b[0;34m        Reward is 1 for every step taken, including the termination step\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Starting State:\u001b[0m\n",
      "\u001b[0;34m        All observations are assigned a uniform random value between ±0.05\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Episode Termination:\u001b[0m\n",
      "\u001b[0;34m        Pole Angle is more than ±12°\u001b[0m\n",
      "\u001b[0;34m        Cart Position is more than ±2.4 (center of the cart reaches the edge of the display)\u001b[0m\n",
      "\u001b[0;34m        Episode length is greater than 200\u001b[0m\n",
      "\u001b[0;34m        Solved Requirements\u001b[0m\n",
      "\u001b[0;34m        Considered solved when the average reward is greater than or equal to 195.0 over 100 consecutive trials.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'render.modes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'video.frames_per_second'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9.8\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasscart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasscart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;31m# actually half the pole's length\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.02\u001b[0m  \u001b[0;31m# seconds between state updates\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'euler'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Angle at which to fail the episode\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.4\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Angle limit set to 2 * theta_threshold_radians so failing observation is still within bounds\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mhigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%r (%s) invalid\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mforce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcostheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msintheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msintheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mthetaacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msintheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcostheta\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mxacc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'euler'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# semi-implicit euler\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta_dot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Pole just fell!\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscreen_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscreen_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mworld_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscreen_width\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mworld_width\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcarty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;31m# TOP OF CART\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpolewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpolelen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0maxleoffset\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolelen\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxleoffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_circle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;31m# MIDDLE OF CART\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcartx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# env is a TimeLimit wrapper around an env, so use env.env to look into the env (but otherwise you can forget about this)\n",
    "??env.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nice thing about the CARTPOLE is that it has very nice rendering functionality (if you are on a local environment). Let's have a look at an episode\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "done = False\n",
    "while not done:\n",
    "    obs, reward, done, _ = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "env.close() # Close the environment or you will have a lot of render screens soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2d83f70e62b99520",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Remember from the previous lab, that in order to optimize a policy we need to estimate the Q-values (e.g. estimate the *action* values). In the CartPole problem, our state is the current position of the cart, the current velocity of the cart, the current (angular) position of the pole and the (angular) speed of the pole. As these are continuous variables, we have an infinite number of states (ignoring the fact that a digital computer can only represent finitely many states in finite memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b3162496f5e6cf5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.1 Implement Q-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96a86bcfa1ebc84a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We will not use the tabular approach but approximate the Q-value function by a general approximator function. We will skip the linear case and directly use a two layer Neural Network. We use [PyTorch](https://pytorch.org/) to implement the network, as this will allow us to train it easily later. We can implement a model using `torch.nn.Sequential`, but with PyTorch it is actually very easy to implement the model (e.g. the forward pass) from scratch. Now implement the `QNetwork.forward` function that uses one hidden layer with ReLU activation (no output activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-216429a5dccf8a0e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_hidden=128):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-00ce108d640a5942",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's instantiate and test if it works\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1)\n",
    "Q_net = QNetwork(num_hidden)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "test_model = nn.Sequential(\n",
    "    nn.Linear(4, num_hidden), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(num_hidden, 2)\n",
    ")\n",
    "\n",
    "x = torch.rand(10, 4)\n",
    "\n",
    "# If you do not need backpropagation, wrap the computation in the torch.no_grad() context\n",
    "# This saves time and memory, and PyTorch complains when converting to numpy\n",
    "with torch.no_grad():\n",
    "    assert np.allclose(Q_net(x).numpy(), test_model(x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ca77eae2e62180cf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.2 Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2c1d117a1a75fd69",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to stabilize learning, we will use an experience replay to save states in and sample states from. Now implement the `push` function that adds a transition to the replay buffer, and the `sample` function that samples a (random!) batch of data, for use during training (hint: you can use the function `random.sample`). It should keep at most the maximum number of transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a3cc876e51eb157f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, transition):\n",
    "        # YOUR CODE HERE\n",
    "        if len(self.memory) >= self.capacity:\n",
    "            self.memory.pop(0)\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # YOUR CODE HERE\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3b90135921c4da76",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([ 0.03144807, -0.03402679, -0.03618021, -0.03736154]), 0, 1.0, array([ 0.03076753, -0.22861173, -0.03692745,  0.2436902 ]), False)]\n"
     ]
    }
   ],
   "source": [
    "capacity = 10\n",
    "memory = ReplayMemory(capacity)\n",
    "\n",
    "# Sample a transition\n",
    "s = env.reset()\n",
    "a = env.action_space.sample()\n",
    "s_next, r, done, _ = env.step(a)\n",
    "\n",
    "# Push a transition\n",
    "memory.push((s, a, r, s_next, done))\n",
    "\n",
    "# Sample a batch size of 1\n",
    "print(memory.sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88f67e3c051da6a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.3 $\\epsilon$psilon Greedy Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aa3c7d1b3000f697",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to learn a good policy, we need to explore quite a bit initially. As we start to learn a good policy, we want to decrease the exploration. As the amount of exploration using an $\\epsilon$-greedy policy is controlled by $\\epsilon$, we can define an 'exploration scheme' by writing $\\epsilon$ as a function of time. There are many possible schemes, but we will use a simple one: we will start with only exploring (so taking random actions) at iteration 0, and then in 1000 iterations linearly anneal $\\epsilon$ such that after 1000 iterations we take random (exploration) actions with 5\\% probability (forever, as you never know if the environment will change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5789e7a792108576",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def get_epsilon(it):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    epsilon = max(1.0 - (it / 1000) * (1.0 - 0.05), 0.05)\n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-40e66db45e742b2e",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe35d4c0410>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So what's an easy way to check?\n",
    "plt.plot([get_epsilon(it) for it in range(5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8b604c9998c6c3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now write a function of *EpsilonGreedyPolicy* class. This function takes a state and uses the Q-network to select an ($\\epsilon$-greedy) action. It should return a random action with probability epsilon. Note, you do not need to backpropagate through the model computations, so use `with torch.no_grad():` (see above for example). Note that to convert a PyTorch tensor with only 1 element (0 dimensional) to a simple python scalar (int or float), you can use the '.item()' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-878ad3a637cfb51c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class EpsilonGreedyPolicy(object):\n",
    "    \"\"\"\n",
    "    A simple epsilon greedy policy.\n",
    "    \"\"\"\n",
    "    def __init__(self, Q, epsilon):\n",
    "        self.Q = Q\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def sample_action(self, obs):\n",
    "        \"\"\"\n",
    "        This method takes a state as input and returns an action sampled from this policy.  \n",
    "\n",
    "        Args:\n",
    "            obs: current state\n",
    "\n",
    "        Returns:\n",
    "            An action (int).\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        with torch.no_grad():\n",
    "            # Exploratory action\n",
    "            if np.random.rand() < self.epsilon:\n",
    "                action = np.random.randint(2)\n",
    "            # Greedy action\n",
    "            else:\n",
    "                action = torch.argmax(self.Q(torch.tensor(obs).float())).item()\n",
    "        \n",
    "        return action\n",
    "        \n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e895338d56bee477",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "epg = EpsilonGreedyPolicy(Q_net, 0.05)\n",
    "a = epg.sample_action(s)\n",
    "assert not torch.is_tensor(a)\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 975, 1: 25}\n"
     ]
    }
   ],
   "source": [
    "counts = {0: 0, 1: 0}\n",
    "for i in range(1000):\n",
    "    s = env.reset()\n",
    "    counts[epg.sample_action(s)] += 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec5e94e0b03f8aec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d1a12cc97386fe56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we will implement the function 'train' that samples a batch from the memory and performs a gradient step using some convenient PyTorch functionality. However, you still need to compute the Q-values for the (state, action) pairs in the experience, as well as their target (e.g. the value they should move towards). What is the target for a Q-learning update? What should be the target if `next_state` is terminal (e.g. `done`)?\n",
    "\n",
    "For computing the Q-values for the actions, note that the model returns all action values where you are only interested in a single action value. Because of the batch dimension, you can't use simple indexing, but you may want to have a look at [torch.gather](https://pytorch.org/docs/stable/torch.html?highlight=gather#torch.gather) or use [advanced indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html) (numpy tutorial but works mostly the same in PyTorch). Note, you should NOT modify the function train. You can view the size of a tensor `x` with `x.size()` (similar to `x.shape` in numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c45485324b40081",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def compute_q_vals(Q, states, actions):\n",
    "    \"\"\"\n",
    "    This method returns Q values for given state action pairs.\n",
    "    \n",
    "    Args:\n",
    "        Q: Q-net\n",
    "        states: a tensor of states. Shape: batch_size x obs_dim\n",
    "        actions: a tensor of actions. Shape: Shape: batch_size x 1\n",
    "\n",
    "    Returns:\n",
    "        A torch tensor filled with Q values. Shape: batch_size x 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    Q_values = Q(states).gather(1, actions)\n",
    "    return Q_values\n",
    "\n",
    "    \n",
    "def compute_targets(Q, rewards, next_states, dones, discount_factor):\n",
    "    \"\"\"\n",
    "    This method returns targets (values towards which Q-values should move).\n",
    "    \n",
    "    Args:\n",
    "        Q: Q-net\n",
    "        rewards: a tensor of rewards. Shape: Shape: batch_size x 1\n",
    "        next_states: a tensor of states. Shape: batch_size x obs_dim\n",
    "        dones: a tensor of boolean done flags (indicates if next_state is terminal) Shape: batch_size x 1\n",
    "        discount_factor: discount\n",
    "    Returns:\n",
    "        A torch tensor filled with target values. Shape: batch_size x 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    max_next_Q = Q(next_states).max(1)[0][:, None]\n",
    "    bool_mask = torch.logical_not(dones)\n",
    "    targets = rewards + discount_factor * max_next_Q * bool_mask\n",
    "\n",
    "    return targets\n",
    "\n",
    "def train(Q, memory, optimizer, batch_size, discount_factor):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "    \n",
    "    # don't learn without some decent experience\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "\n",
    "    # random transition batch is taken from experience replay memory\n",
    "    transitions = memory.sample(batch_size)\n",
    "    \n",
    "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
    "    state, action, reward, next_state, done = zip(*transitions)\n",
    "    \n",
    "    # convert to PyTorch and define types\n",
    "    state = torch.tensor(state, dtype=torch.float)\n",
    "    action = torch.tensor(action, dtype=torch.int64)[:, None]  # Need 64 bit to use them as index\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float)\n",
    "    reward = torch.tensor(reward, dtype=torch.float)[:, None]\n",
    "    done = torch.tensor(done, dtype=torch.uint8)[:, None]  # Boolean\n",
    "    \n",
    "    # compute the q value\n",
    "    q_val = compute_q_vals(Q, state, action)\n",
    "    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n",
    "        target = compute_targets(Q, reward, next_state, done, discount_factor)\n",
    "    \n",
    "    # loss is measured from error between current and newly expected Q values\n",
    "    loss = F.smooth_l1_loss(q_val, target)\n",
    "\n",
    "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()  # Returns a Python scalar, and releases history (similar to .detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b060b822eec4282f",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46689027547836304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/miniconda3/envs/rlcourse/lib/python3.7/site-packages/ipykernel_launcher.py:54: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /croot/pytorch_1675190298929/work/torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    }
   ],
   "source": [
    "# You may want to test your functions individually, but after you do so lets see if the method train works.\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "# Simple gradient descent may take long, so we will use Adam\n",
    "optimizer = optim.Adam(Q_net.parameters(), learn_rate)\n",
    "\n",
    "# We need a larger memory, fill with dummy data\n",
    "transition = memory.sample(1)[0]\n",
    "memory = ReplayMemory(10 * batch_size)\n",
    "for i in range(batch_size):\n",
    "    memory.push(transition)\n",
    "\n",
    "# Now let's see if it works\n",
    "loss = train(Q_net, memory, optimizer, batch_size, discount_factor)\n",
    "\n",
    "print (loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3eafd0ab49103f3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-36b8a04b393d8104",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now that you have implemented the training step, you should be able to put everything together. Implement the function `run_episodes` that runs a number of episodes of DQN training. It should return the durations (e.g. number of steps) of each episode. Note: we pass the train function as an argument such that we can swap it for a different training step later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-540a7d50ecc1d046",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def run_episodes(train, Q, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate):\n",
    "    \n",
    "    optimizer = optim.Adam(Q.parameters(), learn_rate)\n",
    "    \n",
    "    global_steps = 0  # Count the steps (do not reset at episode start, to compute epsilon)\n",
    "    episode_durations = []  #\n",
    "    for i in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        \n",
    "        steps = 0\n",
    "        while True:\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            epsilon = get_epsilon(global_steps)\n",
    "            policy.set_epsilon(epsilon)\n",
    "            action = policy.sample_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.push((state, action, reward, next_state, done))\n",
    "            train(Q, memory, optimizer, batch_size, discount_factor)\n",
    "            state = next_state\n",
    "            steps += 1\n",
    "            global_steps += 1\n",
    "            \n",
    "            if done:\n",
    "                if i % 10 == 0:\n",
    "                    print(\"{2} Episode {0} finished after {1} steps\"\n",
    "                          .format(i, steps, '\\033[92m' if steps >= 195 else '\\033[99m'))\n",
    "                episode_durations.append(steps)\n",
    "                break\n",
    "    return episode_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 0 finished after 23 steps\n",
      "\u001b[99m Episode 10 finished after 10 steps\n",
      "\u001b[99m Episode 20 finished after 23 steps\n",
      "\u001b[99m Episode 30 finished after 19 steps\n",
      "\u001b[99m Episode 40 finished after 73 steps\n",
      "\u001b[99m Episode 50 finished after 110 steps\n",
      "\u001b[99m Episode 60 finished after 183 steps\n",
      "\u001b[99m Episode 70 finished after 166 steps\n",
      "\u001b[99m Episode 80 finished after 167 steps\n",
      "\u001b[99m Episode 90 finished after 154 steps\n"
     ]
    }
   ],
   "source": [
    "# Let's run it!\n",
    "num_episodes = 100\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "memory = ReplayMemory(10000)\n",
    "num_hidden = 128\n",
    "seed = 42  # This is not randomly chosen\n",
    "\n",
    "# We will seed the algorithm (before initializing QNetwork!) for reproducibility\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "\n",
    "Q_net = QNetwork(num_hidden)\n",
    "policy = EpsilonGreedyPolicy(Q_net, 0.05)\n",
    "episode_durations = run_episodes(train, Q_net, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-928ecc11ed5c43d8",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Episode durations per episode')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGxCAYAAABIjE2TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABV20lEQVR4nO3deVyU1f4H8M8wzAz7sAyr7IqigrjgbuGWhqaVLZqZ2uKvW7ZYebu23axbedu7NzOrW5ppaatZeW+5L7mBhuIOgggCsjMMyzDMnN8fyOQIKMgMM8N83q/XvIrnOfPMd3iQ+XCec84jEUIIEBEREdkQJ2sXQERERHQ5BhQiIiKyOQwoREREZHMYUIiIiMjmMKAQERGRzWFAISIiIpvDgEJEREQ2hwGFiIiIbA4DChEREdkcBhSyeStXroREImn1sX379nYfc/v27df83I4YPXo0Ro8e3WVepzUbN27E4sWLW9wXGRmJuXPndmo9jm7u3LmIjIzs1Nc8e/YsJBIJVq5c2amvS12Hs7ULIGqrFStWIDY2ttn2Pn36tPtYAwcOxN69e6/puXR1GzduxAcffNBiSPnhhx/g5eXV+UU5sBdeeAGPP/64tcsgahcGFLIbcXFxSExMNMuxvLy8MGzYMLMcyxHU1NTAzc3NLMcaMGCAWY5jz8z5/WyL7t27d9prEZkLL/FQlyKRSPDII4/go48+Qs+ePaFQKNCnTx+sXbvWpF1Ll3iysrIwY8YMhISEQKFQIDAwEOPGjUNaWpqxjcFgwBtvvIHY2FgoFAoEBARg9uzZyMvLMzm+EAJvvPEGIiIi4OLigoEDB+K///1vizWr1WosXLgQUVFRkMvl6NatGxYsWIDq6uqrvt+2vk7TZbKzZ89e9fswevRoxMXFYefOnRgxYgTc3Nxw3333AQDWrVuHCRMmIDg4GK6urujduzcWLVpkUuvcuXPxwQcfAIDJpbim127pEs+5c+cwa9YsBAQEQKFQoHfv3nj77bdhMBiMbZouGbz11lt45513EBUVBQ8PDwwfPhz79u0zOV5bzmVL5s6dCw8PDxw7dgzjxo2Du7s7/P398cgjj6CmpqbZ937ZsmXo378/XF1d4ePjg9tvvx1ZWVkm7a70/WxNamoqpk6dCl9fX7i4uGDAgAH4+uuvTdo0ndNNmzbh3nvvha+vL9zd3TFlypRmNbR0ieebb77B0KFDoVQq4ebmhujo6GZ1teW8AEB+fj7uvPNOeHp6QqlUYvr06SgsLLzm90YEsAeF7Iher0dDQ4PJNolEAqlUarJtw4YN2LZtG15++WW4u7tj2bJluOuuu+Ds7Izbb7+91eNPmjQJer0eb7zxBsLDw1FSUoI9e/agoqLC2Oahhx7Cxx9/jEceeQQ33XQTzp49ixdeeAHbt2/HoUOHoFKpAAAvvfQSXnrpJdx///24/fbbkZubi3nz5kGv16NXr17G49XU1CApKQl5eXl49tln0a9fPxw7dgx///vfkZ6ejs2bN0MikbRac1tfp70KCgowa9YsPP3003jttdfg5NT4t0xGRgYmTZqEBQsWwN3dHSdPnsTrr7+OAwcOYOvWrQAaLydUV1fj22+/xd69e43HDA4ObvG1iouLMWLECNTX1+Mf//gHIiMj8fPPP2PhwoU4c+YMli1bZtL+gw8+QGxsLN577z3j602aNAnZ2dlQKpUA2nYuW6PT6TBp0iQ8+OCDWLRoEfbs2YNXXnkFOTk5+Omnn4ztHnzwQaxcuRKPPfYYXn/9dZSVleHll1/GiBEjcPjwYQQGBl71+9mSbdu24cYbb8TQoUOxfPlyKJVKrF27FtOnT0dNTU2zcHf//ffjhhtuwJdffonc3Fw8//zzGD16NI4cOQJvb+8WX2Pv3r2YPn06pk+fjsWLF8PFxQU5OTnGc9ie81JbW4vx48cjPz8fS5YsQc+ePfHLL79g+vTpHX5v5OAEkY1bsWKFANDiQyqVmrQFIFxdXUVhYaFxW0NDg4iNjRU9evQwbtu2bZsAILZt2yaEEKKkpEQAEO+9916rdZw4cUIAEA8//LDJ9v379wsA4tlnnxVCCFFeXi5cXFzErbfeatLu999/FwBEUlKScduSJUuEk5OTSElJMWn77bffCgBi48aNrdbTntdp+h5mZ2ebtL38+yCEEElJSQKA2LJlS6uvLYQQBoNB6HQ6sWPHDgFAHD582Lhv/vz5orVfLxEREWLOnDnGrxctWiQAiP3795u0e+ihh4REIhGnTp0SQgiRnZ0tAIj4+HjR0NBgbHfgwAEBQHz11VdCiLady9bMmTNHABD/+te/TLa/+uqrAoDYvXu3EEKIvXv3CgDi7bffNmmXm5srXF1dxdNPP23c1tbvZ5PY2FgxYMAAodPpTLbfdNNNIjg4WOj1eiHEn+e0tfP/yiuvmLyviIgI49dvvfWWACAqKiparaOt5+XDDz8UAMSPP/5o0m7evHkCgFixYkW73xuREELwEg/ZjVWrViElJcXksX///mbtxo0bZ/LXq1QqxfTp05GZmdnsUkwTX19fdO/eHW+++Sbeeecd/PHHH826sbdt2wYAzf7KGzJkCHr37o0tW7YAaPzrtK6uDnfffbdJuxEjRiAiIsJk288//4y4uDj0798fDQ0NxsfEiROvOsuoPa/TXj4+Phg7dmyz7VlZWZg5cyaCgoIglUohk8mQlJQEADhx4sQ1vdbWrVvRp08fDBkyxGT73LlzIYQw+aseACZPnmzSa9avXz8AQE5ODoC2ncurufx7OnPmTAB//gz8/PPPkEgkmDVrlsl5CwoKQkJCQrPz1tr383KZmZk4efKk8fUvPfakSZNQUFCAU6dOXbHWpvPfVGtLBg8eDAC488478fXXX+P8+fPN2rT1vGzbtg2enp6YOnWqSbum71lH3hs5NgYUshu9e/dGYmKiyWPQoEHN2gUFBbW6rbS0tMVjSyQSbNmyBRMnTsQbb7yBgQMHwt/fH4899hiqqqpMntvSpYqQkBDj/qb/XqmOJhcuXMCRI0cgk8lMHp6enhBCoKSkpNXvR3tep71aeo8ajQbXXXcd9u/fj1deeQXbt29HSkoKvv/+ewCNXf3XorS0tNXvadP+S/n5+Zl8rVAoTF6/LefySpydnZu9xuU/PxcuXIAQAoGBgc3O3b59+5qdt9Yub13uwoULAICFCxc2O+7DDz8MAM2O3dr5b+1nHQCuv/56rF+/Hg0NDZg9ezZCQ0MRFxeHr776ytimreeltLTU5A+C1uq6lvdGjo1jUKjLaWlwXtO2yz94LhUREYFPP/0UAHD69Gl8/fXXWLx4Merr67F8+XLjcwsKChAaGmry3Pz8fOP4k6Z2rdVx6WBFlUoFV1dXfPbZZy3W1HTMlrTndVxcXAAAWq3WpF1rHwgtjXvZunUr8vPzsX37dmOvCYA2jeu4Ej8/PxQUFDTbnp+fD+DK34PWXO1cXklDQwNKS0tNflYu//lRqVSQSCTYtWuXMSBd6vJtVxpHdKmm9/rMM89g2rRpLba5fGxRa+e/R48eV3ytm2++GTfffDO0Wi327duHJUuWYObMmYiMjMTw4cPbfF78/Pxw4MCBFmvo6Hsjx8YeFOpytmzZYvxrDWgcXLtu3Tp07969WbBoTc+ePfH8888jPj4ehw4dAgBjF/3q1atN2qakpODEiRMYN24cAGDYsGFwcXHBmjVrTNrt2bPHeBmiyU033YQzZ87Az8+vWe9QYmLiFRfXas/rNB3nyJEjJts3bNhwhe+CqaYP2cs/fD/66KNmbS/v1biScePG4fjx48bvc5NVq1ZBIpFgzJgxba6xJS2dy6u5/Hv65ZdfAoBx8bubbroJQgicP3++xfMWHx9/TbX26tULMTExOHz4cIvHTUxMhKen5xVrbTr/bV2oT6FQICkpCa+//joA4I8//gDQ9vMyZswYVFVVNftZavqedeS9kWNjDwrZjaNHjzabxQM0rvHg7+9v/FqlUmHs2LF44YUXjLN4Tp482Wyq8aWOHDmCRx55BHfccQdiYmIgl8uxdetWHDlyBIsWLQLQ+Av2//7v//D+++/DyckJycnJxlk8YWFheOKJJwA0jjdYuHAhXnnlFTzwwAO44447kJubi8WLFzfr9l6wYAG+++47XH/99XjiiSfQr18/GAwGnDt3Dr/99hueeuopDB06tMWa2/M6gwcPRq9evbBw4UI0NDTAx8cHP/zwA3bv3t22bz4axzb4+PjgL3/5C1588UXIZDKsWbMGhw8fbta26QP69ddfR3JyMqRSKfr16we5XN6s7RNPPIFVq1Zh8uTJePnllxEREYFffvkFy5Ytw0MPPYSePXu2uUagbefySuRyOd5++21oNBoMHjzYOIsnOTkZo0aNAgCMHDkS//d//4d7770XqampuP766+Hu7o6CggLs3r0b8fHxeOihh9pVd5OPPvoIycnJmDhxIubOnYtu3bqhrKwMJ06cwKFDh/DNN9+YtE9NTTU5/8899xy6detmvGzSkr///e/Iy8vDuHHjEBoaioqKCvzrX/8yGVPU1vMye/ZsvPvuu5g9ezZeffVVxMTEYOPGjfj11187/N7IwVl1iC5RG1xpFg8A8cknnxjbAhDz588Xy5YtE927dxcymUzExsaKNWvWmBzz8tkrFy5cEHPnzhWxsbHC3d1deHh4iH79+ol3333XZMaIXq8Xr7/+uujZs6eQyWRCpVKJWbNmidzcXJPjGwwGsWTJEhEWFibkcrno16+f+Omnn0RSUpLJ7BohhNBoNOL5558XvXr1EnK5XCiVShEfHy+eeOIJk9lILWnP65w+fVpMmDBBeHl5CX9/f/Hoo4+KX375pcVZPH379m3x9fbs2SOGDx8u3NzchL+/v3jggQfEoUOHms3W0Gq14oEHHhD+/v5CIpGYzCC6fBaPEELk5OSImTNnCj8/PyGTyUSvXr3Em2++aTKro2kWz5tvvtmsLgDixRdfFEK0/Vy2ZM6cOcLd3V0cOXJEjB49Wri6ugpfX1/x0EMPCY1G06z9Z599JoYOHSrc3d2Fq6ur6N69u5g9e7ZITU1t0/ezNYcPHxZ33nmnCAgIEDKZTAQFBYmxY8eK5cuXG9s0/bv47bffxD333CO8vb2Fq6urmDRpksjIyGj2vi6dxfPzzz+L5ORk0a1bNyGXy0VAQICYNGmS2LVrl8nz2nJehBAiLy9P3HbbbcLDw0N4enqK2267TezZs6fZz0Vb3xuREEJIhBCi82MRkWVIJBLMnz8fS5cutXYpZIfmzp2Lb7/9FhqNxtqlXNXKlStx7733IiUlxWwrLBPZEo5BISIiIpvDgEJEREQ2h5d4iIiIyOawB4WIiIhsDgMKERER2RwGFCIiIrI5drlQm8FgQH5+Pjw9Pdu8hDQRERFZlxACVVVVCAkJgZPTlftI7DKg5OfnIywszNplEBER0TXIzc296q1H7DKgNN2vITc3F15eXlauhoiIiNpCrVYjLCysTfddssuA0nRZx8vLiwGFiIjIzrRleAYHyRIREZHNYUAhIiIim8OAQkRERDaHAYWIiIhsDgMKERER2RwGFCIiIrI5DChERERkcxhQiIiIyOYwoBAREZHNYUAhIiIim8OAQkRERDaHAYWIiIhsDgMKERF1WKlGi2XbM3G+otbapVAXYZd3MyYiIttRqtFixsf7kFGkQVZxNd66I8HaJVEXwB4UIiK6ZhU19Zj16QFkFGkAAEfyKqxbEHUZDChERHRN1HU6zP7sAE4UqOHtJgMAZBZpUFuvt3Jl1BUwoBARUbtptA2Y+9kBHMmrhK+7HF8/OBwqDzkMAjhRqLZ2edQFMKAQEVG7VGsbcN/KFBw6VwEvF2d8cf8Q9Az0RN8QJQDgWD4DCnUcAwoREbXZwZwyTPr3LhzILoOHwhlf3D/UGEziunkBAI6dr7RmidRFcBYPERFdVX2DAe9tPo3lO87AIIBgpQs+uHsgEsK8jW2agsrRfAYU6jgGFCIiuqKThWo8se4wThQ0XrqZNrAbXpzSF0pXmUm7uIsB5XShBvUNBsid2UlP144BhYiIWrXzdDEe+DwV9XoDfN3leO3WONwYF9xi2zBfV3i6OKOqrgEZRVXGHhWia8F4S0RELWrQG7D4p2Oo1xswupc/fl1wfavhBAAkEomxF+XYeQ6UpY5hQCEiohZ9czAPWcXV8HWX4/27BsDfU3HV5/QNuThQluNQqIMYUIiIqJnaej3e23waADB/TA94usiu8oxGcd2aBsqyB4U6hgGFiIiaWbnnLC6otejm7YpZw8Lb/LymqcYnCtTQG4SlyiMHwIBCREQmKmt0+HB7JgDgyRt6QuEsbfNzo1QecJVJUVOvR3ZJtaVKJAfAgEJE5IByy2rw8k/HcSC7rNm+D3ecgbquAb0CPXHLgG7tOq7USYLewZ4AOA6FOoYBhYjIwdTUN+D+z1Pw2e/ZuPOjvXjq68Mo0WgBAIWVdVjxezYA4Okbe0HqJGn38ZvGoXDJe+oIroNCRORAhBB45vt0nL6ggYfCGdX1DfjuUB42HS/E0zfGIj2vEtoGAxIjfDA2NuCaXqNpqvFRLnlPHcCAQkTkQFbvy8GPafmQOknw2dzBcJZK8PwPR3G8QI3n1x81tluUHAuJpP29JwDQ5+JU46PnKyGEuObjkGPjJR4iIjsmRNtnyqTlVuDln48DABbdGIshUb4YGO6DDY+MxItT+sBD0fg36/jeAUiM9L3mmnoGekImlUBd14C88tprPg45NvagEBHZqV+OFOCv3x7GlH4heHZy72b3xrlUeXU95q85BJ1e4Ma+QXjguijjPmepE+4dGYVJ8cHYcqIIk/u1vlpsW8idndAryBNHz6txLL8SYb5uHToeOSb2oBAR2SGDQeCt306hpl6Pdam5uOGdHfj1WGGrbResS8P5ilpE+rnhjTv6tXjZJdDLBTOHhl8x6LRV3+CmcSgcKEvXhj0oRER2aEdGMbJLquGpcIa/pwJZJdV48IuDmBwfjMVT+0KnN2B3Zgl+v/go0dTDReaED2cNglcbV4XtiLhuXliXyqnGdO0YUIiI7NDK388CAKYPDsPCib3w7y0Z+GhnFn5JL8Cm4xdQrzeYtHeXS/HG7QnoHezVKfX15ZL31EEMKEREduZMsQY7ThdDIgFmD4+Ei0yKp2+MxaT4YDz97REcL1DDSQL0C/XGdTEqjOyhwsBwH8idO++qfu8gLzhJgOIqLYrUdQjwcum016auod0/rTt37sSUKVMQEhICiUSC9evXm+yXSCQtPt58801jm9GjRzfbP2PGjA6/GSIiR7Bqz1kAwLjYQIT7/TkANa6bEj8+MhK/PDYKf/x9AtbPH4mnJvTCsGi/Tg0nAOAql6K7vwcALthG16bdP7HV1dVISEjA0qVLW9xfUFBg8vjss88gkUhw2223mbSbN2+eSbuPPvro2t4BEZEDUdfp8O3BPADAvSMjm+2XSZ3QN0RploGuHdW0ouwfuRXWLYTsUrsv8SQnJyM5ObnV/UFBQSZf//jjjxgzZgyio6NNtru5uTVr2xqtVgutVmv8Wq1mGicix/Rtah6q6/WICfDAiO5+1i7nihIjffDDH+exfMcZDI3yxcgeKmuXRHbEon1+Fy5cwC+//IL777+/2b41a9ZApVKhb9++WLhwIaqqqlo9zpIlS6BUKo2PsLAwS5ZNRGSTDAaBz/eeBQDMHRlp8yu03pkYhhv6BKK+wYD7P0/B/qxSa5dEdsSiAeXzzz+Hp6cnpk2bZrL97rvvxldffYXt27fjhRdewHfffdeszaWeeeYZVFZWGh+5ubmWLJuIyCZtP12EnNIaeLk449Z23mXYGmRSJyydOQCje/mjTmfAfStTcDCn3NplkZ2w6Cyezz77DHfffTdcXExHb8+bN8/4/3FxcYiJiUFiYiIOHTqEgQMHNjuOQqGAQqGwZKlERDZvxcWpxTOGhMNNbh+TMBXOUiyfNQgPfJ6K3ZklmPvZAayZNxT9Qr2tXRrZOIv1oOzatQunTp3CAw88cNW2AwcOhEwmQ0ZGhqXKISKya5lFVdiVUQInCXDPsAhrl9MuLjIpPp49CEOifFGlbcA9nx7AyUKOJaQrs1hA+fTTTzFo0CAkJCRcte2xY8eg0+kQHNyx+z8QEXVVa/afAwCM6x1ol/e2cZM747O5gzEg3BuVtTo8vPoQauv11i7LoRVW1uHT3dmY9Z/9ePSrP/Bj2nlU1uqsXZZRu/sINRoNMjMzjV9nZ2cjLS0Nvr6+CA8PB9A4y+abb77B22+/3ez5Z86cwZo1azBp0iSoVCocP34cTz31FAYMGICRI0d24K0QEXVNDXoDfjpcAAC4a4j9ThLwUDhjxdzBmPjeTmSVVOP1/53E4ql9rV2WQynVaLHxaCF+PpyPA2fLcOnNsH86nA9nJwmGRvtifO9AjLdyGJaI9tyrG8D27dsxZsyYZtvnzJmDlStXAgA+/vhjLFiwAAUFBVAqlSbtcnNzMWvWLBw9ehQajQZhYWGYPHkyXnzxRfj6tu323mq1GkqlEpWVlfDy6pxlm4mIrGXn6WLM/uwAfNxkOPDceMik9n2f16b3AwBf3D8E18X4t/sYlbU6ZBVrkFVcjUJ1HaYmhNhlz1Jnyimtxs0f/I6Kmj97SRIjfJAcH4wSjRabj19ARpHGuM9T4YxDf7/BrD9v7fn8bndAsQUMKETkSJ78Og3fHzqPWcPC8cot8dYuxyxeWH8UX+zLQZCXC35dcD2UbldfWO5Adhn+vSUDJwvVKNHUm+wbGuWLdQ8Ot1S5XcIrPx/Hf3ZnI9zXDbOGhWNyvxB083Y1aXO2pBqbT1zApuMXEOjlgn/fNcCsNbTn89s+hoETETmoOp0evx4tBADc0t/2pxa31TOTYrE7swTZJdV4ccNRvDej9Q/CqjodXv/fSazed85ke6CXAtEqDxw4W4b92WU4UaDutJsh2pv6BgO+/+M8AODFKX0wrndgi+0iVe544LpoPHBdNAwG6/Zf2Hc/IRFRF7f5xAVU1+sR6uOKQRE+1i7HbNzkznj7zgQ4SYD1afn45UhBi+22nSzChHd3GsPJXUPC8NMjo3D0pYnY/+x4fPV/wzCxb+OH7aq9OZ1Wv73ZcuICyqrrEeCpQFLPtl1Sc3Ky7kKA7EEhIrJh6//IBwBMTQix+ZVj22tguA/mj+mB97dm4rn16ajV6aHTG1Cn06NWp8ex82r8kt4YXCL83LBkWjxGdG++XP6c4ZHYmF6I9X+cx6IbY9t0ucjRfJ3auMDpbYNC4WwnY5gYUIiIbFRFTT12nC4CANxiByvHXotHx8Zg68kiHMtXY+E3h5vtd5IA94+KwpM39IKrXNriMYZE+SI2yBMnC6vwzcFcPHBddIvtHFVhZR12nC4G0Hj7AXvBgEJEZKM2phdCpxfoHeyFnoGe1i7HIuTOTnj/rgF46afj0BsEXGRSuMic4CqTwsPFGbf074aEMO8rHkMikWD28Eg8+0M6vtiXg/tGRln98oQt+e5QHgyiMchFqdytXU6bMaAQEdmoH9MaBzXe3D/EypVYVrS/Bz6/b0iHjnHLgBAs+e8J5JTWYEdGMcb0CjBTdbalskaHp75Jg6eLDFMSgjGqhz/kzq1fsjEYhPHyjj31ngAMKERENim/ohb7s8sgkTSOP6Erc5M7487EMHy6Oxuf7znbZQPKVynnsPlE42W/H/44D6WrDMlxQZiSEIJh0X6QXtZzdOBsGXJKa+ChcMak+CBrlHzN7GOkDBGRg9lwuHFw7JBIX4RctlYFteyeYRGQSIDtp4pxtqTa2uVYxI9pjT8XI7r7wd9TgcpaHdam5OLu/+zHbR/uQWFlnUn7r1Mae0+mJATbzQ0mmzCgEBHZoKYPopu70Nonlhapcsfoi1Nov9jX9aYcn75QhRMFasikEiy7eyD2PTMOXz4wFHcNCYOHwhlpuRW46f3dSDlbBgBQ1+mw8WjjLCh7u7wDMKAQEdmcSz+I7K1b3tpmj4gE0Dittqa+wbrFmFnTmKSkngHwdpND6iTBiB4qLJnWD788NgqxQZ4o0Whx18f7sHpfDjak5aNOZ0DPQA/0v8pAY1vEgEJEZGM2XOw9Gd2r8YOI2i4pxh8Rfm6oqmvAv7ZkdJmQIoS4pFet+ZikCD93fP/wCEzuF4wGg8Dz64/itY0nADT2ntjjGjoMKERENmbziQsAwN6Ta+DkJMHci70oH+3IwtDXtuDln44j287HpBzMKUdeeS3c5VKMb2WZeje5M5beNQB/uzEWEglQU6+HTCrBrXa6ho59jZghIuri8itqcbKwCk4SYHTPrjkTxdLmDI8EAKzccxY5pTX47PdsfPZ7Nq7v6Y9FN8aiT4j93a+nqfdkYlxQqwvWAY1rwjw0ujv6hHjh2e/TMSk+CH4eis4q06wYUIiIbMi2U41TSAeE+8DHnZd3roWTkwT3jozCnOGR2JFRjC/25mDbqSLsPF2Mw7kV+PrB4egVZD8L3+n0BuOS/20dNJ3U0x+/LxprybIsjpd4iIhsyNaLa1yMjWXvSUc5OUkwplcAPps7GDsWjsGAcG9U1upwz6f7kVNqP5d8dmUUo6y6HioPOUZ297N2OZ2GPShERDaiTqfH72dKADCgmFu4nxtWzh2C6R/vxcnCKsz6dD++eXAEgpQuxjY6vQFfp+Zi9b5zkDoBwUpXdPN2RbDSBd18XHF9T394uXT+jQibLu/c1C/Ebm70Zw4MKERENmLvmVLU6QwIVrog1o4uQdgLpZsMq+4fgjuW70VOaQ3u+XQ/vn5wOJSuMmw8WoC3fzttMpj26Hm1yfO7ebvio3sGIa6bstXXKKqqg4+bHDIzBYlqbQN+O9Y4aLqr3/LgcgwoREQ2YuvJPy/v2OO0UHsQ4OmC1fcPxR3L9yKjSINZn+6Hk0SC9POVAAA/dznmj+mBCD835FfUIr+yDgUVtTiQXYbzFbW4ffkevH5bv2ZjQQoqa/H6f09ifVo+unm7Yv6YHrh9UOgV75PTFpuOX0CtTo8IPze7XMukIxhQiIhsgBDCJKCQ5YT5umH1A409KcfyG3tJ3OVSzLs+Gg9cFw0PRfOPxsoaHR5b+wd2nC7G42vTcPR8Jf52Yyx0eoGPdp7B8h1nUKczAADOV9Ti2R/S8cG2TDw0ujvuSAyFwrn1mTdX8ucNI7s5XGiVCCGEtYtoL7VaDaVSicrKSnh52d90MSKiy50qrMLE93ZC4eyEtL9PuOJUUjKP9LxKvLjhKPqH+WD+mO5XnY6rNwi8/dspLNt+BgAwONIH58sbe1mavl6UHIvDuZX4cMcZFFdpAQAhShe8ems8xrQzeBZXaTFsyRboDQJbnkpCd3+Pa3iXtqU9n9/sQSEisgFNvScjuvsxnHSS+FAlvn94ZJvbS50kePrGWPQNUWLhN4eRcrYcQOPYlGcn9cak+CBIJBIMivDFzKHh+OrAOSzfcQb5lXV4aM1BrJ8/ErFBbfujulrbgAe/SIXeIJAQquwS4aS9HGc4MBGRDdvGyzt2Y3K/YPwwfwTG9w7AXyf2wpankjC5X7DJJRgXmRT3jozCjr+OwXUxKtTpDHho9SFU1emuenxtgx5/WX0Qh85VQOkqwxu3J1jy7dgsBhQiIiurqKlHak7jHWjbexmArCM2yAv/mTMY88f0gIus9R4vF5kU/5oxACFKF2SXVOPpb4/gSiMrGvQGPP5VGnZllMBNLsXKewfb1aJy5sSAQkTUScqr67Eu5RxKNVqT7TtOF8MggF6Bngj1cbNSdWQpvu5yfHD3QMikEvz3aCE+3Z3dYjuDQWDR9+n437FCyKVO+GR2IgaE+3RytbaDAYWIqBNU1elw1yf78Lfv0nHDuzvxY9p541/STeNP2HvSdQ0I98Hzk/sAAJb89yRSzpaZ7C+rrsdLPx3DtwfzIHWS4P2ZAzCyh8oapdoMDpIlIrIwnd6Ah9ccwsnCKgCNH0aPr03DhrR8vHRzX+w4XQyA40+6utnDI3AwpxwbDudj/ppDeHx8DA7nViA1pxxZxX8uEPfGbf0wsS/vZM2AQkRkQUIIPPt9OnZllMBVJsWaeUPxe0YJ3t+aiS0ni7ArswT1DQYoXWUYGO5t7XLJgiQSCZZMi8fxAjUyizR47oejJvt7BHjgoaTuuG1QqJUqtC0MKEREFvT+1kx8czAPThJg6cwBGBjug4HhPrgxLghPf3cEf5yrANB491lHus+Ko3JXOGP5rEF47Ks/4OHijMQIHyRG+mBAGO9efTku1EZEZCHfHczDU98cBgD845Y43DMswmS/3iDw+Z6z+O14IRZP7dvmNTKI7BUXaiMishJtgx4Hc8qxK6MEn+zMAgA8mBTdLJwAjQt/3TcqCveNiursMolsHgMKEVEHqet0+DolFzszSnAgu9R4TxYAuKlfMP42MdaK1RHZJwYUIqIOevvXU/h8b47xa39PBUb1UOH6nipM6RcCJyfHuskbkTkwoBARddCeM6UAgPtHRWH64DDEBHg43J1nicyNAYWIqAMqauqRUaQBADw8+up3xCWituGcNiKiDjh0rvGOtlEqd4YTIjNiQCEi6oCDOY0BZVCE494zhcgS2h1Qdu7ciSlTpiAkJAQSiQTr16832T937lxIJBKTx7Bhw0zaaLVaPProo1CpVHB3d8fUqVORl5fXoTdCRGQNqWcbA0oiAwqRWbU7oFRXVyMhIQFLly5ttc2NN96IgoIC42Pjxo0m+xcsWIAffvgBa9euxe7du6HRaHDTTTdBr9e3/x0QEVmJTm/A4bwKAEBiJAMKkTm1e5BscnIykpOTr9hGoVAgKKjlGx1VVlbi008/xRdffIHx48cDAFavXo2wsDBs3rwZEydObG9JRERWcSxfjTqdAd5uMkSrPKxdDlGXYpExKNu3b0dAQAB69uyJefPmoaioyLjv4MGD0Ol0mDBhgnFbSEgI4uLisGfPnhaPp9VqoVarTR5ERNaWerYMADAo3IdrnRCZmdkDSnJyMtasWYOtW7fi7bffRkpKCsaOHQutVgsAKCwshFwuh4+PaXdoYGAgCgsLWzzmkiVLoFQqjY+wsDBzl01E1G7GAbK8vENkdmZfB2X69OnG/4+Li0NiYiIiIiLwyy+/YNq0aa0+TwjR6sJGzzzzDJ588knj12q1miGFiKxKCIHUpoASzoBCZG4Wn2YcHByMiIgIZGRkAACCgoJQX1+P8vJyk3ZFRUUIDAxs8RgKhQJeXl4mDyIia8orr0VxlRYyqQQJYd7WLoeoy7F4QCktLUVubi6Cg4MBAIMGDYJMJsOmTZuMbQoKCnD06FGMGDHC0uUQEZlFak7j+JO+IUq4yKRWroao62n3JR6NRoPMzEzj19nZ2UhLS4Ovry98fX2xePFi3HbbbQgODsbZs2fx7LPPQqVS4dZbbwUAKJVK3H///Xjqqafg5+cHX19fLFy4EPHx8cZZPUREto7rnxBZVrsDSmpqKsaMGWP8umlsyJw5c/Dhhx8iPT0dq1atQkVFBYKDgzFmzBisW7cOnp6exue8++67cHZ2xp133ona2lqMGzcOK1euhFTKv0KIyD40DZDl+idEliERQghrF9FearUaSqUSlZWVHI9CRJ2uslaH/i//BiGAA8+NQ4Cni7VLIrIL7fn85r14iIjaKS23AkIA4b5uDCdEFsKAQkTUTgcvLtDG8SdElsOAQkTUTqlcoI3I4hhQiIjaoUFvQFpuBQAgMcLXusUQdWFmX0mWiMjeCSFQVl2PrJJqFKm16Objimh/d3i5yHCioAo19Xp4uTgjJoA3CCSyFAYUIiIAZ4o1+GjHGWQUaZBVXI3KWl2zNioPBTwUjcshDIzgDQKJLIkBhYgIwOINx7Aro8T4tUQChChdEeilQF55LYqqtCjRaFGiadw/LNrPSpUSOQYGFCJyeEXqOvye2RhO3ry9H+K6KRGlcjdZwr6qToes4mpklWig0epx+8BQa5VL5BAYUIjI4W04nA+DAAaEe+OOxJbvlO7pIkNCmDdvDEjUSTiLh4gc3o9p+QCAWwd0s3IlRNSEAYWIHFpmURXSz1fC2UmCyfHB1i6HiC5iQCEih7b+j8bek6Se/vDzUFi5GiJqwoBCRA7LYBBYn3YeAHALL+8Q2RQOkiUis9t2sgif7MpCg8H0Zuk+bjIsmdYPvu5yK1Vm6uC5cuSV18JD4YzxvQOtXQ4RXYIBhYjM7tWNJ5BZpGlxX0LYOTw8ukcnV9Sy9X809p5M7BsEV7n0Kq2JqDMxoBCRWZ0rrUFmkQZSJwneuTMBMmnjleS9Z0rxxb4c7DxdbBMBpb7BgJ+PFADg7B0iW8SAQkRmtfXkBQBAYoQPbu7/5wd/n2AvfLEvB6lny6HRNsBDYd1fP9tPFaGyVocATwWGd+eqsES2hoNkicistp4qBgCMjQ0w2R6pcke4rxsaDAJ7z5RaozQTTYNjb+4fAinvqUNkcxhQiMhsqrUN2HcxfFweUADg+p4qAMDO08WdWtflKmt12HyiCABn7xDZKl7iISKz+T2zBPV6A8J8XdEjwKPZ/qSeAVi97xx2ZnReQFHX6fDDofOoqNGhVqdHnU6Ps6XVqG8woGegB/oEe3VaLUTUdgwoRGQ220419kqM7RUAiaT5ZZPh3f3g7CRBTmkNzpZUI1LlbtF6dHoDZv1nP47kVba4f9rA0BbrJCLrY0AhIrMQQmDryYsBpZU1RTwUzhgU4YP92WXYmVFs8YCydGsmjuRVQukqw+R+wXCVSeEic4KrTAo/DwWmDeTlHSJbxYBCRGZxLF+NC2otXGVSDI3ybbVdUi//xoByuhizh0darJ603Aos3ZYJAHjlljhMSQix2GsRkflxkCwRmcW2i70nI3uo4CJrfdGz62P8AQB7zpSivsFgkVpq6/V4cl0a9AaBKQkhDCdEdogBhYjMYsvFgDKud/PZO5fqE+wFlYccNfV6pOaUWaSW1/93Elkl1Qj0UuAfN/e1yGsQkWUxoBBRh5VqtDicVwEAGNPrygHFyUli7EXZebrE7LXsyijGyj1nAQBv3J4AbzfbuO8PEbUPAwoRddj2U8UQAugb4oUgpctV21/fszGg7DDzeiiVNTr89ZsjAIB7hkUg6eLrEJH9YUAhog4zzt5pYXG2loyKaVyw7USBGkVVdWapwWAQWPT9ERSq6xClcsczk2LNclwisg4GFCLqEJ3eYFwZdkwbA4rKQ4H4bkoAwC4zXeZ5f2sm/nu0EDJp400K3eScpEhkzxhQiKhDUs+Wo0rbAD93ORJCvdv8POOy92ZYVfZ/Rwvw7ubTAIBXb4nHgHCfDh+TiKyLAYWIOmTLica7Fyf18m/XTfeaBsruyiiBwSCu+fVPFKjx5NeHAQBzR0TizsFh13wsIrIdDChEdM3OFGuwen8OAGBCn5ZXj23NwAgfeCicUVZdj9Sc8mt6/bLqesxblYqaej1G9VDh+cm9r+k4RGR7GFCI6JrUNxiwYG0a6nQGjOqhwoQ+Qe16vkzqZBxU+9DqgzhRoG7zc4UQqK3X46HVB5FXXosIPzcsnTkAzlL+SiPqKjiKjIiuybubTyP9fCW83WR4644EOLXj8k6TxVP7IqtEg6Pn1Zjx8T58ft8Q9A/zNmmjrtPhg22Z+G96Iaq1DajV6VGr00NcvCrkoXDGf2Yncr0Toi6Gf24QUbvtyyrF8h1nAABLbo1v09onLfF1l+PLecMwKMIHlbU63P3JPuzPKgUA6A0CXx04h7FvbcdHO7JwrqwGpdX1qKn/M5x4u8nw/l0DEBPoaZb3RUS2gz0oRNQulbU6PLkuDUIAdyaGIjk+uEPH83KRYdV9QzBvVSr2nCnFnBUHsHBCL3x36Lzxsk+0yh0LJ/ZCd3+PxjsSy53gIpPCTSblZR2iLkoihLj24fNWolaroVQqUVlZCS8vL2uXQ+QwhBB4bG0afjqcjwg/N2x87Dq4K8zzd06dTo+H1xwyLvoGAF4uznh8fE/cMywCcmcGESJ7157P73b/i9+5cyemTJmCkJAQSCQSrF+/3rhPp9Phb3/7G+Lj4+Hu7o6QkBDMnj0b+fn5JscYPXo0JBKJyWPGjBntLYWIOtmPafn46XA+pE4SvDe9v9nCCQC4yKRYPmsQbukfAmcnCe4ZFoHtfx2D+0dFMZwQOaB2/3aprq5GQkIC7r33Xtx2220m+2pqanDo0CG88MILSEhIQHl5ORYsWICpU6ciNTXVpO28efPw8ssvG792dXW9xrdARJ3BYBB467dTAIDHxsZYZDE0ubMT3psxAG/cnsBQQuTg2h1QkpOTkZyc3OI+pVKJTZs2mWx7//33MWTIEJw7dw7h4eHG7W5ubggKat+0RCKynp0Zxcgrr4WXizMeTIq26GsxnBCRxX8LVFZWQiKRwNvb22T7mjVroFKp0LdvXyxcuBBVVVWtHkOr1UKtVps8iKhzfbn/HABg2sBQuMikVq6GiLo6i87iqaurw6JFizBz5kyTwTB33303oqKiEBQUhKNHj+KZZ57B4cOHm/W+NFmyZAleeuklS5ZKRFdwQV2HLRcHr949NPwqrYmIOs5iAUWn02HGjBkwGAxYtmyZyb558+YZ/z8uLg4xMTFITEzEoUOHMHDgwGbHeuaZZ/Dkk08av1ar1QgL4/02iDrLupRc6A0CgyN9uOYIEXUKiwQUnU6HO++8E9nZ2di6detVpxINHDgQMpkMGRkZLQYUhUIBhUJhiVKJ6Cr0BoG1Bxov78xk7wkRdRKzB5SmcJKRkYFt27bBz8/vqs85duwYdDodgoM7tuATEZnf9lNFyK+sg7ebDMlx/DdKRJ2j3QFFo9EgMzPT+HV2djbS0tLg6+uLkJAQ3H777Th06BB+/vln6PV6FBYWAgB8fX0hl8tx5swZrFmzBpMmTYJKpcLx48fx1FNPYcCAARg5cqT53hkRmUXT4NjbOTiWiDpRuwNKamoqxowZY/y6aWzInDlzsHjxYmzYsAEA0L9/f5Pnbdu2DaNHj4ZcLseWLVvwr3/9CxqNBmFhYZg8eTJefPFFSKX85UdkS/IrarHtVOPg2Lt4eYeIOlG7A8ro0aNxpdXxr7ZyflhYGHbs2NHelyUiK1ibkguDAIZF+6K7v4e1yyEiB8LVkIioRQ16A9alNA2OjbByNUTkaBhQiKgZg0Hg5yMFuKDWwtddjol9A61dEhE5GIsu1EZE9iGntBrfHszDmWINsoqrkV1SDW2DAQBwR2IoFM4cH0ZEnYsBhYjw9LdHsD+7zGSbTCpBn2Av3DsiykpVEZEjY0AhcnANegMO51UAAJ4Y3xP9QpWIUrkj1McVzlJeBSYi62BAIXJwmcUa1OkM8FA449GxPeDkJLF2SUREHCRL5OiO5FUCAOK6eTGcEJHNYEAhcnDpFwNKfDellSshIvoTAwqRg0s/fzGghHpbtxAiokswoBA5MJ3egOMFagDsQSEi28KAQuTAMi5oUN9ggKeLMyJ83axdDhGREQMKkQNLP18BAIgLUXKALBHZFAYUIgfWNP6kXygv7xCRbWFAIXJg6cYpxgwoRGRbGFCIHFR9gwEnCqoAsAeFiGwPAwqRgzp9oQr1egO8XJwRzgGyRGRjGFCIHNSf658oIZFwgCwR2RYGFCIHZQwo3bytWwgRUQsYUIgcFJe4JyJbxoBC5IC0DXqcLGxcQZYDZInIFjGgEDmg04Ua6PQCSlcZQn1crV0OEVEzDChEDujSBdo4QJaIbBEDCpEDMi5xz/EnRGSjGFCIHNCRiwNk+zGgEJGNYkAhcjB1Oj1OX2hcQTaeA2SJyEYxoBA5mFOFVdDpBXzcZOjmzQGyRGSbGFCIHMyfK8h6c4AsEdksBhQiB/PnAm1eVq6EiKh1DChEDiYttwIAl7gnItvGgELkQCpq6nHq4gDZxEgfK1dDRNQ6BhQiB5J6thwAEO3vDpWHwsrVEBG1jgGFyIEcOFsGABga5WvlSoiIrowBhciBHMhuDChDGFCIyMYxoBA5iGptA45enGI8OJIBhYhsGwMKkYP441wFGgwC3bxdEerjZu1yiIiuiAGFyEE0jT8ZzNk7RGQHGFCIHMSB7FIAwJAoPytXQkR0de0OKDt37sSUKVMQEhICiUSC9evXm+wXQmDx4sUICQmBq6srRo8ejWPHjpm00Wq1ePTRR6FSqeDu7o6pU6ciLy+vQ2+EiFpX32DAH+cqAABDotiDQkS2r90Bpbq6GgkJCVi6dGmL+9944w288847WLp0KVJSUhAUFIQbbrgBVVVVxjYLFizADz/8gLVr12L37t3QaDS46aaboNfrr/2dEFGr0s9XQNtggK+7HN39PaxdDhHRVTm39wnJyclITk5ucZ8QAu+99x6ee+45TJs2DQDw+eefIzAwEF9++SUefPBBVFZW4tNPP8UXX3yB8ePHAwBWr16NsLAwbN68GRMnTuzA2yGilhzIblygbUikL28QSER2waxjULKzs1FYWIgJEyYYtykUCiQlJWHPnj0AgIMHD0Kn05m0CQkJQVxcnLHN5bRaLdRqtcmDiNquafzJYK5/QkR2wqwBpbCwEAAQGBhosj0wMNC4r7CwEHK5HD4+Pq22udySJUugVCqNj7CwMHOWTdSl6Q0CqTmNPShcQZaI7IVFZvFc3oUshLhqt/KV2jzzzDOorKw0PnJzc81WK1FXd7JQjaq6BngonNE72Mva5RARtYlZA0pQUBAANOsJKSoqMvaqBAUFob6+HuXl5a22uZxCoYCXl5fJg4jaJuXi8vaDInwgdeL4EyKyD2YNKFFRUQgKCsKmTZuM2+rr67Fjxw6MGDECADBo0CDIZDKTNgUFBTh69KixDRGZT9MCbbz/DhHZk3bP4tFoNMjMzDR+nZ2djbS0NPj6+iI8PBwLFizAa6+9hpiYGMTExOC1116Dm5sbZs6cCQBQKpW4//778dRTT8HPzw++vr5YuHAh4uPjjbN6iMg8hBB/zuBhQCEiO9LugJKamooxY8YYv37yyScBAHPmzMHKlSvx9NNPo7a2Fg8//DDKy8sxdOhQ/Pbbb/D09DQ+591334WzszPuvPNO1NbWYty4cVi5ciWkUqkZ3hIRNckuqUaJRgu5sxP6hSqtXQ4RUZtJhBDC2kW0l1qthlKpRGVlJcejEF3B2gPnsOj7dAyJ8sXXDw63djlE5ODa8/nNe/EQdWFN4084vZiI7A0DClEXJYTA/qymOxgzoBCRfWFAIeqicstqcb6iFjKpBImRvEEgEdkXBhSiLmpvVgkAICHUG27ydo+HJyKyKgYUoi5q75nG++8M7+5n5UqIiNqPAYWoCxJCYG/WxYASzYBCRPaHAYWoC8ouqcYFdeP6JwMjOP6EiOwPAwpRF9TUezIw3BsuMi6ASET2hwGFqAsyjj+JVlm5EiKia8OAQtTFCCGw7+L6JxwgS0T2igGFqIvJLNKgRKOFi8wJCWG8/w4R2ScGFKIuZs/FyzuJEb5QOHP8CRHZJwYUoi6G658QUVfAgELUhRgMAvuyGwPKMK5/QkR2jAGFqAs5WViFihod3ORS9Avl+BMisl8MKERdSNP6J4MjfSGT8p83Edkv/gYj6kKaxp+M4PgTIrJzDChEXYTeILA/mwNkiahrYEAh6iKO56tRVdcATxdn9A3h+BMism8MKERdxN6sEgDA0ChfSJ0kVq6GiKhjGFCIuoim8SecXkxEXQEDClEXoNMbcCCb998hoq6DAYWoC0g/X4nqej283WToHeRl7XKIiDqMAYWoC2i6vDM0yhdOHH9CRF0AAwpRF7Dv4gJtwzn+hIi6CAYUIjtX32BA6tlyAMDw7iorV0NEZB4MKER27nBeBWp1evi5y9Ez0MPa5RARmQUDCpGdM04v7u4HiYTjT4ioa2BAIbJzTQGF40+IqCthQCGyY3U6PQ6eaxp/woBCRF0HAwqRHTt0rhz1DQYEeCoQrXK3djlERGbDgEJkx/ad+fPuxRx/QkRdCQMKkR3by/VPiKiLYkAhslO19Xqk5VYA4PgTIup6GFCI7FRqThl0eoEQpQvCfd2sXQ4RkVkxoBDZKa5/QkRdGQMKkZ3aw/VPiKgLM3tAiYyMhEQiafaYP38+AGDu3LnN9g0bNszcZRB1aRptA9LPVwLg+BMi6pqczX3AlJQU6PV649dHjx7FDTfcgDvuuMO47cYbb8SKFSuMX8vlcnOXQdSlpWSXQW8QCPd1Q6gPx58QUddj9oDi7+9v8vU///lPdO/eHUlJScZtCoUCQUFB5n5pIofB6cVE1NVZdAxKfX09Vq9ejfvuu89kEN/27dsREBCAnj17Yt68eSgqKrricbRaLdRqtcmDyJHtzy4DwMs7RNR1WTSgrF+/HhUVFZg7d65xW3JyMtasWYOtW7fi7bffRkpKCsaOHQutVtvqcZYsWQKlUml8hIWFWbJsIptmMAhkXKgCAMR187JyNUREliERQghLHXzixImQy+X46aefWm1TUFCAiIgIrF27FtOmTWuxjVarNQkwarUaYWFhqKyshJcXf0GTYzlfUYuR/9wKZycJTvzjRsiknIxHRPZBrVZDqVS26fPb7GNQmuTk5GDz5s34/vvvr9guODgYERERyMjIaLWNQqGAQqEwd4lEdimzSAMAiFS5M5wQUZdlsd9uK1asQEBAACZPnnzFdqWlpcjNzUVwcLClSiHqUpoCSg9/DytXQkRkORYJKAaDAStWrMCcOXPg7PxnJ41Go8HChQuxd+9enD17Ftu3b8eUKVOgUqlw6623WqIUoi7HGFACGFCIqOuyyCWezZs349y5c7jvvvtMtkulUqSnp2PVqlWoqKhAcHAwxowZg3Xr1sHT09MSpRB1OWcYUIjIAVgkoEyYMAEtjb11dXXFr7/+aomXJHIYmcUMKETU9XGEHZEdKdVoUVZdDwCI9ne3cjVERJbDgEJkR5rGn4T6uMJNbrFJeEREVseAQmRHeHmHiBwFAwqRHeEUYyJyFAwoRHaEU4yJyFEwoBDZEU4xJiJHwYBCZCeqtQ3Ir6wDwIBCRF0fAwqRnThzcYCsykMBbze5lashIrIsBhQiO5FxoenyDtc/IaKujwGFyE5wijERORIGFCI7wSnGRORIGFCI7MSfM3h4Y00i6voYUIjsQH2DATllNQB4iYeIHAMDCpEdOFtaDb1BwEPhjEAvhbXLISKyOAYUIjtw6QqyEonEytUQEVkeAwqRHfhzijEv7xCRY2BAIbIDnGJMRI6GAYXIDnCKMRE5GgYUIhunNwhksQeFiBwMAwqRjTtfXgttgwFyZyeE+bpZuxwiok7BgEJk4zKLqwAA0Sp3SJ04g4eIHAMDCpGNu3SKMRGRo2BAIbJxDChE5IgYUIhs3GmugUJEDogBhciGabQNOHq+EgCQEOpt3WKIiDoRAwqRDdt3phQNBoEIPzfO4CEih8KAQmTDdmeWAABG9VBZuRIios7FgEJkw3ZmFAMArovxt3IlRESdiwGFyEblV9Qiq7gaThJgeHc/a5dDRNSpGFCIbNTujMbLOwlh3lC6yqxcDRFR52JAIbJRuy6OP7mO40+IyAExoBDZIINB4PemAbIcf0JEDogBhcgGHS9Qo6y6Hu5yKQaEe1u7HCKiTseAQmSDmqYXD4v2g0zKf6ZE5Hj4m4/IBjUNkB0Vw/EnROSYGFCIbEydTo8DZ8sAcP0TInJcDChENuZAdhnqGwwIVrqgu7+7tcshIrIKsweUxYsXQyKRmDyCgoKM+4UQWLx4MUJCQuDq6orRo0fj2LFj5i6DyG5dury9RCKxcjVERNZhkR6Uvn37oqCgwPhIT0837nvjjTfwzjvvYOnSpUhJSUFQUBBuuOEGVFVVWaIUIruzi+NPiIjgbJGDOjub9Jo0EULgvffew3PPPYdp06YBAD7//HMEBgbiyy+/xIMPPtji8bRaLbRarfFrtVptibKJrK64SosTBY0/3yO5QBsROTCL9KBkZGQgJCQEUVFRmDFjBrKysgAA2dnZKCwsxIQJE4xtFQoFkpKSsGfPnlaPt2TJEiiVSuMjLCzMEmUTWd2eM429J32CvaDyUFi5GiIi6zF7QBk6dChWrVqFX3/9FZ988gkKCwsxYsQIlJaWorCwEAAQGBho8pzAwEDjvpY888wzqKysND5yc3PNXTaR1RkMAr8ea/x3cB0v7xCRgzP7JZ7k5GTj/8fHx2P48OHo3r07Pv/8cwwbNgwAmg38E0JccTCgQqGAQsG/JqnrOlGgxvPrj+JgTjkAYGxsgJUrIiKyLotPM3Z3d0d8fDwyMjKM41Iu7y0pKipq1qtC5Ag02gb84+fjuOn93TiYUw53uRQvTe2LodF+1i6NiMiqLB5QtFotTpw4geDgYERFRSEoKAibNm0y7q+vr8eOHTswYsQIS5dCZFN2Z5Rg3Nvb8enubOgNApPjg7HlqdGYMyLS2qUREVmd2S/xLFy4EFOmTEF4eDiKiorwyiuvQK1WY86cOZBIJFiwYAFee+01xMTEICYmBq+99hrc3Nwwc+ZMc5dCZLM02gY88tUhVNToEOnnhpdujkNST64aS0TUxOwBJS8vD3fddRdKSkrg7++PYcOGYd++fYiIiAAAPP3006itrcXDDz+M8vJyDB06FL/99hs8PT3NXQqRzVqzLwcVNTpEq9yx8fHr4CKTWrskIiKbIhFCCGsX0V5qtRpKpRKVlZXw8vKydjlE7VJbr8d1b2xFiaYeb92RgNsHhVq7JCKiTtGez2/ei4eok61NOYcSTT3CfF1xc/8Qa5dDRGSTGFCIOpG2QY+PdjQuXPhQUg/IpPwnSETUEv52JOpE3x08j0J1HYK8XHDboG7WLoeIyGYxoBB1Ep3egGXbMwEADyZFQ+HMgbFERK1hQCHqJD+m5SOvvBYqDzlmDA63djlERDaNAYWoE+gNAsu2NfaePHBdNFzl7D0hIroSBhSiTrAxvQBZJdXwdpNh1rAIa5dDRGTzGFCILKxOp8e7m08DAO4bGQUPhdnXRyQi6nIYUIgs7P2tGcgqroa/p4L32SEiaiMGFCILOnq+Essvrnvyj5vjoHSVWbkiIiL7wIBCZCE6vQF//fZI452K+wXjxrgga5dERGQ3GFCILGT59jM4UaCGj5sML03ta+1yiIjsCgMKkQWcvlCFf2/NAAAsntoXKg+FlSsiIrIvDChEZtagN+Cv3xyGTi8wvncApibwhoBERO3FgEJkZp/9no3DeZXwdHHGK7fEQyKRWLskIiK7w4BCZEZ6gzDO2nl+cm8EKV2sXBERkX1iQCEyoz/OlaOsuh5KVxmmDQy1djlERHaLAYXIjDaduAAAGNPLHzIp/3kREV0r/gYlMqPNxxsDyvg+gVauhIjIvjGgEJlJVrEGZ4qrIZNKcH1Pf2uXQ0Rk1xhQiMxky4kiAMCwaD94uXBJeyKijmBAITKTpvEn43vz8g4RUUcxoBCZQXl1PVLPlgEAxvUOsHI1RET2jwGFyAy2nSqCQQC9g70Q6uNm7XKIiOweAwqRGWy+eHnnBvaeEBGZBQMKUQdpG/TYcaoYADCO40+IiMyCAYWog/ZllaG6Xo8ATwXiuymtXQ4RUZfAgELUQU2Ls43rHQgnJ94YkIjIHBhQiDpACPHn+JM+HH9CRGQuDChEHXAsX42Cyjq4yqQY0V1l7XKIiLoMBhSiDmjqPbkuRgUXmdTK1RARdR3O1i6AyN4IIZCWW4GvU/OwIe08AN4ckIjI3BhQiNqovLoe3xzMxTepecgo0hi3x3dTIjkuyIqVERF1PQwoRG2QcrYMD60+hBKNFgDgInPCpLhg3JEYhqFRvpy9Q0RkZgwoRFcghMDq/efw0oZjaDAIdPd3xwPXRWNyv2DesZiIyIIYUIhaoW3Q4+/rj2Fdai4AYHK/YLx5ez+4yfnPhojI0sw+i2fJkiUYPHgwPD09ERAQgFtuuQWnTp0yaTN37lxIJBKTx7Bhw8xdCtE1K6ysw/SP9mFdai6cJMCi5FgsvWsAwwkRUScx+2/bHTt2YP78+Rg8eDAaGhrw3HPPYcKECTh+/Djc3d2N7W688UasWLHC+LVcLjd3KUTtVqLR4pOdWfhiXw5q6vXwcnHG+zMHIqmnv7VLIyJyKGYPKP/73/9Mvl6xYgUCAgJw8OBBXH/99cbtCoUCQUGc+UC2oUSjxcc7s/DF3hzU6vQAgIQwb/x7Rn9E+Llf5dlERGRuFu+vrqysBAD4+vqabN++fTsCAgLg7e2NpKQkvPrqqwgIaHmpcK1WC61Wa/xarVZbrmByKDq9Ae9vycDHu7JQpzMAABJClXh8fAzG9AqARMLZOURE1iARQghLHVwIgZtvvhnl5eXYtWuXcfu6devg4eGBiIgIZGdn44UXXkBDQwMOHjwIhULR7DiLFy/GSy+91Gx7ZWUlvLy8LFU+dXHnSmvw6No/cDi3AgDQP8wbj4+Pweie/gwmREQWoFaroVQq2/T5bdGAMn/+fPzyyy/YvXs3QkNDW21XUFCAiIgIrF27FtOmTWu2v6UelLCwMAYUumY/pp3Hcz8chUbbAC8XZ7w2LR6T44MZTIiILKg9AcVil3geffRRbNiwATt37rxiOAGA4OBgREREICMjo8X9CoWixZ4VovbSaBvw4o/H8N2hPADA4EgfvDdjALp5u1q5MiIiupTZA4oQAo8++ih++OEHbN++HVFRUVd9TmlpKXJzcxEcHGzucoiMqrUNuHP5XhwvUMNJAjw2LgaPjOkBZynvmUlEZGvMHlDmz5+PL7/8Ej/++CM8PT1RWFgIAFAqlXB1dYVGo8HixYtx2223ITg4GGfPnsWzzz4LlUqFW2+91dzlEAEADAaBJ79Ow/ECNVQeciy7exCGRPle/YlERGQVZg8oH374IQBg9OjRJttXrFiBuXPnQiqVIj09HatWrUJFRQWCg4MxZswYrFu3Dp6enuYuhwgA8K8tGfj12AXIpU746J5EDIrwsXZJRER0BRa5xHMlrq6u+PXXX839skSt+m96Af61pXF806u3xjGcEBHZAV58py7teL4aT359GABw/6go3JEYZuWKiIioLRhQqMsq1Wgxb1UqanV6XBejwjPJsdYuiYiI2ogB5TJv/XoK+7NKrV0GdVBVnQ7zVqXifEUtolTuWHrXQM7WISKyI/yNfYk/zpVj6bZMTP94H2Z8vBd7zzCo2KOKmnrc/Z/9OHSuAp4uzvhk9iAo3WTWLouIiNqB946/RJDSBXcPDcfXqbnYl1WGfVn7MCTKFwvGxSAhzBvZJdU4U6xBVnE1zpZWQ+kqw4juKgzv7gela8sfgJU1OrjKpZA7Mwt2huIqLe75dD9OFlbB112OVfcNQY8Azg4jIrI3Fl3q3lLas1TutcivqMWH289gXUou6vWGq7Z3kgD9Qr1xXYwKbnJnZBVrkFVSjaxiDcprdOju747180fC04V/xVtSfkUtZv1nP7JKqhHgqcCaB4YiJpDhhIjIVtjMvXgsxdIBpUlBZS2Wbz+Dr1JyUd9ggK+7HNEqd0T7uyNK5YGCylrszixBVnH1VY9128BQvH1ngsVqdXQ5pdWY+cl+nK+oRTdvV6x5YCgiVe7WLouIiC7BgGJmGm0DGvQGeLvJW9x/vqIWv2eWYO+ZUugNAt39PRDt3xhkyqrrMeezAzAI4IOZAzG5n3WW8zcYBHZllqC2Xo/rezb29HQVpRotpi793TggdvUDQ3lvHSIiG8SAYmPe/PUkPth2Bl4uzvjfgusR0okfngaDwH+PFuLfWzJw6kIVAMBVJsX4PoGY0i8YSb38oXCWdlo95tagN2D2Zwew50wpIv3c8PVfhiPA08XaZRERUQsYUGyMTm/AbR/uwZG8SgyP9sOaB4bCyUli0dc0GAQ2Hi3Av7dk4PQFDQDAU+EMb3cZcstqje08XZwxLNoP3bxdEeLtgmBl43+jVB7wdW+5x8iWvLbxBD7emQU3uRTr549ET445ISKyWe35/O46/fw2TCZ1wnvT+2Pyv3djb1YpPtmVhQeTuhv3q+t0SMkuQ4lG2+y5Pm5y9O2mRIjSBRLJn6FGpzcg5WwZNh8vwtaTF1CorjN5nsEA4wBfTxdn3DcyCveNjIKXqzOO5FXip8P5+PlIAQrVddh0/EKLdUer3DEowgeJkT4YFOGD7v4eJjVY24bD+fh4ZxYA4K07EhhOiIi6EPagdKKvDpzDM9+nQyaV4M3bE5BVUo3dGcU4nFcJveHKp8HbTYa+IV7oG6LEBXUdtp0sgrqu4YrP8XJxxv2jojF3ZGSL06ANBoGD58pxokCN/Io65FfUoqCyFufLa5FfWdesva+7HCO6++G6GBVG9lAh1Metfd+AiyprdfjuYB50egOmDw5rdWzPlZwoUGPasj2o1enxl6TuWMRVYomIbB4v8dgoIQQe/OIgfmuhxyJK5Y5olTsu7aAQonEAbmaRBg0tBBhfdznGxgZgfO9A9A3xwuWdGyoPBVxk1za+pLy6HofOleNgTjlSc8pxOLcC2gbTKddRKneMjQ3AzKHh6O7vcdVj5lfU4rPd2fjqwDlU1+sBNIaov4zujntHRMFV/metQgicKKjCxvQCFFXVIVLljmiVB3oEuEPpKsdtH+7BubIaXBejwsp7h0Bq4UtmRETUcQwoNqysuh63L9+DyhodRvRQYVQPv6v2RtTp9Mi4oMGx/EqcKFDDTeGMcbEBGBDu02kfzPUNBqTlVmB3ZkmLvT7Xxahwz7AIjOsdaKxJCIELai0yizT4/lAeNhzONwatXoGekEiAk4WNA3cDPBV4fHwMBkf6YmN6AX46nI8zV5m+Herjip8eGQUfOxgrQ0REDCjUCdR1OuzJLMW3B3Ox5WQRmn6Kunm7YkC4N86WViO7uNrYU9JkeLQfHkyKRlJPfxgEsOHwebz922nkldc2ew25sxPG9gpAryBP5JRWX1z8rhoabQPc5VJ8/Zfh6Bui7Iy3S0REZsCAQp0qt6wGq/fnYF1KLipqdCb7pE4ShPu6oX+YN+4dGYl+od7Nnq9t0OPL/efw/tZMqGt1GBWjwtSEENzQJ7DZ6rtCCBRXaSGTOrHnhIjIzjCgkFXU6fT479ECXFBrL66464FwX7c234eoQW+ATi9MxqIQEVHXwWnGZBUuMiluHRB6zc93ljrBjteMIyIiM+ItdomIiMjmMKAQERGRzWFAISIiIpvDgEJEREQ2hwGFiIiIbA4DChEREdkcBhQiIiKyOQwoREREZHMYUIiIiMjmMKAQERGRzWFAISIiIpvDgEJEREQ2hwGFiIiIbI5d3s1YCAGg8bbNREREZB+aPrebPsevxC4DSlVVFQAgLCzMypUQERFRe1VVVUGpVF6xjUS0JcbYGIPBgPz8fHh6ekIikZj12Gq1GmFhYcjNzYWXl5dZj03tx/NhW3g+bAvPh+3hObkyIQSqqqoQEhICJ6crjzKxyx4UJycnhIaGWvQ1vLy8+MNlQ3g+bAvPh23h+bA9PCetu1rPSRMOkiUiIiKbw4BCRERENocB5TIKhQIvvvgiFAqFtUsh8HzYGp4P28LzYXt4TszHLgfJEhERUdfGHhQiIiKyOQwoREREZHMYUIiIiMjmMKAQERGRzWFAISIiIpvDgHKJZcuWISoqCi4uLhg0aBB27dpl7ZIcwpIlSzB48GB4enoiICAAt9xyC06dOmXSRgiBxYsXIyQkBK6urhg9ejSOHTtmpYody5IlSyCRSLBgwQLjNp6Pznf+/HnMmjULfn5+cHNzQ//+/XHw4EHjfp6TztPQ0IDnn38eUVFRcHV1RXR0NF5++WUYDAZjG54PMxAkhBBi7dq1QiaTiU8++UQcP35cPP7448Ld3V3k5ORYu7Qub+LEiWLFihXi6NGjIi0tTUyePFmEh4cLjUZjbPPPf/5TeHp6iu+++06kp6eL6dOni+DgYKFWq61Yedd34MABERkZKfr16ycef/xx43aej85VVlYmIiIixNy5c8X+/ftFdna22Lx5s8jMzDS24TnpPK+88orw8/MTP//8s8jOzhbffPON8PDwEO+9956xDc9HxzGgXDRkyBDxl7/8xWRbbGysWLRokZUqclxFRUUCgNixY4cQQgiDwSCCgoLEP//5T2Oburo6oVQqxfLly61VZpdXVVUlYmJixKZNm0RSUpIxoPB8dL6//e1vYtSoUa3u5znpXJMnTxb33XefybZp06aJWbNmCSF4PsyFl3gA1NfX4+DBg5gwYYLJ9gkTJmDPnj1WqspxVVZWAgB8fX0BANnZ2SgsLDQ5PwqFAklJSTw/FjR//nxMnjwZ48ePN9nO89H5NmzYgMTERNxxxx0ICAjAgAED8Mknnxj385x0rlGjRmHLli04ffo0AODw4cPYvXs3Jk2aBIDnw1zs8m7G5lZSUgK9Xo/AwECT7YGBgSgsLLRSVY5JCIEnn3wSo0aNQlxcHAAYz0FL5ycnJ6fTa3QEa9euxaFDh5CSktJsH89H58vKysKHH36IJ598Es8++ywOHDiAxx57DAqFArNnz+Y56WR/+9vfUFlZidjYWEilUuj1erz66qu46667APDfiLkwoFxCIpGYfC2EaLaNLOuRRx7BkSNHsHv37mb7eH46R25uLh5//HH89ttvcHFxabUdz0fnMRgMSExMxGuvvQYAGDBgAI4dO4YPP/wQs2fPNrbjOekc69atw+rVq/Hll1+ib9++SEtLw4IFCxASEoI5c+YY2/F8dAwv8QBQqVSQSqXNekuKioqaJWCynEcffRQbNmzAtm3bEBoaatweFBQEADw/neTgwYMoKirCoEGD4OzsDGdnZ+zYsQP//ve/4ezsbPye83x0nuDgYPTp08dkW+/evXHu3DkA/DfS2f76179i0aJFmDFjBuLj43HPPffgiSeewJIlSwDwfJgLAwoAuVyOQYMGYdOmTSbbN23ahBEjRlipKschhMAjjzyC77//Hlu3bkVUVJTJ/qioKAQFBZmcn/r6euzYsYPnxwLGjRuH9PR0pKWlGR+JiYm4++67kZaWhujoaJ6PTjZy5MhmU+9Pnz6NiIgIAPw30tlqamrg5GT68SmVSo3TjHk+zMSKA3RtStM0408//VQcP35cLFiwQLi7u4uzZ89au7Qu76GHHhJKpVJs375dFBQUGB81NTXGNv/85z+FUqkU33//vUhPTxd33XUXp+x1oktn8QjB89HZDhw4IJydncWrr74qMjIyxJo1a4Sbm5tYvXq1sQ3PSeeZM2eO6Natm3Ga8ffffy9UKpV4+umnjW14PjqOAeUSH3zwgYiIiBByuVwMHDjQOM2VLAtAi48VK1YY2xgMBvHiiy+KoKAgoVAoxPXXXy/S09OtV7SDuTyg8Hx0vp9++knExcUJhUIhYmNjxccff2yyn+ek86jVavH444+L8PBw4eLiIqKjo8Vzzz0ntFqtsQ3PR8dJhBDCmj04RERERJfjGBQiIiKyOQwoREREZHMYUIiIiMjmMKAQERGRzWFAISIiIpvDgEJEREQ2hwGFiIiIbA4DChEREdkcBhQiIiKyOQwoREREZHMYUIiIiMjm/D9adYBOOnBqYgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And see the results\n",
    "def smooth(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "plt.plot(smooth(episode_durations, 10))\n",
    "plt.title('Episode durations per episode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "rlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
