{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Deep Q Network\n",
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports %%execwritefile command (executes cell and writes it into file). \n",
    "# All cells that start with %%execwritefile should be in td_autograde.py file after running all cells.\n",
    "\n",
    "from custommagics import CustomMagics\n",
    "get_ipython().register_magics(CustomMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile dqn_autograde.py\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc69f22067705372",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 7, 0), \"Make sure you have Python 3.7 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fef7e20e54e6243b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1. Deep Q-Network (DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-39519f4ab05eb2a1",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/miniconda3/envs/rlcourse/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.envs.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        CartPoleEnv\n",
      "\u001b[0;31mString form:\u001b[0m <CartPoleEnv<CartPole-v1>>\n",
      "\u001b[0;31mFile:\u001b[0m        ~/miniconda3/envs/rlcourse/lib/python3.7/site-packages/gym/envs/classic_control/cartpole.py\n",
      "\u001b[0;31mSource:\u001b[0m     \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mCartPoleEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m    Description:\u001b[0m\n",
      "\u001b[0;34m        A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum starts upright, and the goal is to prevent it from falling over by increasing and reducing the cart's velocity.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Source:\u001b[0m\n",
      "\u001b[0;34m        This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Observation: \u001b[0m\n",
      "\u001b[0;34m        Type: Box(4)\u001b[0m\n",
      "\u001b[0;34m        Num     Observation                 Min         Max\u001b[0m\n",
      "\u001b[0;34m        0       Cart Position             -4.8            4.8\u001b[0m\n",
      "\u001b[0;34m        1       Cart Velocity             -Inf            Inf\u001b[0m\n",
      "\u001b[0;34m        2       Pole Angle                 -24°           24°\u001b[0m\n",
      "\u001b[0;34m        3       Pole Velocity At Tip      -Inf            Inf\u001b[0m\n",
      "\u001b[0;34m        \u001b[0m\n",
      "\u001b[0;34m    Actions:\u001b[0m\n",
      "\u001b[0;34m        Type: Discrete(2)\u001b[0m\n",
      "\u001b[0;34m        Num     Action\u001b[0m\n",
      "\u001b[0;34m        0       Push cart to the left\u001b[0m\n",
      "\u001b[0;34m        1       Push cart to the right\u001b[0m\n",
      "\u001b[0;34m        \u001b[0m\n",
      "\u001b[0;34m        Note: The amount the velocity is reduced or increased is not fixed as it depends on the angle the pole is pointing. This is because the center of gravity of the pole increases the amount of energy needed to move the cart underneath it\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Reward:\u001b[0m\n",
      "\u001b[0;34m        Reward is 1 for every step taken, including the termination step\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Starting State:\u001b[0m\n",
      "\u001b[0;34m        All observations are assigned a uniform random value between ±0.05\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Episode Termination:\u001b[0m\n",
      "\u001b[0;34m        Pole Angle is more than ±12°\u001b[0m\n",
      "\u001b[0;34m        Cart Position is more than ±2.4 (center of the cart reaches the edge of the display)\u001b[0m\n",
      "\u001b[0;34m        Episode length is greater than 200\u001b[0m\n",
      "\u001b[0;34m        Solved Requirements\u001b[0m\n",
      "\u001b[0;34m        Considered solved when the average reward is greater than or equal to 195.0 over 100 consecutive trials.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'render.modes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'video.frames_per_second'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9.8\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasscart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasscart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;31m# actually half the pole's length\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.02\u001b[0m  \u001b[0;31m# seconds between state updates\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'euler'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Angle at which to fail the episode\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.4\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Angle limit set to 2 * theta_threshold_radians so failing observation is still within bounds\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mhigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%r (%s) invalid\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mforce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_mag\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcostheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msintheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msintheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mthetaacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgravity\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msintheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcostheta\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasspole\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mxacc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolemass_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcostheta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkinematics_integrator\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'euler'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# semi-implicit euler\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta_dot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mthetaacc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta_dot\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_dot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta_dot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m \\\n",
      "                \u001b[0;32mor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_threshold_radians\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Pole just fell!\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_beyond_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscreen_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscreen_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mworld_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_threshold\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscreen_width\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mworld_width\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcarty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;31m# TOP OF CART\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpolewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpolelen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0maxleoffset\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolelen\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilledPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxleoffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_circle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolewidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcartx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;31m# MIDDLE OF CART\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarttrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcartx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# env is a TimeLimit wrapper around an env, so use env.env to look into the env (but otherwise you can forget about this)\n",
    "??env.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nice thing about the CARTPOLE is that it has very nice rendering functionality (if you are on a local environment). Let's have a look at an episode\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "done = False\n",
    "while not done:\n",
    "    obs, reward, done, _ = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "env.close() # Close the environment or you will have a lot of render screens soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2d83f70e62b99520",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Remember from the previous lab, that in order to optimize a policy we need to estimate the Q-values (e.g. estimate the *action* values). In the CartPole problem, our state is the current position of the cart, the current velocity of the cart, the current (angular) position of the pole and the (angular) speed of the pole. As these are continuous variables, we have an infinite number of states (ignoring the fact that a digital computer can only represent finitely many states in finite memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b3162496f5e6cf5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.1 Implement Q-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96a86bcfa1ebc84a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We will not use the tabular approach but approximate the Q-value function by a general approximator function. We will skip the linear case and directly use a two layer Neural Network. We use [PyTorch](https://pytorch.org/) to implement the network, as this will allow us to train it easily later. We can implement a model using `torch.nn.Sequential`, but with PyTorch it is actually very easy to implement the model (e.g. the forward pass) from scratch. Now implement the `QNetwork.forward` function that uses one hidden layer with ReLU activation (no output activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-216429a5dccf8a0e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_hidden=128):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-00ce108d640a5942",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's instantiate and test if it works\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1)\n",
    "Q_net = QNetwork(num_hidden)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "test_model = nn.Sequential(\n",
    "    nn.Linear(4, num_hidden), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(num_hidden, 2)\n",
    ")\n",
    "\n",
    "x = torch.rand(10, 4)\n",
    "\n",
    "# If you do not need backpropagation, wrap the computation in the torch.no_grad() context\n",
    "# This saves time and memory, and PyTorch complains when converting to numpy\n",
    "with torch.no_grad():\n",
    "    assert np.allclose(Q_net(x).numpy(), test_model(x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ca77eae2e62180cf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.2 Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2c1d117a1a75fd69",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to stabilize learning, we will use an experience replay to save states in and sample states from. Now implement the `push` function that adds a transition to the replay buffer, and the `sample` function that samples a (random!) batch of data, for use during training (hint: you can use the function `random.sample`). It should keep at most the maximum number of transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a3cc876e51eb157f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, transition):\n",
    "        # YOUR CODE HERE\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # YOUR CODE HERE\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3b90135921c4da76",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([-0.01753518,  0.00463285,  0.00107614, -0.00827561]), 0, 1.0, array([-0.01744252, -0.19050452,  0.00091062,  0.28474665]), False)]\n"
     ]
    }
   ],
   "source": [
    "capacity = 10\n",
    "memory = ReplayMemory(capacity)\n",
    "\n",
    "# Sample a transition\n",
    "s = env.reset()\n",
    "a = env.action_space.sample()\n",
    "s_next, r, done, _ = env.step(a)\n",
    "\n",
    "# Push a transition\n",
    "memory.push((s, a, r, s_next, done))\n",
    "\n",
    "# Sample a batch size of 1\n",
    "print(memory.sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-88f67e3c051da6a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.3 $\\epsilon$psilon Greedy Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aa3c7d1b3000f697",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to learn a good policy, we need to explore quite a bit initially. As we start to learn a good policy, we want to decrease the exploration. As the amount of exploration using an $\\epsilon$-greedy policy is controlled by $\\epsilon$, we can define an 'exploration scheme' by writing $\\epsilon$ as a function of time. There are many possible schemes, but we will use a simple one: we will start with only exploring (so taking random actions) at iteration 0, and then in 1000 iterations linearly anneal $\\epsilon$ such that after 1000 iterations we take random (exploration) actions with 5\\% probability (forever, as you never know if the environment will change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5789e7a792108576",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n",
      "0.05\n",
      "0.55\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def get_epsilon(it):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    if it < 1000:\n",
    "        epsilon = 1 - it * (0.9 / 1000)\n",
    "    else:\n",
    "        epsilon = 0.05 \n",
    "    return epsilon\n",
    "\n",
    "print(get_epsilon(1000))\n",
    "print(get_epsilon(500))\n",
    "print(get_epsilon(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-40e66db45e742b2e",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x794d2c127250>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So what's an easy way to check?\n",
    "plt.plot([get_epsilon(it) for it in range(5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8b604c9998c6c3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now write a function of *EpsilonGreedyPolicy* class. This function takes a state and uses the Q-network to select an ($\\epsilon$-greedy) action. It should return a random action with probability epsilon. Note, you do not need to backpropagate through the model computations, so use `with torch.no_grad():` (see above for example). Note that to convert a PyTorch tensor with only 1 element (0 dimensional) to a simple python scalar (int or float), you can use the '.item()' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-878ad3a637cfb51c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "class EpsilonGreedyPolicy(object):\n",
    "    \"\"\"\n",
    "    A simple epsilon greedy policy.\n",
    "    \"\"\"\n",
    "    def __init__(self, Q, epsilon):\n",
    "        self.Q = Q\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def sample_action(self, obs):\n",
    "        \"\"\"\n",
    "        This method takes a state as input and returns an action sampled from this policy.  \n",
    "\n",
    "        Args:\n",
    "            obs: current state\n",
    "\n",
    "        Returns:\n",
    "            An action (int).\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        with torch.no_grad():\n",
    "            # Exploratory action\n",
    "            if np.random.rand() < self.epsilon:\n",
    "                action = np.random.randint(2)\n",
    "            # Greedy action\n",
    "            else:\n",
    "                action = torch.argmax(self.Q(torch.tensor(obs).float())).item()\n",
    "        \n",
    "        return action\n",
    "        \n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e895338d56bee477",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "epg = EpsilonGreedyPolicy(Q_net, 0.05)\n",
    "a = epg.sample_action(s)\n",
    "assert not torch.is_tensor(a)\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 969, 1: 31}\n"
     ]
    }
   ],
   "source": [
    "counts = {0: 0, 1: 0}\n",
    "for i in range(1000):\n",
    "    s = env.reset()\n",
    "    counts[epg.sample_action(s)] += 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec5e94e0b03f8aec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Training function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d1a12cc97386fe56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we will implement the function 'train' that samples a batch from the memory and performs a gradient step using some convenient PyTorch functionality. However, you still need to compute the Q-values for the (state, action) pairs in the experience, as well as their target (e.g. the value they should move towards). What is the target for a Q-learning update? What should be the target if `next_state` is terminal (e.g. `done`)?\n",
    "\n",
    "For computing the Q-values for the actions, note that the model returns all action values where you are only interested in a single action value. Because of the batch dimension, you can't use simple indexing, but you may want to have a look at [torch.gather](https://pytorch.org/docs/stable/torch.html?highlight=gather#torch.gather) or use [advanced indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html) (numpy tutorial but works mostly the same in PyTorch). Note, you should NOT modify the function train. You can view the size of a tensor `x` with `x.size()` (similar to `x.shape` in numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c45485324b40081",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def compute_q_vals(Q, states, actions):\n",
    "    \"\"\"\n",
    "    This method returns Q values for given state action pairs.\n",
    "    \n",
    "    Args:\n",
    "        Q: Q-net\n",
    "        states: a tensor of states. Shape: batch_size x obs_dim\n",
    "        actions: a tensor of actions. Shape: Shape: batch_size x 1\n",
    "\n",
    "    Returns:\n",
    "        A torch tensor filled with Q values. Shape: batch_size x 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    Q_values = Q(states).gather(1, actions)\n",
    "    return Q_values\n",
    "\n",
    "    \n",
    "def compute_targets(Q, rewards, next_states, dones, discount_factor):\n",
    "    \"\"\"\n",
    "    This method returns targets (values towards which Q-values should move).\n",
    "    \n",
    "    Args:\n",
    "        Q: Q-net\n",
    "        rewards: a tensor of rewards. Shape: Shape: batch_size x 1\n",
    "        next_states: a tensor of states. Shape: batch_size x obs_dim\n",
    "        dones: a tensor of boolean done flags (indicates if next_state is terminal) Shape: batch_size x 1\n",
    "        discount_factor: discount\n",
    "    Returns:\n",
    "        A torch tensor filled with target values. Shape: batch_size x 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    max_next_Q = Q(next_states).max(1)[0][:, None]\n",
    "    bool_mask = torch.logical_not(dones)\n",
    "    targets = rewards + discount_factor * max_next_Q * bool_mask\n",
    "\n",
    "    return targets\n",
    "\n",
    "def train(Q, memory, optimizer, batch_size, discount_factor):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "    \n",
    "    # don't learn without some decent experience\n",
    "    if len(memory) < batch_size:\n",
    "        return None\n",
    "\n",
    "    # random transition batch is taken from experience replay memory\n",
    "    transitions = memory.sample(batch_size)\n",
    "    \n",
    "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
    "    state, action, reward, next_state, done = zip(*transitions)\n",
    "    \n",
    "    # convert to PyTorch and define types\n",
    "    state = torch.tensor(state, dtype=torch.float)\n",
    "    action = torch.tensor(action, dtype=torch.int64)[:, None]  # Need 64 bit to use them as index\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float)\n",
    "    reward = torch.tensor(reward, dtype=torch.float)[:, None]\n",
    "    done = torch.tensor(done, dtype=torch.uint8)[:, None]  # Boolean\n",
    "    \n",
    "    # compute the q value\n",
    "    q_val = compute_q_vals(Q, state, action)\n",
    "    with torch.no_grad():  # Don't compute gradient info for the target (semi-gradient)\n",
    "        target = compute_targets(Q, reward, next_state, done, discount_factor)\n",
    "    \n",
    "    # loss is measured from error between current and newly expected Q values\n",
    "    loss = F.smooth_l1_loss(q_val, target)\n",
    "\n",
    "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()  # Returns a Python scalar, and releases history (similar to .detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b060b822eec4282f",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46737411618232727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bart/miniconda3/envs/rlcourse/lib/python3.7/site-packages/ipykernel_launcher.py:54: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /croot/pytorch_1675190298929/work/torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    }
   ],
   "source": [
    "# You may want to test your functions individually, but after you do so lets see if the method train works.\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "# Simple gradient descent may take long, so we will use Adam\n",
    "optimizer = optim.Adam(Q_net.parameters(), learn_rate)\n",
    "\n",
    "# We need a larger memory, fill with dummy data\n",
    "transition = memory.sample(1)[0]\n",
    "memory = ReplayMemory(10 * batch_size)\n",
    "for i in range(batch_size):\n",
    "    memory.push(transition)\n",
    "\n",
    "# Now let's see if it works\n",
    "loss = train(Q_net, memory, optimizer, batch_size, discount_factor)\n",
    "\n",
    "print (loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3eafd0ab49103f3b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-36b8a04b393d8104",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now that you have implemented the training step, you should be able to put everything together. Implement the function `run_episodes` that runs a number of episodes of DQN training. It should return the durations (e.g. number of steps) of each episode. Note: we pass the train function as an argument such that we can swap it for a different training step later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-540a7d50ecc1d046",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dqn_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a dqn_autograde.py\n",
    "\n",
    "def run_episodes(train, Q, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate):\n",
    "    \n",
    "    optimizer = optim.Adam(Q.parameters(), learn_rate)\n",
    "    \n",
    "    global_steps = 0  # Count the steps (do not reset at episode start, to compute epsilon)\n",
    "    episode_durations = []  #\n",
    "    for i in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        \n",
    "        steps = 0\n",
    "        while True:\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            action = policy.sample_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.push((state, action, reward, next_state, done))\n",
    "            train(Q, memory, optimizer, batch_size, discount_factor)\n",
    "            state = next_state\n",
    "            steps += 1\n",
    "            \n",
    "            if done:\n",
    "                if i % 10 == 0:\n",
    "                    print(\"{2} Episode {0} finished after {1} steps\"\n",
    "                          .format(i, steps, '\\033[92m' if steps >= 195 else '\\033[99m'))\n",
    "                episode_durations.append(steps)\n",
    "                break\n",
    "    return episode_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 0 finished after 10 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 10 finished after 8 steps\n",
      "\u001b[99m Episode 20 finished after 9 steps\n",
      "\u001b[99m Episode 30 finished after 8 steps\n",
      "\u001b[99m Episode 40 finished after 8 steps\n",
      "\u001b[99m Episode 50 finished after 10 steps\n",
      "\u001b[99m Episode 60 finished after 17 steps\n",
      "\u001b[99m Episode 70 finished after 10 steps\n",
      "\u001b[99m Episode 80 finished after 32 steps\n",
      "\u001b[99m Episode 90 finished after 50 steps\n"
     ]
    }
   ],
   "source": [
    "# Let's run it!\n",
    "num_episodes = 100\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "memory = ReplayMemory(10000)\n",
    "num_hidden = 128\n",
    "seed = 42  # This is not randomly chosen\n",
    "\n",
    "# We will seed the algorithm (before initializing QNetwork!) for reproducibility\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "\n",
    "Q_net = QNetwork(num_hidden)\n",
    "policy = EpsilonGreedyPolicy(Q_net, 0.05)\n",
    "episode_durations = run_episodes(train, Q_net, policy, memory, env, num_episodes, batch_size, discount_factor, learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-928ecc11ed5c43d8",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Episode durations per episode')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And see the results\n",
    "def smooth(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "plt.plot(smooth(episode_durations, 10))\n",
    "plt.title('Episode durations per episode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the dqn_autograde.py file into codegrade.**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "rlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
